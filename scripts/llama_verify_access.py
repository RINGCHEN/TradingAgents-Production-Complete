#!/usr/bin/env python3
"""
LLaMA è¨ªå•æ¬Šé™é©—è­‰è…³æœ¬
æª¢æŸ¥ HuggingFace token å’Œ LLaMA æ¨¡å‹è¨ªå•æ¬Šé™
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def verify_llama_access():
    """é©—è­‰LLaMAè¨ªå•æ¬Šé™"""
    print("ğŸ” æª¢æŸ¥ LLaMA è¨ªå•æ¬Šé™...")
    
    # æª¢æŸ¥token
    hf_token = os.getenv("HUGGING_FACE_HUB_TOKEN")
    if not hf_token or hf_token == "your_token_here":
        print("âŒ HuggingFace token æœªé…ç½®ï¼")
        print("è«‹åœ¨ .env æ–‡ä»¶ä¸­è¨­ç½® HUGGING_FACE_HUB_TOKEN")
        return False
    
    print(f"âœ… HuggingFace token: {hf_token[:10]}...")
    
    try:
        from transformers import AutoTokenizer
        from huggingface_hub import login
        
        # ç™»éŒ„
        print("ğŸ” ç™»éŒ„ HuggingFace...")
        login(token=hf_token)
        print("âœ… HuggingFace ç™»éŒ„æˆåŠŸ")
        
        # æ¸¬è©¦ä¸åŒçš„LLaMAæ¨¡å‹
        models_to_test = [
            "meta-llama/Llama-3.2-1B-Instruct",
            "meta-llama/Llama-3.2-3B-Instruct",
            "meta-llama/Meta-Llama-3.1-8B-Instruct"
        ]
        
        accessible_models = []
        
        for model_name in models_to_test:
            try:
                print(f"ğŸ§ª æ¸¬è©¦æ¨¡å‹: {model_name}")
                tokenizer = AutoTokenizer.from_pretrained(model_name)
                print(f"âœ… {model_name} - å¯è¨ªå•")
                accessible_models.append(model_name)
            except Exception as e:
                print(f"âŒ {model_name} - ç„¡æ³•è¨ªå•: {str(e)[:100]}...")
        
        if accessible_models:
            print(f"\nğŸ‰ æˆåŠŸï¼å¯è¨ªå• {len(accessible_models)} å€‹ LLaMA æ¨¡å‹:")
            for model in accessible_models:
                print(f"  âœ… {model}")
            
            print(f"\nğŸš€ æ¨è–¦ä½¿ç”¨: {accessible_models[0]} (æœ€è¼•é‡)")
            return True
        else:
            print("\nâŒ ç„¡æ³•è¨ªå•ä»»ä½• LLaMA æ¨¡å‹")
            print("è«‹ç¢ºèª:")
            print("1. å·²åœ¨ HuggingFace ç”³è«‹ LLaMA è¨ªå•æ¬Šé™")
            print("2. Token å…·æœ‰æ­£ç¢ºçš„æ¬Šé™")
            print("3. ç¶²è·¯é€£æ¥æ­£å¸¸")
            return False
            
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„å¥—ä»¶: {e}")
        print("è«‹åŸ·è¡Œ: pip install transformers huggingface_hub")
        return False
    except Exception as e:
        print(f"âŒ é©—è­‰éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

if __name__ == "__main__":
    success = verify_llama_access()
    if success:
        print("\nâœ… LLaMA è¨ªå•æ¬Šé™é©—è­‰æˆåŠŸï¼")
        print("ğŸš€ ç¾åœ¨å¯ä»¥é–‹å§‹ AI è¨“ç·´äº†")
        print("åŸ·è¡Œ: python start_llama_training.py")
    else:
        print("\nâŒ LLaMA è¨ªå•æ¬Šé™é©—è­‰å¤±æ•—")
        sys.exit(1)