#!/usr/bin/env python3
"""
è¨“ç·´æ•¸æ“šå’Œç¯„ä¾‹ç³»çµ± - Task 4.2å¯¦ç¾
çµ±ä¸€ç®¡ç†è¨“ç·´æ•¸æ“šé›†ã€ç¯„ä¾‹ç”Ÿæˆã€æ•¸æ“šé©—è­‰å’ŒJSONLæ ¼å¼è™•ç†

This system provides:
- Unified training data management for SFT/LoRA/GRPO
- Financial example generation with domain expertise
- Data validation and quality assurance
- JSONL format standardization and conversion
- Dataset splitting and preprocessing utilities
- Integration with TradingAgents ecosystem

Author: TradingAgents Team (å¤©å·¥é–‹ç‰©) - æ”¯æ´AIè¨“ç·´å°ˆå®¶åœ˜éšŠ
Version: 1.0.0
"""

import os
import sys
import json
import logging
import random
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union, Generator
from dataclasses import dataclass, asdict
from enum import Enum
import uuid
import pandas as pd
import numpy as np
from collections import Counter, defaultdict
import re
from concurrent.futures import ThreadPoolExecutor

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [è¨“ç·´æ•¸æ“šç³»çµ±] - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/training/training_data_system.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("TrainingDataSystem")


class DatasetType(Enum):
    """æ•¸æ“šé›†é¡å‹æšèˆ‰"""
    SFT = "supervised_fine_tuning"      # ç›£ç£å¾®èª¿
    LORA = "lora_adaptation"           # LoRAé©æ‡‰
    GRPO = "grpo_reinforcement"        # GRPOå¼·åŒ–å­¸ç¿’
    CHAT = "chat_completion"           # å°è©±è£œå…¨
    INSTRUCTION = "instruction_following"  # æŒ‡ä»¤è·Ÿéš¨


class DataFormat(Enum):
    """æ•¸æ“šæ ¼å¼æšèˆ‰"""
    ALPACA = "alpaca"          # Alpacaæ ¼å¼
    SHAREGPT = "sharegpt"      # ShareGPTæ ¼å¼
    GRPO = "grpo"              # GRPOå°ˆç”¨æ ¼å¼
    CUSTOM = "custom"          # è‡ªå®šç¾©æ ¼å¼


class DatasetSplit(Enum):
    """æ•¸æ“šé›†åˆ†å‰²é¡å‹"""
    TRAIN = "train"
    VALIDATION = "validation"
    TEST = "test"


@dataclass
class DatasetConfig:
    """æ•¸æ“šé›†é…ç½®"""
    name: str
    description: str
    dataset_type: DatasetType
    data_format: DataFormat
    total_samples: int = 0
    train_ratio: float = 0.8
    validation_ratio: float = 0.1
    test_ratio: float = 0.1
    min_length: int = 10
    max_length: int = 2048
    quality_threshold: float = 0.7
    enable_augmentation: bool = False
    augmentation_ratio: float = 0.2


@dataclass
class DataSample:
    """æ•¸æ“šæ¨£æœ¬å®šç¾©"""
    sample_id: str
    dataset_type: DatasetType
    data_format: DataFormat
    content: Dict[str, Any]
    metadata: Dict[str, Any]
    quality_score: float = 0.0
    created_at: str = ""
    validated: bool = False


@dataclass
class DatasetStats:
    """æ•¸æ“šé›†çµ±è¨ˆä¿¡æ¯"""
    total_samples: int
    train_samples: int
    validation_samples: int
    test_samples: int
    avg_input_length: float
    avg_output_length: float
    quality_distribution: Dict[str, int]
    token_count: int
    unique_topics: int


class FinancialExampleGenerator:
    """
    é‡‘èé ˜åŸŸç¯„ä¾‹ç”Ÿæˆå™¨
    å°ˆé–€ç”Ÿæˆé«˜è³ªé‡çš„é‡‘èAIè¨“ç·´æ•¸æ“š
    """
    
    def __init__(self):
        # é‡‘èä¸»é¡Œåˆ†é¡
        self.financial_topics = {
            "è‚¡ç¥¨åˆ†æ": [
                "æŠ€è¡“åˆ†æ", "åŸºæœ¬é¢åˆ†æ", "è²¡å ±åˆ†æ", "ç”¢æ¥­åˆ†æ", 
                "æŠ•è³‡ç­–ç•¥", "é¢¨éšªè©•ä¼°", "åƒ¹å€¼æŠ•è³‡", "æˆé•·è‚¡æŠ•è³‡"
            ],
            "å¸‚å ´ç ”ç©¶": [
                "å¸‚å ´è¶‹å‹¢", "ç¶“æ¿ŸæŒ‡æ¨™", "ç”¢æ¥­å‰æ™¯", "æ”¿ç­–å½±éŸ¿",
                "åœ‹éš›å¸‚å ´", "åŒ¯ç‡åˆ†æ", "å•†å“æœŸè²¨", "ç¸½é«”ç¶“æ¿Ÿ"
            ],
            "æŠ•è³‡ç†è²¡": [
                "è³‡ç”¢é…ç½®", "æŠ•è³‡çµ„åˆ", "é¢¨éšªç®¡ç†", "é€€ä¼‘è¦åŠƒ",
                "ä¿éšªè¦åŠƒ", "ç¨…å‹™è¦åŠƒ", "å®šæœŸå®šé¡", "ETFæŠ•è³‡"
            ],
            "äº¤æ˜“ç­–ç•¥": [
                "ç•¶æ²–ç­–ç•¥", "æ³¢æ®µæ“ä½œ", "é•·æœŸæŠ•è³‡", "é¸è‚¡æ–¹æ³•",
                "è²·è³£æ™‚æ©Ÿ", "åœæåœåˆ©", "è³‡é‡‘ç®¡ç†", "å¿ƒç†å»ºè¨­"
            ]
        }
        
        # å°è‚¡å…¬å¸ç¯„ä¾‹
        self.taiwan_companies = [
            "å°ç©é›»(2330)", "é´»æµ·(2317)", "è¯ç™¼ç§‘(2454)", "å°é”é›»(2308)",
            "ä¸­è¯é›»(2412)", "å¯Œé‚¦é‡‘(2881)", "åœ‹æ³°é‡‘(2882)", "å°å¡‘(1301)",
            "å—äº(1303)", "ä¸­é‹¼(2002)", "çµ±ä¸€(1216)", "æ°¸è±é¤˜(1907)",
            "å»£é”(2382)", "å’Œç¢©(4938)", "æ—¥æœˆå…‰(3711)", "è¯é›»(2303)"
        ]
        
        # é‡‘èè¡“èªåº«
        self.financial_terms = {
            "åŸºç¤": ["æœ¬ç›Šæ¯”", "è‚¡åƒ¹æ·¨å€¼æ¯”", "æ®–åˆ©ç‡", "å¸‚å€¼", "æˆäº¤é‡", "é€±è½‰ç‡"],
            "é€²éš": ["EBITDA", "è‡ªç”±ç¾é‡‘æµ", "ROE", "ROA", "æ¯›åˆ©ç‡", "è² å‚µæ¯”"],
            "æŠ€è¡“": ["ç§»å‹•å¹³å‡ç·š", "ç›¸å°å¼·å¼±æŒ‡æ¨™", "MACD", "å¸ƒæ—é€šé“", "KDæŒ‡æ¨™", "å¨å»‰æŒ‡æ¨™"],
            "å¸‚å ´": ["å¤šé ­", "ç©ºé ­", "ç›¤æ•´", "çªç ´", "å›æª”", "åå½ˆ", "æ•´ç†"]
        }
        
    def generate_sft_samples(self, num_samples: int) -> List[Dict[str, Any]]:
        """ç”ŸæˆSFTè¨“ç·´æ¨£æœ¬"""
        samples = []
        
        for i in range(num_samples):
            topic = random.choice(list(self.financial_topics.keys()))
            subtopic = random.choice(self.financial_topics[topic])
            company = random.choice(self.taiwan_companies)
            
            # ç”Ÿæˆå•é¡Œ
            instruction = self._generate_instruction(topic, subtopic, company)
            
            # ç”Ÿæˆå›ç­”
            output = self._generate_financial_answer(topic, subtopic, company, instruction)
            
            sample = {
                "instruction": instruction,
                "input": "",
                "output": output,
                "topic": topic,
                "subtopic": subtopic,
                "company": company
            }
            
            samples.append(sample)
            
        return samples
    
    def generate_grpo_samples(self, num_samples: int) -> List[Dict[str, Any]]:
        """ç”ŸæˆGRPOè¨“ç·´æ¨£æœ¬"""
        samples = []
        
        for i in range(num_samples):
            topic = random.choice(list(self.financial_topics.keys()))
            subtopic = random.choice(self.financial_topics[topic])
            company = random.choice(self.taiwan_companies)
            
            query = self._generate_grpo_query(topic, subtopic, company)
            context = self._generate_context(topic, subtopic)
            reference = self._generate_reference_answer(topic, subtopic, company)
            
            sample = {
                "query": query,
                "context": context,
                "reference": reference,
                "topic": topic,
                "subtopic": subtopic
            }
            
            samples.append(sample)
            
        return samples
    
    def generate_chat_samples(self, num_samples: int) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå°è©±æ ¼å¼æ¨£æœ¬"""
        samples = []
        
        for i in range(num_samples):
            conversation = self._generate_financial_conversation()
            
            sample = {
                "conversations": conversation,
                "topic": conversation[0].get("metadata", {}).get("topic", "general")
            }
            
            samples.append(sample)
            
        return samples
    
    def _generate_instruction(self, topic: str, subtopic: str, company: str) -> str:
        """ç”ŸæˆæŒ‡ä»¤"""
        templates = [
            f"è«‹åˆ†æ{company}çš„{subtopic}",
            f"å¦‚ä½•è©•ä¼°{company}çš„{subtopic}ï¼Ÿ",
            f"å¾{subtopic}è§’åº¦åˆ†æ{company}çš„æŠ•è³‡åƒ¹å€¼",
            f"è«‹èªªæ˜{company}åœ¨{subtopic}æ–¹é¢çš„è¡¨ç¾",
            f"åˆ†æ{company}çš„{subtopic}ä¸¦çµ¦å‡ºæŠ•è³‡å»ºè­°",
        ]
        
        # æ ¹æ“šä¸»é¡Œèª¿æ•´æ¨¡æ¿
        if topic == "å¸‚å ´ç ”ç©¶":
            templates.extend([
                f"ç•¶å‰{subtopic}å°{company}çš„å½±éŸ¿å¦‚ä½•ï¼Ÿ",
                f"è«‹åˆ†æ{subtopic}è¶¨å‹¢å°{company}çš„æ½›åœ¨å½±éŸ¿"
            ])
        
        return random.choice(templates)
    
    def _generate_financial_answer(self, topic: str, subtopic: str, company: str, instruction: str) -> str:
        """ç”Ÿæˆé‡‘èåˆ†æå›ç­”"""
        # åŸºç¤å›ç­”çµæ§‹
        analysis_points = []
        
        # æ ¹æ“šå­ä¸»é¡Œæ·»åŠ åˆ†æè¦é»
        if "æŠ€è¡“åˆ†æ" in subtopic:
            analysis_points.extend([
                f"{company}è¿‘æœŸè‚¡åƒ¹èµ°å‹¢é¡¯ç¤º",
                f"å¾æŠ€è¡“æŒ‡æ¨™ä¾†çœ‹",
                f"æ”¯æ’ä½å’Œå£“åŠ›ä½åˆ†æ"
            ])
        elif "åŸºæœ¬é¢åˆ†æ" in subtopic:
            analysis_points.extend([
                f"{company}çš„è²¡å‹™æ•¸æ“šé¡¯ç¤º",
                f"ç‡Ÿæ”¶æˆé•·æ€§åˆ†æ",
                f"ç²åˆ©èƒ½åŠ›è©•ä¼°"
            ])
        elif "é¢¨éšªè©•ä¼°" in subtopic:
            analysis_points.extend([
                f"{company}é¢è‡¨çš„ä¸»è¦é¢¨éšªåŒ…æ‹¬",
                f"ç”¢æ¥­ç«¶çˆ­é¢¨éšª",
                f"è²¡å‹™é¢¨éšªè©•ä¼°"
            ])
        
        # æ§‹å»ºå›ç­”
        answer_parts = []
        for point in analysis_points[:3]:  # é™åˆ¶3å€‹è¦é»
            detail = self._generate_analysis_detail(topic, subtopic)
            answer_parts.append(f"{point}{detail}")
        
        # æ·»åŠ é¢¨éšªè­¦å‘Š
        risk_warning = "æŠ•è³‡æœ‰é¢¨éšªï¼Œå»ºè­°ä»”ç´°è©•ä¼°ä¸¦åˆ†æ•£æŠ•è³‡ã€‚"
        
        # çµ„åˆå®Œæ•´å›ç­”
        full_answer = "ã€‚".join(answer_parts) + "ã€‚" + risk_warning
        
        return full_answer
    
    def _generate_analysis_detail(self, topic: str, subtopic: str) -> str:
        """ç”Ÿæˆåˆ†æç´°ç¯€"""
        details = [
            "è¡¨ç¾ç©©å¥ï¼Œå€¼å¾—æŒçºŒé—œæ³¨",
            "æœ‰ä¸€å®šä¸Šæ¼²æ½›åŠ›ï¼Œä½†éœ€æ³¨æ„é¢¨éšªæ§åˆ¶",
            "çŸ­æœŸå¯èƒ½é¢è‡¨èª¿æ•´å£“åŠ›",
            "é•·æœŸæŠ•è³‡åƒ¹å€¼çœ‹å¥½",
            "å»ºè­°ç­‰å¾…æ›´å¥½çš„è²·é»",
            "é©åˆå®šæœŸå®šé¡æŠ•è³‡ç­–ç•¥"
        ]
        
        return random.choice(details)
    
    def _generate_grpo_query(self, topic: str, subtopic: str, company: str) -> str:
        """ç”ŸæˆGRPOæŸ¥è©¢"""
        queries = [
            f"åˆ†æ{company}çš„æŠ•è³‡æ½›åŠ›",
            f"{company}é©åˆç¾åœ¨æŠ•è³‡å—ï¼Ÿ",
            f"è«‹è©•ä¼°{company}çš„{subtopic}",
            f"{company}çš„é¢¨éšªå’Œæ©Ÿæœƒæ˜¯ä»€éº¼ï¼Ÿ",
            f"å¾{subtopic}è§’åº¦çœ‹{company}æ€éº¼æ¨£ï¼Ÿ"
        ]
        
        return random.choice(queries)
    
    def _generate_context(self, topic: str, subtopic: str) -> str:
        """ç”Ÿæˆä¸Šä¸‹æ–‡"""
        contexts = {
            "è‚¡ç¥¨åˆ†æ": "å°è‚¡æŠ•è³‡åˆ†æ",
            "å¸‚å ´ç ”ç©¶": "å¸‚å ´ç ”ç©¶å ±å‘Š",
            "æŠ•è³‡ç†è²¡": "æŠ•è³‡ç†è²¡è«®è©¢",
            "äº¤æ˜“ç­–ç•¥": "äº¤æ˜“ç­–ç•¥åˆ†æ"
        }
        
        return contexts.get(topic, "é‡‘èåˆ†æ")
    
    def _generate_reference_answer(self, topic: str, subtopic: str, company: str) -> str:
        """ç”Ÿæˆåƒè€ƒç­”æ¡ˆ"""
        return f"é‡å°{company}çš„{subtopic}ï¼Œéœ€è¦ç¶œåˆè€ƒæ…®å¤šé …å› ç´ ï¼ŒåŒ…æ‹¬è²¡å‹™è¡¨ç¾ã€å¸‚å ´ç’°å¢ƒå’Œé¢¨éšªå› ç´ ã€‚å»ºè­°æŠ•è³‡äººä»”ç´°ç ”ç©¶ç›¸é—œè³‡æ–™å¾Œå†åšæ±ºå®šã€‚"
    
    def _generate_financial_conversation(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆé‡‘èå°è©±"""
        topic = random.choice(list(self.financial_topics.keys()))
        company = random.choice(self.taiwan_companies)
        
        conversation = [
            {
                "from": "human",
                "value": f"æˆ‘æƒ³äº†è§£{company}çš„æŠ•è³‡åƒ¹å€¼ï¼Œå¯ä»¥å¹«æˆ‘åˆ†æå—ï¼Ÿ",
                "metadata": {"topic": topic}
            },
            {
                "from": "gpt",
                "value": f"æˆ‘ä¾†ç‚ºæ‚¨åˆ†æ{company}çš„æŠ•è³‡åƒ¹å€¼ã€‚é¦–å…ˆéœ€è¦å¾å¹¾å€‹ç¶­åº¦ä¾†è©•ä¼°ï¼šè²¡å‹™é¢ã€æŠ€è¡“é¢å’ŒåŸºæœ¬é¢ã€‚è®“æˆ‘è©³ç´°èªªæ˜..."
            },
            {
                "from": "human", 
                "value": "é‚£é¢¨éšªæ–¹é¢éœ€è¦æ³¨æ„ä»€éº¼ï¼Ÿ"
            },
            {
                "from": "gpt",
                "value": f"æŠ•è³‡{company}éœ€è¦æ³¨æ„ä»¥ä¸‹é¢¨éšªï¼šç”¢æ¥­ç«¶çˆ­åŠ åŠ‡ã€å¸‚å ´æ³¢å‹•é¢¨éšªã€ä»¥åŠç¸½é«”ç¶“æ¿Ÿè®ŠåŒ–çš„å½±éŸ¿ã€‚å»ºè­°åˆ†æ•£æŠ•è³‡ä¸¦è¨­å®šåˆç†çš„åœæé»ã€‚"
            }
        ]
        
        return conversation


class DataValidator:
    """
    æ•¸æ“šé©—è­‰å™¨
    ç¢ºä¿è¨“ç·´æ•¸æ“šçš„è³ªé‡å’Œä¸€è‡´æ€§
    """
    
    def __init__(self, config: DatasetConfig):
        self.config = config
        
        # è³ªé‡æª¢æŸ¥è¦å‰‡
        self.quality_rules = {
            'min_length': config.min_length,
            'max_length': config.max_length,
            'required_fields': self._get_required_fields(),
            'forbidden_patterns': [
                r'å…§ç·šæ¶ˆæ¯', r'ä¿è­‰ç²åˆ©', r'ç©©è³ºä¸è³ ', r'æ˜ç‰Œ',
                r'ä¸€å®šæœƒæ¼²', r'çµ•å°å®‰å…¨'
            ]
        }
    
    def _get_required_fields(self) -> List[str]:
        """ç²å–å¿…éœ€å­—æ®µ"""
        if self.config.data_format == DataFormat.ALPACA:
            return ['instruction', 'output']
        elif self.config.data_format == DataFormat.GRPO:
            return ['query', 'reference']
        elif self.config.data_format == DataFormat.SHAREGPT:
            return ['conversations']
        else:
            return []
    
    def validate_sample(self, sample: Dict[str, Any]) -> Tuple[bool, float, List[str]]:
        """
        é©—è­‰å–®å€‹æ¨£æœ¬
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, è³ªé‡åˆ†æ•¸, å•é¡Œåˆ—è¡¨)
        """
        issues = []
        quality_score = 1.0
        
        # æª¢æŸ¥å¿…éœ€å­—æ®µ
        for field in self.quality_rules['required_fields']:
            if field not in sample:
                issues.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                quality_score -= 0.3
        
        # æª¢æŸ¥å…§å®¹é•·åº¦
        content_text = self._extract_text_content(sample)
        if len(content_text) < self.quality_rules['min_length']:
            issues.append(f"å…§å®¹éçŸ­: {len(content_text)} < {self.quality_rules['min_length']}")
            quality_score -= 0.2
        
        if len(content_text) > self.quality_rules['max_length']:
            issues.append(f"å…§å®¹éé•·: {len(content_text)} > {self.quality_rules['max_length']}")
            quality_score -= 0.2
        
        # æª¢æŸ¥ç¦ç”¨æ¨¡å¼
        for pattern in self.quality_rules['forbidden_patterns']:
            if re.search(pattern, content_text):
                issues.append(f"åŒ…å«ç¦ç”¨å…§å®¹: {pattern}")
                quality_score -= 0.4
        
        # æª¢æŸ¥é‡‘èç›¸é—œæ€§
        financial_relevance = self._check_financial_relevance(content_text)
        if financial_relevance < 0.3:
            issues.append("é‡‘èç›¸é—œæ€§ä¸è¶³")
            quality_score -= 0.3
        
        # æœ€çµ‚è³ªé‡åˆ†æ•¸
        quality_score = max(0.0, min(1.0, quality_score))
        is_valid = quality_score >= self.config.quality_threshold and not any("ç¼ºå°‘å¿…éœ€å­—æ®µ" in issue for issue in issues)
        
        return is_valid, quality_score, issues
    
    def _extract_text_content(self, sample: Dict[str, Any]) -> str:
        """æå–æ¨£æœ¬çš„æ–‡æœ¬å…§å®¹"""
        content_parts = []
        
        if 'instruction' in sample:
            content_parts.append(sample['instruction'])
        if 'input' in sample and sample['input']:
            content_parts.append(sample['input'])
        if 'output' in sample:
            content_parts.append(sample['output'])
        if 'query' in sample:
            content_parts.append(sample['query'])
        if 'reference' in sample:
            content_parts.append(sample['reference'])
        if 'conversations' in sample:
            for turn in sample['conversations']:
                if 'value' in turn:
                    content_parts.append(turn['value'])
        
        return ' '.join(content_parts)
    
    def _check_financial_relevance(self, text: str) -> float:
        """æª¢æŸ¥é‡‘èç›¸é—œæ€§"""
        financial_keywords = [
            'æŠ•è³‡', 'è‚¡ç¥¨', 'è‚¡åƒ¹', 'åˆ†æ', 'é¢¨éšª', 'å ±é…¬', 'å¸‚å ´',
            'è²¡å‹™', 'ç²åˆ©', 'ç‡Ÿæ”¶', 'æœ¬ç›Šæ¯”', 'æ®–åˆ©ç‡', 'æŠ€è¡“åˆ†æ',
            'åŸºæœ¬é¢', 'ç”¢æ¥­', 'ç¶“æ¿Ÿ', 'è³‡ç”¢', 'é…ç½®', 'ç†è²¡'
        ]
        
        keyword_count = sum(1 for keyword in financial_keywords if keyword in text)
        relevance_score = min(1.0, keyword_count / 10)  # 10å€‹é—œéµè©å¾—æ»¿åˆ†
        
        return relevance_score


class TrainingDataSystem:
    """
    è¨“ç·´æ•¸æ“šå’Œç¯„ä¾‹ç³»çµ±ä¸»é¡
    çµ±ä¸€ç®¡ç†æ‰€æœ‰è¨“ç·´ç›¸é—œçš„æ•¸æ“šè™•ç†
    """
    
    def __init__(self, config_path: Optional[str] = None):
        logger.info("ğŸ—ƒï¸ åˆå§‹åŒ–è¨“ç·´æ•¸æ“šç³»çµ±...")
        
        # åŠ è¼‰é…ç½®
        self.config = self._load_config(config_path)
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.example_generator = FinancialExampleGenerator()
        
        # æ•¸æ“šå­˜å„²
        self.datasets: Dict[str, List[DataSample]] = {}
        self.dataset_configs: Dict[str, DatasetConfig] = {}
        self.dataset_stats: Dict[str, DatasetStats] = {}
        
        # æ•¸æ“šè·¯å¾‘
        self.data_base_path = Path(self.config.get('data_base_path', '/app/data/training'))
        self.data_base_path.mkdir(parents=True, exist_ok=True)
        
        logger.info("âœ… è¨“ç·´æ•¸æ“šç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """åŠ è¼‰ç³»çµ±é…ç½®"""
        default_config = {
            'data_base_path': '/app/data/training',
            'supported_formats': ['alpaca', 'sharegpt', 'grpo'],
            'default_train_ratio': 0.8,
            'default_validation_ratio': 0.1,
            'default_test_ratio': 0.1,
            'quality_threshold': 0.7,
            'enable_parallel_processing': True,
            'max_workers': 4,
            'auto_backup': True,
            'backup_interval_hours': 24
        }
        
        if config_path and Path(config_path).exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                default_config.update(user_config)
                logger.info(f"ğŸ“‹ é…ç½®å·²å¾ {config_path} è¼‰å…¥")
            except Exception as e:
                logger.warning(f"âš ï¸ é…ç½®è¼‰å…¥å¤±æ•— {config_path}: {e}")
        
        return default_config
    
    def create_dataset(self, 
                      name: str,
                      dataset_type: DatasetType,
                      data_format: DataFormat,
                      num_samples: int,
                      **kwargs) -> str:
        """
        å‰µå»ºæ–°çš„æ•¸æ“šé›†
        
        Returns:
            æ•¸æ“šé›†ID
        """
        dataset_id = f"{name}_{uuid.uuid4().hex[:8]}"
        
        logger.info(f"ğŸ“Š å‰µå»ºæ•¸æ“šé›†: {name} (é¡å‹: {dataset_type.value}, æ ¼å¼: {data_format.value})")
        
        # å‰µå»ºæ•¸æ“šé›†é…ç½®
        dataset_config = DatasetConfig(
            name=name,
            description=kwargs.get('description', f'{dataset_type.value}æ•¸æ“šé›†'),
            dataset_type=dataset_type,
            data_format=data_format,
            total_samples=num_samples,
            **{k: v for k, v in kwargs.items() if k in DatasetConfig.__annotations__}
        )
        
        self.dataset_configs[dataset_id] = dataset_config
        
        # ç”Ÿæˆæ•¸æ“šæ¨£æœ¬
        samples = self._generate_samples(dataset_config, num_samples)
        
        # é©—è­‰æ•¸æ“šè³ªé‡
        validated_samples = self._validate_samples(samples, dataset_config)
        
        # å­˜å„²æ•¸æ“šé›†
        self.datasets[dataset_id] = validated_samples
        
        # æ›´æ–°çµ±è¨ˆä¿¡æ¯
        self._update_dataset_stats(dataset_id)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_dataset(dataset_id)
        
        logger.info(f"âœ… æ•¸æ“šé›†å‰µå»ºå®Œæˆ: {dataset_id} ({len(validated_samples)} å€‹æœ‰æ•ˆæ¨£æœ¬)")
        
        return dataset_id
    
    def _generate_samples(self, config: DatasetConfig, num_samples: int) -> List[DataSample]:
        """ç”Ÿæˆæ•¸æ“šæ¨£æœ¬"""
        logger.info(f"ğŸ”„ ç”Ÿæˆ {num_samples} å€‹ {config.dataset_type.value} æ¨£æœ¬...")
        
        samples = []
        
        if config.dataset_type == DatasetType.SFT:
            raw_samples = self.example_generator.generate_sft_samples(num_samples)
        elif config.dataset_type == DatasetType.GRPO:
            raw_samples = self.example_generator.generate_grpo_samples(num_samples)
        elif config.dataset_type == DatasetType.CHAT:
            raw_samples = self.example_generator.generate_chat_samples(num_samples)
        else:
            # é»˜èªç”ŸæˆSFTæ¨£æœ¬
            raw_samples = self.example_generator.generate_sft_samples(num_samples)
        
        # è½‰æ›ç‚ºDataSampleå°è±¡
        for i, raw_sample in enumerate(raw_samples):
            sample = DataSample(
                sample_id=f"{config.name}_{i:06d}",
                dataset_type=config.dataset_type,
                data_format=config.data_format,
                content=raw_sample,
                metadata={
                    'created_at': datetime.now().isoformat(),
                    'generator': 'FinancialExampleGenerator',
                    'version': '1.0.0'
                },
                created_at=datetime.now().isoformat()
            )
            samples.append(sample)
        
        return samples
    
    def _validate_samples(self, samples: List[DataSample], config: DatasetConfig) -> List[DataSample]:
        """é©—è­‰æ•¸æ“šæ¨£æœ¬"""
        logger.info(f"ğŸ” é©—è­‰ {len(samples)} å€‹æ•¸æ“šæ¨£æœ¬...")
        
        validator = DataValidator(config)
        validated_samples = []
        validation_stats = {'valid': 0, 'invalid': 0, 'total_issues': 0}
        
        for sample in samples:
            is_valid, quality_score, issues = validator.validate_sample(sample.content)
            
            sample.quality_score = quality_score
            sample.validated = True
            
            if issues:
                sample.metadata['validation_issues'] = issues
                validation_stats['total_issues'] += len(issues)
            
            if is_valid:
                validated_samples.append(sample)
                validation_stats['valid'] += 1
            else:
                validation_stats['invalid'] += 1
        
        logger.info(f"âœ… é©—è­‰å®Œæˆ: {validation_stats['valid']} æœ‰æ•ˆ, {validation_stats['invalid']} ç„¡æ•ˆ")
        
        if validation_stats['total_issues'] > 0:
            logger.warning(f"âš ï¸ ç™¼ç¾ {validation_stats['total_issues']} å€‹æ•¸æ“šè³ªé‡å•é¡Œ")
        
        return validated_samples
    
    def split_dataset(self, dataset_id: str, 
                     train_ratio: Optional[float] = None,
                     validation_ratio: Optional[float] = None,
                     test_ratio: Optional[float] = None) -> Dict[str, List[DataSample]]:
        """åˆ†å‰²æ•¸æ“šé›†"""
        if dataset_id not in self.datasets:
            raise ValueError(f"æ•¸æ“šé›†ä¸å­˜åœ¨: {dataset_id}")
        
        config = self.dataset_configs[dataset_id]
        samples = self.datasets[dataset_id]
        
        # ä½¿ç”¨é…ç½®çš„æ¯”ä¾‹
        train_ratio = train_ratio or config.train_ratio
        validation_ratio = validation_ratio or config.validation_ratio
        test_ratio = test_ratio or config.test_ratio
        
        # ç¢ºä¿æ¯”ä¾‹ç¸½å’Œç‚º1
        total_ratio = train_ratio + validation_ratio + test_ratio
        if abs(total_ratio - 1.0) > 0.01:
            train_ratio /= total_ratio
            validation_ratio /= total_ratio
            test_ratio /= total_ratio
        
        # éš¨æ©Ÿæ‰“äº‚æ¨£æœ¬
        shuffled_samples = samples.copy()
        random.shuffle(shuffled_samples)
        
        total_samples = len(shuffled_samples)
        train_size = int(total_samples * train_ratio)
        val_size = int(total_samples * validation_ratio)
        
        # åˆ†å‰²æ•¸æ“š
        splits = {
            'train': shuffled_samples[:train_size],
            'validation': shuffled_samples[train_size:train_size + val_size],
            'test': shuffled_samples[train_size + val_size:]
        }
        
        logger.info(f"ğŸ“Š æ•¸æ“šé›†åˆ†å‰²å®Œæˆ: è¨“ç·´={len(splits['train'])}, "
                   f"é©—è­‰={len(splits['validation'])}, æ¸¬è©¦={len(splits['test'])}")
        
        return splits
    
    def export_dataset(self, dataset_id: str, 
                      output_path: str,
                      split: Optional[str] = None,
                      export_format: str = 'jsonl') -> str:
        """å°å‡ºæ•¸æ“šé›†"""
        if dataset_id not in self.datasets:
            raise ValueError(f"æ•¸æ“šé›†ä¸å­˜åœ¨: {dataset_id}")
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if split:
            # å°å‡ºç‰¹å®šåˆ†å‰²
            splits = self.split_dataset(dataset_id)
            if split not in splits:
                raise ValueError(f"åˆ†å‰²ä¸å­˜åœ¨: {split}")
            samples_to_export = splits[split]
            export_file = output_path / f"{dataset_id}_{split}.{export_format}"
        else:
            # å°å‡ºå®Œæ•´æ•¸æ“šé›†
            samples_to_export = self.datasets[dataset_id]
            export_file = output_path / f"{dataset_id}.{export_format}"
        
        logger.info(f"ğŸ’¾ å°å‡ºæ•¸æ“šé›†: {export_file} ({len(samples_to_export)} å€‹æ¨£æœ¬)")
        
        if export_format == 'jsonl':
            with open(export_file, 'w', encoding='utf-8') as f:
                for sample in samples_to_export:
                    f.write(json.dumps(sample.content, ensure_ascii=False) + '\n')
        elif export_format == 'json':
            export_data = [sample.content for sample in samples_to_export]
            with open(export_file, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å°å‡ºæ ¼å¼: {export_format}")
        
        logger.info(f"âœ… æ•¸æ“šé›†å·²å°å‡º: {export_file}")
        
        return str(export_file)
    
    def _update_dataset_stats(self, dataset_id: str):
        """æ›´æ–°æ•¸æ“šé›†çµ±è¨ˆä¿¡æ¯"""
        samples = self.datasets[dataset_id]
        config = self.dataset_configs[dataset_id]
        
        # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
        total_samples = len(samples)
        
        # é•·åº¦çµ±è¨ˆ
        input_lengths = []
        output_lengths = []
        quality_scores = []
        
        for sample in samples:
            content = sample.content
            quality_scores.append(sample.quality_score)
            
            if 'instruction' in content:
                input_lengths.append(len(content['instruction']))
            if 'output' in content:
                output_lengths.append(len(content['output']))
            if 'query' in content:
                input_lengths.append(len(content['query']))
            if 'reference' in content:
                output_lengths.append(len(content['reference']))
        
        # è³ªé‡åˆ†å¸ƒ
        quality_distribution = {
            'excellent': sum(1 for s in quality_scores if s >= 0.9),
            'good': sum(1 for s in quality_scores if 0.7 <= s < 0.9),
            'fair': sum(1 for s in quality_scores if 0.5 <= s < 0.7),
            'poor': sum(1 for s in quality_scores if s < 0.5)
        }
        
        # åˆ†å‰²çµ±è¨ˆ
        splits = self.split_dataset(dataset_id)
        
        stats = DatasetStats(
            total_samples=total_samples,
            train_samples=len(splits['train']),
            validation_samples=len(splits['validation']),
            test_samples=len(splits['test']),
            avg_input_length=np.mean(input_lengths) if input_lengths else 0,
            avg_output_length=np.mean(output_lengths) if output_lengths else 0,
            quality_distribution=quality_distribution,
            token_count=sum(input_lengths + output_lengths),
            unique_topics=len(set(s.content.get('topic', 'unknown') for s in samples))
        )
        
        self.dataset_stats[dataset_id] = stats
    
    def _save_dataset(self, dataset_id: str):
        """ä¿å­˜æ•¸æ“šé›†åˆ°æ–‡ä»¶"""
        dataset_dir = self.data_base_path / dataset_id
        dataset_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æ¨£æœ¬æ•¸æ“š
        samples_file = dataset_dir / 'samples.json'
        with open(samples_file, 'w', encoding='utf-8') as f:
            samples_data = [asdict(sample) for sample in self.datasets[dataset_id]]
            json.dump(samples_data, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜é…ç½®
        config_file = dataset_dir / 'config.json'
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(self.dataset_configs[dataset_id]), f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜çµ±è¨ˆä¿¡æ¯
        if dataset_id in self.dataset_stats:
            stats_file = dataset_dir / 'stats.json'
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(asdict(self.dataset_stats[dataset_id]), f, indent=2, ensure_ascii=False)
    
    def load_dataset(self, dataset_path: str) -> str:
        """è¼‰å…¥ç¾æœ‰æ•¸æ“šé›†"""
        dataset_path = Path(dataset_path)
        
        if not dataset_path.exists():
            raise FileNotFoundError(f"æ•¸æ“šé›†è·¯å¾‘ä¸å­˜åœ¨: {dataset_path}")
        
        logger.info(f"ğŸ“¥ è¼‰å…¥æ•¸æ“šé›†: {dataset_path}")
        
        # ç”Ÿæˆæ•¸æ“šé›†ID
        dataset_id = f"loaded_{dataset_path.stem}_{uuid.uuid4().hex[:8]}"
        
        # è¼‰å…¥JSONLæ ¼å¼æ•¸æ“š
        samples = []
        with open(dataset_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                try:
                    data = json.loads(line.strip())
                    
                    # æ¨æ–·æ•¸æ“šæ ¼å¼å’Œé¡å‹
                    if 'conversations' in data:
                        data_format = DataFormat.SHAREGPT
                        dataset_type = DatasetType.CHAT
                    elif 'query' in data and 'reference' in data:
                        data_format = DataFormat.GRPO
                        dataset_type = DatasetType.GRPO
                    else:
                        data_format = DataFormat.ALPACA
                        dataset_type = DatasetType.SFT
                    
                    sample = DataSample(
                        sample_id=f"loaded_{i:06d}",
                        dataset_type=dataset_type,
                        data_format=data_format,
                        content=data,
                        metadata={'loaded_from': str(dataset_path)},
                        created_at=datetime.now().isoformat()
                    )
                    samples.append(sample)
                    
                except json.JSONDecodeError as e:
                    logger.warning(f"âš ï¸ è·³éç„¡æ•ˆè¡Œ {i+1}: {e}")
        
        # å‰µå»ºæ•¸æ“šé›†é…ç½®
        config = DatasetConfig(
            name=dataset_path.stem,
            description=f"å¾ {dataset_path} è¼‰å…¥çš„æ•¸æ“šé›†",
            dataset_type=dataset_type,
            data_format=data_format,
            total_samples=len(samples)
        )
        
        # å­˜å„²æ•¸æ“šé›†
        self.datasets[dataset_id] = samples
        self.dataset_configs[dataset_id] = config
        self._update_dataset_stats(dataset_id)
        
        logger.info(f"âœ… æ•¸æ“šé›†è¼‰å…¥å®Œæˆ: {dataset_id} ({len(samples)} å€‹æ¨£æœ¬)")
        
        return dataset_id
    
    def get_dataset_info(self, dataset_id: str) -> Dict[str, Any]:
        """ç²å–æ•¸æ“šé›†ä¿¡æ¯"""
        if dataset_id not in self.datasets:
            raise ValueError(f"æ•¸æ“šé›†ä¸å­˜åœ¨: {dataset_id}")
        
        config = self.dataset_configs[dataset_id]
        stats = self.dataset_stats.get(dataset_id)
        
        info = {
            'dataset_id': dataset_id,
            'config': asdict(config),
            'stats': asdict(stats) if stats else None,
            'sample_count': len(self.datasets[dataset_id]),
            'created_at': datetime.now().isoformat()
        }
        
        return info
    
    def list_datasets(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰æ•¸æ“šé›†"""
        return [self.get_dataset_info(dataset_id) for dataset_id in self.datasets.keys()]


def main():
    """ä¸»å‡½æ•¸ - å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è¨“ç·´æ•¸æ“šå’Œç¯„ä¾‹ç³»çµ±')
    parser.add_argument('--action', type=str, required=True, 
                       choices=['create', 'load', 'export', 'info', 'list'],
                       help='æ“ä½œé¡å‹')
    parser.add_argument('--name', type=str, help='æ•¸æ“šé›†åç¨±')
    parser.add_argument('--type', type=str, default='sft',
                       choices=['sft', 'lora', 'grpo', 'chat'], 
                       help='æ•¸æ“šé›†é¡å‹')
    parser.add_argument('--format', type=str, default='alpaca',
                       choices=['alpaca', 'sharegpt', 'grpo'],
                       help='æ•¸æ“šæ ¼å¼')
    parser.add_argument('--samples', type=int, default=1000, help='æ¨£æœ¬æ•¸é‡')
    parser.add_argument('--input', type=str, help='è¼¸å…¥æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--output', type=str, help='è¼¸å‡ºæ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--dataset-id', type=str, help='æ•¸æ“šé›†ID')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾‘')
    
    args = parser.parse_args()
    
    try:
        # å‰µå»ºæ•¸æ“šç³»çµ±
        data_system = TrainingDataSystem(args.config)
        
        if args.action == 'create':
            if not args.name:
                raise ValueError("å‰µå»ºæ•¸æ“šé›†éœ€è¦æä¾›åç¨± (--name)")
            
            dataset_type = DatasetType[args.type.upper()]
            data_format = DataFormat[args.format.upper()]
            
            dataset_id = data_system.create_dataset(
                name=args.name,
                dataset_type=dataset_type,
                data_format=data_format,
                num_samples=args.samples
            )
            
            print(f"âœ… æ•¸æ“šé›†å·²å‰µå»º: {dataset_id}")
            
        elif args.action == 'load':
            if not args.input:
                raise ValueError("è¼‰å…¥æ•¸æ“šé›†éœ€è¦æä¾›è¼¸å…¥è·¯å¾‘ (--input)")
            
            dataset_id = data_system.load_dataset(args.input)
            print(f"âœ… æ•¸æ“šé›†å·²è¼‰å…¥: {dataset_id}")
            
        elif args.action == 'export':
            if not args.dataset_id or not args.output:
                raise ValueError("å°å‡ºæ•¸æ“šé›†éœ€è¦æä¾›æ•¸æ“šé›†IDå’Œè¼¸å‡ºè·¯å¾‘")
            
            export_file = data_system.export_dataset(args.dataset_id, args.output)
            print(f"âœ… æ•¸æ“šé›†å·²å°å‡º: {export_file}")
            
        elif args.action == 'info':
            if not args.dataset_id:
                raise ValueError("æŸ¥çœ‹æ•¸æ“šé›†ä¿¡æ¯éœ€è¦æä¾›æ•¸æ“šé›†ID")
            
            info = data_system.get_dataset_info(args.dataset_id)
            print(json.dumps(info, indent=2, ensure_ascii=False))
            
        elif args.action == 'list':
            datasets = data_system.list_datasets()
            print(json.dumps(datasets, indent=2, ensure_ascii=False))
            
    except Exception as e:
        logger.error(f"âŒ æ“ä½œå¤±æ•—: {e}")
        raise



# è‡ªå‹•æª¢æ¸¬å’Œåˆ‡æ›åˆ° TradingAgents ç›®éŒ„
def ensure_tradingagents_directory():
    """ç¢ºä¿ç•¶å‰å·¥ä½œç›®éŒ„åœ¨ TradingAgents/ ä¸‹ï¼Œä»¥æ­£ç¢ºè¨ªå•é…ç½®æ–‡ä»¶"""
    current_dir = Path.cwd()
    
    # å¦‚æœç•¶å‰ç›®éŒ„æ˜¯ TradingAgents çš„çˆ¶ç›®éŒ„ï¼Œåˆ‡æ›åˆ° TradingAgents
    if (current_dir / 'TradingAgents').exists():
        os.chdir(current_dir / 'TradingAgents')
        print(f"[DIR] è‡ªå‹•åˆ‡æ›å·¥ä½œç›®éŒ„åˆ°: {Path.cwd()}")
    
    # é©—è­‰å¿…è¦çš„ç›®éŒ„å­˜åœ¨
    required_dirs = ['configs', 'training', 'tradingagents']
    missing_dirs = [d for d in required_dirs if not Path(d).exists()]
    
    if missing_dirs:
        raise FileNotFoundError(f"ç¼ºå°‘å¿…è¦ç›®éŒ„: {missing_dirs}. è«‹ç¢ºä¿å¾ TradingAgents/ ç›®éŒ„åŸ·è¡Œæ­¤è…³æœ¬")

# ç›®éŒ„æª¢æŸ¥å‡½æ•¸å·²æº–å‚™å¥½ï¼Œä½†ä¸åœ¨æ¨¡çµ„å°å…¥æ™‚è‡ªå‹•åŸ·è¡Œ
# åªåœ¨éœ€è¦æ™‚æ‰‹å‹•èª¿ç”¨ ensure_tradingagents_directory()

if __name__ == "__main__":
    # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
    os.makedirs('/app/logs/training', exist_ok=True)
    
    # é‹è¡Œä¸»å‡½æ•¸
    main()