"""
Performance Prediction and Routing Decision System
æ€§èƒ½é æ¸¬å’Œè·¯ç”±æ±ºç­–ç³»çµ±

ä»»å‹™6.3: æ€§èƒ½é æ¸¬å’Œè·¯ç”±æ±ºç­–
è² è²¬äºº: å°k (AIè¨“ç·´å°ˆå®¶åœ˜éšŠ)

æä¾›ï¼š
- æ€§èƒ½é æ¸¬æ¨¡å‹
- æ™ºèƒ½è·¯ç”±æ±ºç­–
- è² è¼‰é æ¸¬å’Œå®¹é‡è¦åŠƒ
- æ€§èƒ½å„ªåŒ–å»ºè­°
- å‹•æ…‹è³‡æºåˆ†é…
"""

import os
import json
import logging
import numpy as np
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
from enum import Enum
import pickle
from collections import deque, defaultdict
import threading
import time

from .task_analyzer import TaskAnalysisResult, TaskType, TaskComplexity, ResourceRequirement
from .cost_calculator import CostComparisonResult, DeploymentMode

logger = logging.getLogger(__name__)

class PerformanceMetric(Enum):
    """æ€§èƒ½æŒ‡æ¨™æšèˆ‰"""
    THROUGHPUT = "throughput"           # ååé‡
    LATENCY = "latency"                # å»¶é²
    GPU_UTILIZATION = "gpu_utilization" # GPUåˆ©ç”¨ç‡
    MEMORY_USAGE = "memory_usage"       # è¨˜æ†¶é«”ä½¿ç”¨ç‡
    ENERGY_EFFICIENCY = "energy_efficiency"  # èƒ½æ•ˆ
    COST_EFFICIENCY = "cost_efficiency"      # æˆæœ¬æ•ˆç‡
    QUALITY_SCORE = "quality_score"          # è³ªé‡è©•åˆ†

class PredictionModel(Enum):
    """é æ¸¬æ¨¡å‹é¡å‹æšèˆ‰"""
    LINEAR_REGRESSION = "linear_regression"
    POLYNOMIAL_REGRESSION = "polynomial_regression"
    EXPONENTIAL_SMOOTHING = "exponential_smoothing"
    ARIMA = "arima"
    NEURAL_NETWORK = "neural_network"

class RoutingStrategy(Enum):
    """è·¯ç”±ç­–ç•¥æšèˆ‰"""
    COST_OPTIMAL = "cost_optimal"           # æˆæœ¬æœ€å„ª
    PERFORMANCE_OPTIMAL = "performance_optimal"  # æ€§èƒ½æœ€å„ª
    BALANCED = "balanced"                   # å¹³è¡¡ç­–ç•¥
    ADAPTIVE = "adaptive"                   # è‡ªé©æ‡‰ç­–ç•¥
    LOAD_BALANCED = "load_balanced"         # è² è¼‰å‡è¡¡

@dataclass
class PerformanceData:
    """æ€§èƒ½æ•¸æ“šçµæ§‹"""
    timestamp: datetime
    task_type: TaskType
    deployment_mode: DeploymentMode
    throughput_requests_per_hour: float
    latency_seconds: float
    gpu_utilization_percent: float
    memory_usage_percent: float
    energy_consumption_watts: float
    cost_per_request: float
    quality_score: float
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['timestamp'] = self.timestamp.isoformat()
        result['task_type'] = self.task_type.value
        result['deployment_mode'] = self.deployment_mode.value
        return result

@dataclass
class PerformancePrediction:
    """æ€§èƒ½é æ¸¬çµæœ"""
    metric: PerformanceMetric
    predicted_value: float
    confidence_interval: Tuple[float, float]
    prediction_accuracy: float
    prediction_timestamp: datetime
    prediction_horizon_hours: float
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['metric'] = self.metric.value
        result['prediction_timestamp'] = self.prediction_timestamp.isoformat()
        return result

@dataclass
class RoutingDecision:
    """è·¯ç”±æ±ºç­–çµæœ"""
    task_id: str
    recommended_deployment: DeploymentMode
    confidence_score: float
    expected_performance: Dict[str, float]
    expected_cost: float
    decision_factors: Dict[str, float]
    alternative_options: List[Dict[str, Any]]
    decision_timestamp: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['recommended_deployment'] = self.recommended_deployment.value
        result['decision_timestamp'] = self.decision_timestamp.isoformat()
        return result

@dataclass
class LoadForecast:
    """è² è¼‰é æ¸¬çµæœ"""
    forecast_timestamp: datetime
    forecast_horizon_hours: float
    predicted_load: Dict[str, float]  # å„æ™‚é–“é»çš„é æ¸¬è² è¼‰
    peak_load_time: datetime
    peak_load_value: float
    capacity_recommendations: List[str]
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['forecast_timestamp'] = self.forecast_timestamp.isoformat()
        result['peak_load_time'] = self.peak_load_time.isoformat()
        return result

class PerformancePredictor:
    """æ€§èƒ½é æ¸¬å™¨"""
    
    def __init__(self, history_size: int = 1000):
        self.history_size = history_size
        self.performance_history = deque(maxlen=history_size)
        self.prediction_models = {}
        self.model_accuracy = defaultdict(float)
        self.lock = threading.Lock()
        
        # é æ¸¬æ¨¡å‹åƒæ•¸
        self.smoothing_alpha = 0.3  # æŒ‡æ•¸å¹³æ»‘åƒæ•¸
        self.trend_beta = 0.1       # è¶¨å‹¢å¹³æ»‘åƒæ•¸
        self.seasonal_gamma = 0.1   # å­£ç¯€æ€§å¹³æ»‘åƒæ•¸
    
    def add_performance_data(self, data: PerformanceData):
        """æ·»åŠ æ€§èƒ½æ•¸æ“š"""
        with self.lock:
            self.performance_history.append(data)
            logger.debug(f"æ·»åŠ æ€§èƒ½æ•¸æ“š: {data.task_type.value} - {data.deployment_mode.value}")
    
    def get_historical_data(
        self,
        task_type: Optional[TaskType] = None,
        deployment_mode: Optional[DeploymentMode] = None,
        hours_back: Optional[float] = None
    ) -> List[PerformanceData]:
        """ç²å–æ­·å²æ•¸æ“š"""
        with self.lock:
            filtered_data = list(self.performance_history)
        
        # æŒ‰ä»»å‹™é¡å‹éæ¿¾
        if task_type:
            filtered_data = [d for d in filtered_data if d.task_type == task_type]
        
        # æŒ‰éƒ¨ç½²æ¨¡å¼éæ¿¾
        if deployment_mode:
            filtered_data = [d for d in filtered_data if d.deployment_mode == deployment_mode]
        
        # æŒ‰æ™‚é–“éæ¿¾
        if hours_back:
            cutoff_time = datetime.now() - timedelta(hours=hours_back)
            filtered_data = [d for d in filtered_data if d.timestamp >= cutoff_time]
        
        return filtered_data
    
    def predict_performance(
        self,
        metric: PerformanceMetric,
        task_type: TaskType,
        deployment_mode: DeploymentMode,
        prediction_horizon_hours: float = 1.0,
        model_type: PredictionModel = PredictionModel.EXPONENTIAL_SMOOTHING
    ) -> PerformancePrediction:
        """é æ¸¬æ€§èƒ½æŒ‡æ¨™"""
        # ç²å–æ­·å²æ•¸æ“š
        historical_data = self.get_historical_data(task_type, deployment_mode, hours_back=168)  # ä¸€é€±æ•¸æ“š
        
        if len(historical_data) < 3:
            # æ•¸æ“šä¸è¶³ï¼Œä½¿ç”¨é»˜èªé æ¸¬
            return self._default_prediction(metric, task_type, deployment_mode, prediction_horizon_hours)
        
        # æå–æŒ‡æ¨™å€¼
        values = self._extract_metric_values(historical_data, metric)
        
        # æ ¹æ“šæ¨¡å‹é¡å‹é€²è¡Œé æ¸¬
        if model_type == PredictionModel.EXPONENTIAL_SMOOTHING:
            prediction = self._exponential_smoothing_prediction(values, prediction_horizon_hours)
        elif model_type == PredictionModel.LINEAR_REGRESSION:
            prediction = self._linear_regression_prediction(values, prediction_horizon_hours)
        elif model_type == PredictionModel.POLYNOMIAL_REGRESSION:
            prediction = self._polynomial_regression_prediction(values, prediction_horizon_hours)
        else:
            prediction = self._exponential_smoothing_prediction(values, prediction_horizon_hours)
        
        # è¨ˆç®—ç½®ä¿¡å€é–“
        confidence_interval = self._calculate_confidence_interval(values, prediction, 0.95)
        
        # è©•ä¼°é æ¸¬æº–ç¢ºæ€§
        accuracy = self._evaluate_prediction_accuracy(metric, task_type, deployment_mode)
        
        return PerformancePrediction(
            metric=metric,
            predicted_value=prediction,
            confidence_interval=confidence_interval,
            prediction_accuracy=accuracy,
            prediction_timestamp=datetime.now(),
            prediction_horizon_hours=prediction_horizon_hours
        )
    
    def _extract_metric_values(self, data: List[PerformanceData], metric: PerformanceMetric) -> List[float]:
        """æå–æŒ‡æ¨™å€¼"""
        if metric == PerformanceMetric.THROUGHPUT:
            return [d.throughput_requests_per_hour for d in data]
        elif metric == PerformanceMetric.LATENCY:
            return [d.latency_seconds for d in data]
        elif metric == PerformanceMetric.GPU_UTILIZATION:
            return [d.gpu_utilization_percent for d in data]
        elif metric == PerformanceMetric.MEMORY_USAGE:
            return [d.memory_usage_percent for d in data]
        elif metric == PerformanceMetric.ENERGY_EFFICIENCY:
            return [d.throughput_requests_per_hour / d.energy_consumption_watts if d.energy_consumption_watts > 0 else 0 for d in data]
        elif metric == PerformanceMetric.COST_EFFICIENCY:
            return [1 / d.cost_per_request if d.cost_per_request > 0 else 0 for d in data]
        elif metric == PerformanceMetric.QUALITY_SCORE:
            return [d.quality_score for d in data]
        else:
            return [0.0] * len(data)
    
    def _exponential_smoothing_prediction(self, values: List[float], horizon_hours: float) -> float:
        """æŒ‡æ•¸å¹³æ»‘é æ¸¬"""
        if not values:
            return 0.0
        
        # ç°¡å–®æŒ‡æ•¸å¹³æ»‘
        smoothed = values[0]
        for value in values[1:]:
            smoothed = self.smoothing_alpha * value + (1 - self.smoothing_alpha) * smoothed
        
        # è€ƒæ…®è¶¨å‹¢
        if len(values) >= 2:
            trend = (values[-1] - values[-2]) * self.trend_beta
            prediction = smoothed + trend * horizon_hours
        else:
            prediction = smoothed
        
        return max(0, prediction)  # ç¢ºä¿éè² å€¼
    
    def _linear_regression_prediction(self, values: List[float], horizon_hours: float) -> float:
        """ç·šæ€§å›æ­¸é æ¸¬"""
        if len(values) < 2:
            return values[0] if values else 0.0
        
        # ç°¡å–®ç·šæ€§å›æ­¸
        n = len(values)
        x = np.arange(n)
        y = np.array(values)
        
        # è¨ˆç®—æ–œç‡å’Œæˆªè·
        x_mean = np.mean(x)
        y_mean = np.mean(y)
        
        numerator = np.sum((x - x_mean) * (y - y_mean))
        denominator = np.sum((x - x_mean) ** 2)
        
        if denominator == 0:
            return y_mean
        
        slope = numerator / denominator
        intercept = y_mean - slope * x_mean
        
        # é æ¸¬
        future_x = n + horizon_hours - 1
        prediction = slope * future_x + intercept
        
        return max(0, prediction)
    
    def _polynomial_regression_prediction(self, values: List[float], horizon_hours: float) -> float:
        """å¤šé …å¼å›æ­¸é æ¸¬"""
        if len(values) < 3:
            return self._linear_regression_prediction(values, horizon_hours)
        
        # äºŒæ¬¡å¤šé …å¼æ“¬åˆ
        x = np.arange(len(values))
        y = np.array(values)
        
        try:
            coeffs = np.polyfit(x, y, 2)
            future_x = len(values) + horizon_hours - 1
            prediction = np.polyval(coeffs, future_x)
            return max(0, prediction)
        except:
            # å¦‚æœå¤šé …å¼æ“¬åˆå¤±æ•—ï¼Œå›é€€åˆ°ç·šæ€§å›æ­¸
            return self._linear_regression_prediction(values, horizon_hours)
    
    def _calculate_confidence_interval(
        self,
        values: List[float],
        prediction: float,
        confidence_level: float = 0.95
    ) -> Tuple[float, float]:
        """è¨ˆç®—ç½®ä¿¡å€é–“"""
        if len(values) < 2:
            margin = prediction * 0.1  # 10%çš„é‚Šéš›
            return (max(0, prediction - margin), prediction + margin)
        
        # è¨ˆç®—æ¨™æº–å·®
        std_dev = np.std(values)
        
        # è¨ˆç®—ç½®ä¿¡å€é–“
        z_score = 1.96 if confidence_level == 0.95 else 2.58  # 95%æˆ–99%ç½®ä¿¡åº¦
        margin = z_score * std_dev / np.sqrt(len(values))
        
        lower_bound = max(0, prediction - margin)
        upper_bound = prediction + margin
        
        return (lower_bound, upper_bound)
    
    def _evaluate_prediction_accuracy(
        self,
        metric: PerformanceMetric,
        task_type: TaskType,
        deployment_mode: DeploymentMode
    ) -> float:
        """è©•ä¼°é æ¸¬æº–ç¢ºæ€§"""
        key = f"{metric.value}_{task_type.value}_{deployment_mode.value}"
        
        # å¦‚æœæœ‰æ­·å²æº–ç¢ºæ€§è¨˜éŒ„ï¼Œè¿”å›è©²å€¼
        if key in self.model_accuracy:
            return self.model_accuracy[key]
        
        # å¦å‰‡è¿”å›é»˜èªæº–ç¢ºæ€§
        return 0.8  # 80%çš„é»˜èªæº–ç¢ºæ€§
    
    def _default_prediction(
        self,
        metric: PerformanceMetric,
        task_type: TaskType,
        deployment_mode: DeploymentMode,
        prediction_horizon_hours: float
    ) -> PerformancePrediction:
        """é»˜èªé æ¸¬ï¼ˆç•¶æ•¸æ“šä¸è¶³æ™‚ï¼‰"""
        # åŸºæ–¼ä»»å‹™é¡å‹å’Œéƒ¨ç½²æ¨¡å¼çš„é»˜èªå€¼
        default_values = {
            (PerformanceMetric.THROUGHPUT, TaskType.TRAINING, DeploymentMode.LOCAL_GPU): 50.0,
            (PerformanceMetric.THROUGHPUT, TaskType.INFERENCE, DeploymentMode.LOCAL_GPU): 200.0,
            (PerformanceMetric.LATENCY, TaskType.TRAINING, DeploymentMode.LOCAL_GPU): 2.0,
            (PerformanceMetric.LATENCY, TaskType.INFERENCE, DeploymentMode.LOCAL_GPU): 0.5,
            (PerformanceMetric.GPU_UTILIZATION, TaskType.TRAINING, DeploymentMode.LOCAL_GPU): 85.0,
            (PerformanceMetric.MEMORY_USAGE, TaskType.TRAINING, DeploymentMode.LOCAL_GPU): 70.0,
        }
        
        key = (metric, task_type, deployment_mode)
        default_value = default_values.get(key, 50.0)
        
        return PerformancePrediction(
            metric=metric,
            predicted_value=default_value,
            confidence_interval=(default_value * 0.8, default_value * 1.2),
            prediction_accuracy=0.6,  # è¼ƒä½çš„æº–ç¢ºæ€§ï¼Œå› ç‚ºæ˜¯é»˜èªå€¼
            prediction_timestamp=datetime.now(),
            prediction_horizon_hours=prediction_horizon_hours
        )

class LoadForecaster:
    """è² è¼‰é æ¸¬å™¨"""
    
    def __init__(self):
        self.load_history = deque(maxlen=2000)  # ä¿å­˜æ›´å¤šè² è¼‰æ­·å²
        self.seasonal_patterns = {}  # å­£ç¯€æ€§æ¨¡å¼
        self.lock = threading.Lock()
    
    def add_load_data(self, timestamp: datetime, load_value: float, task_type: TaskType):
        """æ·»åŠ è² è¼‰æ•¸æ“š"""
        with self.lock:
            self.load_history.append({
                'timestamp': timestamp,
                'load': load_value,
                'task_type': task_type,
                'hour_of_day': timestamp.hour,
                'day_of_week': timestamp.weekday(),
                'day_of_month': timestamp.day
            })
    
    def forecast_load(
        self,
        forecast_horizon_hours: float = 24.0,
        task_type: Optional[TaskType] = None
    ) -> LoadForecast:
        """é æ¸¬è² è¼‰"""
        with self.lock:
            historical_data = list(self.load_history)
        
        # éæ¿¾ä»»å‹™é¡å‹
        if task_type:
            historical_data = [d for d in historical_data if d['task_type'] == task_type]
        
        if len(historical_data) < 24:  # è‡³å°‘éœ€è¦24å°æ™‚çš„æ•¸æ“š
            return self._default_load_forecast(forecast_horizon_hours)
        
        # åˆ†æå­£ç¯€æ€§æ¨¡å¼
        hourly_patterns = self._analyze_hourly_patterns(historical_data)
        daily_patterns = self._analyze_daily_patterns(historical_data)
        
        # ç”Ÿæˆé æ¸¬
        forecast_points = {}
        current_time = datetime.now()
        
        for i in range(int(forecast_horizon_hours)):
            future_time = current_time + timedelta(hours=i)
            
            # åŸºæ–¼å°æ™‚æ¨¡å¼é æ¸¬
            hour_factor = hourly_patterns.get(future_time.hour, 1.0)
            
            # åŸºæ–¼æ˜ŸæœŸæ¨¡å¼é æ¸¬
            day_factor = daily_patterns.get(future_time.weekday(), 1.0)
            
            # åŸºç¤è² è¼‰ï¼ˆæœ€è¿‘çš„å¹³å‡å€¼ï¼‰
            recent_loads = [d['load'] for d in historical_data[-24:]]  # æœ€è¿‘24å°æ™‚
            base_load = np.mean(recent_loads) if recent_loads else 50.0
            
            # çµ„åˆé æ¸¬
            predicted_load = base_load * hour_factor * day_factor
            forecast_points[future_time.isoformat()] = predicted_load
        
        # æ‰¾åˆ°å³°å€¼è² è¼‰
        peak_load_value = max(forecast_points.values())
        peak_load_time = max(forecast_points.keys(), key=lambda k: forecast_points[k])
        peak_load_time = datetime.fromisoformat(peak_load_time)
        
        # ç”Ÿæˆå®¹é‡å»ºè­°
        capacity_recommendations = self._generate_capacity_recommendations(
            forecast_points, peak_load_value
        )
        
        return LoadForecast(
            forecast_timestamp=datetime.now(),
            forecast_horizon_hours=forecast_horizon_hours,
            predicted_load=forecast_points,
            peak_load_time=peak_load_time,
            peak_load_value=peak_load_value,
            capacity_recommendations=capacity_recommendations
        )
    
    def _analyze_hourly_patterns(self, data: List[Dict]) -> Dict[int, float]:
        """åˆ†æå°æ™‚æ¨¡å¼"""
        hourly_loads = defaultdict(list)
        
        for record in data:
            hourly_loads[record['hour_of_day']].append(record['load'])
        
        # è¨ˆç®—æ¯å°æ™‚çš„å¹³å‡è² è¼‰ä¿‚æ•¸
        overall_mean = np.mean([record['load'] for record in data])
        hourly_factors = {}
        
        for hour in range(24):
            if hour in hourly_loads:
                hour_mean = np.mean(hourly_loads[hour])
                hourly_factors[hour] = hour_mean / overall_mean if overall_mean > 0 else 1.0
            else:
                hourly_factors[hour] = 1.0
        
        return hourly_factors
    
    def _analyze_daily_patterns(self, data: List[Dict]) -> Dict[int, float]:
        """åˆ†ææ¯æ—¥æ¨¡å¼"""
        daily_loads = defaultdict(list)
        
        for record in data:
            daily_loads[record['day_of_week']].append(record['load'])
        
        # è¨ˆç®—æ¯å¤©çš„å¹³å‡è² è¼‰ä¿‚æ•¸
        overall_mean = np.mean([record['load'] for record in data])
        daily_factors = {}
        
        for day in range(7):  # 0=Monday, 6=Sunday
            if day in daily_loads:
                day_mean = np.mean(daily_loads[day])
                daily_factors[day] = day_mean / overall_mean if overall_mean > 0 else 1.0
            else:
                daily_factors[day] = 1.0
        
        return daily_factors
    
    def _generate_capacity_recommendations(
        self,
        forecast_points: Dict[str, float],
        peak_load: float
    ) -> List[str]:
        """ç”Ÿæˆå®¹é‡å»ºè­°"""
        recommendations = []
        
        # åˆ†æè² è¼‰è®ŠåŒ–
        loads = list(forecast_points.values())
        avg_load = np.mean(loads)
        load_variance = np.var(loads)
        
        if peak_load > avg_load * 1.5:
            recommendations.append("æª¢æ¸¬åˆ°é«˜å³°è² è¼‰ï¼Œå»ºè­°å¢åŠ è¨ˆç®—è³‡æº")
        
        if load_variance > avg_load * 0.5:
            recommendations.append("è² è¼‰æ³¢å‹•è¼ƒå¤§ï¼Œå»ºè­°å¯¦æ–½è‡ªå‹•æ“´ç¸®å®¹")
        
        if peak_load > 100:  # å‡è¨­100æ˜¯é«˜è² è¼‰é–¾å€¼
            recommendations.append("é æ¸¬è² è¼‰è¼ƒé«˜ï¼Œå»ºè­°æå‰æº–å‚™é¡å¤–çš„GPUè³‡æº")
        
        if avg_load < 20:  # å‡è¨­20æ˜¯ä½è² è¼‰é–¾å€¼
            recommendations.append("é æ¸¬è² è¼‰è¼ƒä½ï¼Œå¯ä»¥è€ƒæ…®è³‡æºæ•´åˆä»¥ç¯€çœæˆæœ¬")
        
        return recommendations
    
    def _default_load_forecast(self, forecast_horizon_hours: float) -> LoadForecast:
        """é»˜èªè² è¼‰é æ¸¬"""
        # ç”Ÿæˆç°¡å–®çš„è² è¼‰æ¨¡å¼ï¼ˆå·¥ä½œæ™‚é–“é«˜ï¼Œéå·¥ä½œæ™‚é–“ä½ï¼‰
        forecast_points = {}
        current_time = datetime.now()
        
        for i in range(int(forecast_horizon_hours)):
            future_time = current_time + timedelta(hours=i)
            
            # ç°¡å–®çš„å·¥ä½œæ™‚é–“æ¨¡å¼
            if 9 <= future_time.hour <= 17:  # å·¥ä½œæ™‚é–“
                load = 80.0
            elif 18 <= future_time.hour <= 22:  # æ™šä¸Š
                load = 60.0
            else:  # æ·±å¤œå’Œæ—©æ™¨
                load = 30.0
            
            forecast_points[future_time.isoformat()] = load
        
        peak_load_value = max(forecast_points.values())
        peak_load_time = max(forecast_points.keys(), key=lambda k: forecast_points[k])
        peak_load_time = datetime.fromisoformat(peak_load_time)
        
        return LoadForecast(
            forecast_timestamp=datetime.now(),
            forecast_horizon_hours=forecast_horizon_hours,
            predicted_load=forecast_points,
            peak_load_time=peak_load_time,
            peak_load_value=peak_load_value,
            capacity_recommendations=["ä½¿ç”¨é»˜èªè² è¼‰æ¨¡å¼ï¼Œå»ºè­°æ”¶é›†æ›´å¤šæ­·å²æ•¸æ“šä»¥æé«˜é æ¸¬æº–ç¢ºæ€§"]
        )

class RoutingDecisionEngine:
    """è·¯ç”±æ±ºç­–å¼•æ“"""
    
    def __init__(self):
        self.performance_predictor = PerformancePredictor()
        self.load_forecaster = LoadForecaster()
        self.decision_history = deque(maxlen=1000)
        self.strategy_weights = {
            RoutingStrategy.COST_OPTIMAL: {'cost': 0.8, 'performance': 0.2},
            RoutingStrategy.PERFORMANCE_OPTIMAL: {'cost': 0.2, 'performance': 0.8},
            RoutingStrategy.BALANCED: {'cost': 0.5, 'performance': 0.5},
            RoutingStrategy.ADAPTIVE: {'cost': 0.4, 'performance': 0.4, 'load': 0.2}
        }
    
    def make_routing_decision(
        self,
        task_analysis: TaskAnalysisResult,
        cost_comparison: CostComparisonResult,
        strategy: RoutingStrategy = RoutingStrategy.BALANCED,
        current_load: Optional[float] = None
    ) -> RoutingDecision:
        """åšå‡ºè·¯ç”±æ±ºç­–"""
        logger.info(f"ğŸ¯ é–‹å§‹è·¯ç”±æ±ºç­–: {task_analysis.task_name}")
        
        # é æ¸¬å„éƒ¨ç½²æ¨¡å¼çš„æ€§èƒ½
        performance_predictions = self._predict_deployment_performance(task_analysis)
        
        # è¨ˆç®—æ±ºç­–å› ç´ 
        decision_factors = self._calculate_decision_factors(
            task_analysis, cost_comparison, performance_predictions, current_load
        )
        
        # æ ¹æ“šç­–ç•¥è¨ˆç®—è©•åˆ†
        deployment_scores = self._calculate_deployment_scores(
            decision_factors, strategy
        )
        
        # é¸æ“‡æœ€ä½³éƒ¨ç½²æ¨¡å¼
        recommended_deployment = max(deployment_scores, key=deployment_scores.get)
        confidence_score = deployment_scores[recommended_deployment]
        
        # ç”Ÿæˆæ›¿ä»£é¸é …
        alternative_options = self._generate_alternatives(deployment_scores, decision_factors)
        
        # é æœŸæ€§èƒ½å’Œæˆæœ¬
        expected_performance = performance_predictions.get(recommended_deployment, {})
        expected_cost = self._get_expected_cost(cost_comparison, recommended_deployment)
        
        decision = RoutingDecision(
            task_id=task_analysis.task_id,
            recommended_deployment=recommended_deployment,
            confidence_score=confidence_score,
            expected_performance=expected_performance,
            expected_cost=expected_cost,
            decision_factors=decision_factors,
            alternative_options=alternative_options,
            decision_timestamp=datetime.now()
        )
        
        # è¨˜éŒ„æ±ºç­–æ­·å²
        self.decision_history.append(decision)
        
        logger.info(f"âœ… è·¯ç”±æ±ºç­–å®Œæˆ: {recommended_deployment.value}, ä¿¡å¿ƒåº¦: {confidence_score:.2f}")
        return decision
    
    def _predict_deployment_performance(
        self,
        task_analysis: TaskAnalysisResult
    ) -> Dict[DeploymentMode, Dict[str, float]]:
        """é æ¸¬å„éƒ¨ç½²æ¨¡å¼çš„æ€§èƒ½"""
        predictions = {}
        
        for deployment_mode in [DeploymentMode.LOCAL_GPU, DeploymentMode.CLOUD_API, DeploymentMode.HYBRID]:
            mode_predictions = {}
            
            # é æ¸¬å„é …æ€§èƒ½æŒ‡æ¨™
            for metric in [PerformanceMetric.THROUGHPUT, PerformanceMetric.LATENCY, 
                          PerformanceMetric.GPU_UTILIZATION, PerformanceMetric.QUALITY_SCORE]:
                try:
                    prediction = self.performance_predictor.predict_performance(
                        metric, task_analysis.task_type, deployment_mode
                    )
                    mode_predictions[metric.value] = prediction.predicted_value
                except Exception as e:
                    logger.warning(f"æ€§èƒ½é æ¸¬å¤±æ•— {metric.value}: {e}")
                    mode_predictions[metric.value] = 0.0
            
            predictions[deployment_mode] = mode_predictions
        
        return predictions
    
    def _calculate_decision_factors(
        self,
        task_analysis: TaskAnalysisResult,
        cost_comparison: CostComparisonResult,
        performance_predictions: Dict[DeploymentMode, Dict[str, float]],
        current_load: Optional[float]
    ) -> Dict[str, float]:
        """è¨ˆç®—æ±ºç­–å› ç´ """
        factors = {}
        
        # æˆæœ¬å› ç´ 
        factors['local_gpu_cost'] = float(cost_comparison.local_gpu_cost.total_cost)
        factors['cloud_api_cost'] = float(cost_comparison.cloud_api_cost.total_cost)
        factors['hybrid_cost'] = float(cost_comparison.hybrid_cost.total_cost)
        factors['cost_savings'] = float(cost_comparison.cost_savings)
        
        # æ€§èƒ½å› ç´ 
        for deployment_mode in performance_predictions:
            prefix = deployment_mode.value
            perf_data = performance_predictions[deployment_mode]
            
            factors[f'{prefix}_throughput'] = perf_data.get('throughput', 0.0)
            factors[f'{prefix}_latency'] = perf_data.get('latency', 0.0)
            factors[f'{prefix}_gpu_utilization'] = perf_data.get('gpu_utilization', 0.0)
            factors[f'{prefix}_quality_score'] = perf_data.get('quality_score', 0.0)
        
        # ä»»å‹™ç‰¹æ€§å› ç´ 
        factors['task_complexity'] = task_analysis.complexity.value
        factors['task_priority'] = task_analysis.priority.value
        factors['estimated_duration'] = task_analysis.estimated_duration
        factors['analysis_confidence'] = task_analysis.analysis_confidence
        
        # è³‡æºéœ€æ±‚å› ç´ 
        req = task_analysis.resource_requirements
        factors['gpu_memory_requirement'] = req.gpu_memory_gb
        factors['cpu_cores_requirement'] = req.cpu_cores
        factors['estimated_time_requirement'] = req.estimated_time_hours
        
        # ç•¶å‰è² è¼‰å› ç´ 
        factors['current_load'] = current_load if current_load is not None else 50.0
        
        # é¢¨éšªå› ç´ 
        factors['risk_count'] = len(task_analysis.risk_factors)
        factors['has_high_complexity_risk'] = 1.0 if 'high_complexity_risk' in task_analysis.risk_factors else 0.0
        factors['has_resource_risk'] = 1.0 if 'resource_risk' in task_analysis.risk_factors else 0.0
        
        return factors
    
    def _calculate_deployment_scores(
        self,
        factors: Dict[str, float],
        strategy: RoutingStrategy
    ) -> Dict[DeploymentMode, float]:
        """è¨ˆç®—å„éƒ¨ç½²æ¨¡å¼çš„è©•åˆ†"""
        scores = {}
        
        for deployment_mode in [DeploymentMode.LOCAL_GPU, DeploymentMode.CLOUD_API, DeploymentMode.HYBRID]:
            score = 0.0
            
            if strategy == RoutingStrategy.COST_OPTIMAL:
                # æˆæœ¬æœ€å„ªç­–ç•¥
                if deployment_mode == DeploymentMode.LOCAL_GPU:
                    score = 1.0 / (factors['local_gpu_cost'] + 1.0)
                elif deployment_mode == DeploymentMode.CLOUD_API:
                    score = 1.0 / (factors['cloud_api_cost'] + 1.0)
                else:  # HYBRID
                    score = 1.0 / (factors['hybrid_cost'] + 1.0)
                
                # è€ƒæ…®æˆæœ¬ç¯€çœ
                if factors['cost_savings'] > 0:
                    score *= 1.2
            
            elif strategy == RoutingStrategy.PERFORMANCE_OPTIMAL:
                # æ€§èƒ½æœ€å„ªç­–ç•¥
                prefix = deployment_mode.value
                throughput = factors.get(f'{prefix}_throughput', 0.0)
                latency = factors.get(f'{prefix}_latency', 1.0)
                quality = factors.get(f'{prefix}_quality_score', 0.0)
                
                # ååé‡è¶Šé«˜è¶Šå¥½ï¼Œå»¶é²è¶Šä½è¶Šå¥½ï¼Œè³ªé‡è¶Šé«˜è¶Šå¥½
                score = (throughput * 0.4) + (1.0 / (latency + 0.1) * 0.3) + (quality * 0.3)
            
            elif strategy == RoutingStrategy.BALANCED:
                # å¹³è¡¡ç­–ç•¥
                # æˆæœ¬è©•åˆ†ï¼ˆæˆæœ¬è¶Šä½è©•åˆ†è¶Šé«˜ï¼‰
                if deployment_mode == DeploymentMode.LOCAL_GPU:
                    cost_score = 1.0 / (factors['local_gpu_cost'] + 1.0)
                elif deployment_mode == DeploymentMode.CLOUD_API:
                    cost_score = 1.0 / (factors['cloud_api_cost'] + 1.0)
                else:
                    cost_score = 1.0 / (factors['hybrid_cost'] + 1.0)
                
                # æ€§èƒ½è©•åˆ†
                prefix = deployment_mode.value
                throughput = factors.get(f'{prefix}_throughput', 0.0)
                latency = factors.get(f'{prefix}_latency', 1.0)
                quality = factors.get(f'{prefix}_quality_score', 0.0)
                
                perf_score = (throughput * 0.4) + (1.0 / (latency + 0.1) * 0.3) + (quality * 0.3)
                
                # å¹³è¡¡æˆæœ¬å’Œæ€§èƒ½
                score = cost_score * 0.5 + perf_score * 0.5
            
            elif strategy == RoutingStrategy.ADAPTIVE:
                # è‡ªé©æ‡‰ç­–ç•¥
                # æ ¹æ“šä»»å‹™ç‰¹æ€§å‹•æ…‹èª¿æ•´æ¬Šé‡
                task_priority = factors['task_priority']
                current_load = factors['current_load']
                
                # é«˜å„ªå…ˆç´šä»»å‹™æ›´æ³¨é‡æ€§èƒ½
                if task_priority >= 4:  # URGENTæˆ–CRITICAL
                    perf_weight = 0.7
                    cost_weight = 0.3
                else:
                    perf_weight = 0.4
                    cost_weight = 0.6
                
                # é«˜è² è¼‰æ™‚æ›´æ³¨é‡æˆæœ¬æ•ˆç‡
                if current_load > 80:
                    cost_weight += 0.1
                    perf_weight -= 0.1
                
                # è¨ˆç®—è©•åˆ†
                if deployment_mode == DeploymentMode.LOCAL_GPU:
                    cost_score = 1.0 / (factors['local_gpu_cost'] + 1.0)
                elif deployment_mode == DeploymentMode.CLOUD_API:
                    cost_score = 1.0 / (factors['cloud_api_cost'] + 1.0)
                else:
                    cost_score = 1.0 / (factors['hybrid_cost'] + 1.0)
                
                prefix = deployment_mode.value
                throughput = factors.get(f'{prefix}_throughput', 0.0)
                latency = factors.get(f'{prefix}_latency', 1.0)
                quality = factors.get(f'{prefix}_quality_score', 0.0)
                
                perf_score = (throughput * 0.4) + (1.0 / (latency + 0.1) * 0.3) + (quality * 0.3)
                
                score = cost_score * cost_weight + perf_score * perf_weight
            
            else:  # LOAD_BALANCED
                # è² è¼‰å‡è¡¡ç­–ç•¥
                current_load = factors['current_load']
                
                # æ ¹æ“šç•¶å‰è² è¼‰é¸æ“‡éƒ¨ç½²æ¨¡å¼
                if current_load < 30:  # ä½è² è¼‰
                    if deployment_mode == DeploymentMode.LOCAL_GPU:
                        score = 0.8
                    else:
                        score = 0.6
                elif current_load > 80:  # é«˜è² è¼‰
                    if deployment_mode == DeploymentMode.HYBRID:
                        score = 0.9
                    elif deployment_mode == DeploymentMode.CLOUD_API:
                        score = 0.7
                    else:
                        score = 0.5
                else:  # ä¸­ç­‰è² è¼‰
                    if deployment_mode == DeploymentMode.HYBRID:
                        score = 0.8
                    else:
                        score = 0.7
            
            # æ‡‰ç”¨é¢¨éšªèª¿æ•´
            if factors['has_high_complexity_risk'] > 0:
                if deployment_mode == DeploymentMode.LOCAL_GPU:
                    score *= 0.9  # æœ¬åœ°GPUå°é«˜è¤‡é›œåº¦ä»»å‹™é¢¨éšªè¼ƒé«˜
            
            if factors['has_resource_risk'] > 0:
                if deployment_mode == DeploymentMode.CLOUD_API:
                    score *= 1.1  # é›²ç«¯APIå°è³‡æºé¢¨éšªæ›´æœ‰å½ˆæ€§
            
            scores[deployment_mode] = max(0.0, min(1.0, score))  # é™åˆ¶åœ¨0-1ç¯„åœå…§
        
        return scores
    
    def _generate_alternatives(
        self,
        deployment_scores: Dict[DeploymentMode, float],
        decision_factors: Dict[str, float]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ›¿ä»£é¸é …"""
        alternatives = []
        
        # æŒ‰è©•åˆ†æ’åº
        sorted_deployments = sorted(deployment_scores.items(), key=lambda x: x[1], reverse=True)
        
        # ç”Ÿæˆå‰3å€‹é¸é …çš„è©³ç´°ä¿¡æ¯
        for i, (deployment_mode, score) in enumerate(sorted_deployments[:3]):
            if i == 0:
                continue  # è·³éæ¨è–¦é¸é …
            
            alternative = {
                'deployment_mode': deployment_mode.value,
                'score': score,
                'rank': i + 1,
                'pros': [],
                'cons': [],
                'use_cases': []
            }
            
            # æ ¹æ“šéƒ¨ç½²æ¨¡å¼æ·»åŠ å„ªç¼ºé»
            if deployment_mode == DeploymentMode.LOCAL_GPU:
                alternative['pros'] = ['ä½å»¶é²', 'æ•¸æ“šéš±ç§', 'é•·æœŸæˆæœ¬æ•ˆç›Š']
                alternative['cons'] = ['é«˜åˆå§‹æŠ•è³‡', 'ç¶­è­·æˆæœ¬', 'ç¡¬é«”é™åˆ¶']
                alternative['use_cases'] = ['é«˜é »è¨“ç·´ä»»å‹™', 'æ•æ„Ÿæ•¸æ“šè™•ç†', 'é•·æœŸé‹è¡Œé …ç›®']
            elif deployment_mode == DeploymentMode.CLOUD_API:
                alternative['pros'] = ['ç„¡åˆå§‹æŠ•è³‡', 'å½ˆæ€§æ“´å±•', 'å…ç¶­è­·']
                alternative['cons'] = ['æŒ‰ä½¿ç”¨ä»˜è²»', 'ç¶²è·¯å»¶é²', 'æ•¸æ“šå‚³è¼¸æˆæœ¬']
                alternative['use_cases'] = ['çŸ­æœŸé …ç›®', 'ä¸å®šæœŸä»»å‹™', 'å¿«é€ŸåŸå‹é–‹ç™¼']
            else:  # HYBRID
                alternative['pros'] = ['å¹³è¡¡æˆæœ¬æ€§èƒ½', 'é¢¨éšªåˆ†æ•£', 'å½ˆæ€§èª¿é…']
                alternative['cons'] = ['è¤‡é›œç®¡ç†', 'é›™é‡æˆæœ¬', 'å”èª¿é–‹éŠ·']
                alternative['use_cases'] = ['æ··åˆå·¥ä½œè² è¼‰', 'å³°å€¼è™•ç†', 'æ¼¸é€²å¼é·ç§»']
            
            alternatives.append(alternative)
        
        return alternatives
    
    def _get_expected_cost(
        self,
        cost_comparison: CostComparisonResult,
        deployment_mode: DeploymentMode
    ) -> float:
        """ç²å–é æœŸæˆæœ¬"""
        if deployment_mode == DeploymentMode.LOCAL_GPU:
            return float(cost_comparison.local_gpu_cost.total_cost)
        elif deployment_mode == DeploymentMode.CLOUD_API:
            return float(cost_comparison.cloud_api_cost.total_cost)
        else:  # HYBRID
            return float(cost_comparison.hybrid_cost.total_cost)
    
    def get_decision_analytics(self) -> Dict[str, Any]:
        """ç²å–æ±ºç­–åˆ†æ"""
        if not self.decision_history:
            return {"message": "No decision history available"}
        
        # çµ±è¨ˆæ±ºç­–åˆ†ä½ˆ
        deployment_counts = defaultdict(int)
        strategy_performance = defaultdict(list)
        
        for decision in self.decision_history:
            deployment_counts[decision.recommended_deployment.value] += 1
            strategy_performance['confidence'].append(decision.confidence_score)
        
        # è¨ˆç®—å¹³å‡ä¿¡å¿ƒåº¦
        avg_confidence = np.mean(strategy_performance['confidence']) if strategy_performance['confidence'] else 0.0
        
        return {
            "total_decisions": len(self.decision_history),
            "deployment_distribution": dict(deployment_counts),
            "average_confidence": avg_confidence,
            "recent_decisions": [d.to_dict() for d in list(self.decision_history)[-5:]],
            "analysis_timestamp": datetime.now().isoformat()
        }

# ä¾¿åˆ©å‡½æ•¸
def create_performance_data_sample(
    task_type: TaskType = TaskType.TRAINING,
    deployment_mode: DeploymentMode = DeploymentMode.LOCAL_GPU
) -> PerformanceData:
    """å‰µå»ºæ€§èƒ½æ•¸æ“šæ¨£æœ¬"""
    return PerformanceData(
        timestamp=datetime.now(),
        task_type=task_type,
        deployment_mode=deployment_mode,
        throughput_requests_per_hour=100.0,
        latency_seconds=2.0,
        gpu_utilization_percent=85.0,
        memory_usage_percent=70.0,
        energy_consumption_watts=200.0,
        cost_per_request=0.05,
        quality_score=0.9
    )

def quick_routing_decision(
    task_name: str,
    task_description: str,
    strategy: RoutingStrategy = RoutingStrategy.BALANCED
) -> RoutingDecision:
    """å¿«é€Ÿè·¯ç”±æ±ºç­–çš„ä¾¿åˆ©å‡½æ•¸"""
    from .task_analyzer import analyze_single_task
    from .cost_calculator import quick_cost_comparison
    
    # åˆ†æä»»å‹™
    task_analysis = analyze_single_task(task_name, task_description)
    
    # æˆæœ¬å°æ¯”
    cost_comparison = quick_cost_comparison()
    
    # è·¯ç”±æ±ºç­–
    decision_engine = RoutingDecisionEngine()
    return decision_engine.make_routing_decision(
        task_analysis, cost_comparison, strategy
    )