#!/usr/bin/env python3
"""
LLM Cost Optimizer - LLMæˆæœ¬å„ªåŒ–å™¨
å¤©å·¥ (TianGong) - æ™ºèƒ½LLMæˆæœ¬æ§åˆ¶å’Œæ¨¡å‹é¸æ“‡ç³»çµ±

æ­¤æ¨¡çµ„è² è²¬ï¼š
1. æˆæœ¬ç›£æ§å’Œé ç®—æ§åˆ¶
2. æ™ºèƒ½æ¨¡å‹é¸æ“‡
3. è«‹æ±‚å„ªåŒ–å’Œå¿«å–ç­–ç•¥
4. æˆæœ¬æ•ˆç›Šåˆ†æ
"""

import asyncio
import json
import logging
import os
import time
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import aiohttp
import hashlib

class ModelTier(Enum):
    """æ¨¡å‹ç­‰ç´š"""
    BASIC = "basic"           # GPT-3.5ã€Gemini Flash - ä¾¿å®œå¿«é€Ÿ
    STANDARD = "standard"     # GPT-4ã€Gemini Pro - å¹³è¡¡æ€§èƒ½
    PREMIUM = "premium"       # GPT-4 Turboã€Claude Sonnet - é«˜è³ªé‡
    ULTRA = "ultra"          # GPT-4oã€Claude Opus - æœ€ä½³æ€§èƒ½

class TaskComplexity(Enum):
    """ä»»å‹™è¤‡é›œåº¦"""
    SIMPLE = "simple"         # åŸºç¤åˆ†æã€ç°¡å–®æ‘˜è¦
    MODERATE = "moderate"     # æŠ€è¡“åˆ†æã€æ–°èæ•´ç†
    COMPLEX = "complex"       # ç¶œåˆåˆ†æã€æ·±åº¦ç ”ç©¶
    CRITICAL = "critical"     # æŠ•è³‡å»ºè­°ã€é¢¨éšªè©•ä¼°

class CostUnit(Enum):
    """æˆæœ¬å–®ä½"""
    TOKEN = "token"           # æŒ‰tokenè¨ˆè²»
    REQUEST = "request"       # æŒ‰è«‹æ±‚è¨ˆè²»
    MINUTE = "minute"         # æŒ‰æ™‚é–“è¨ˆè²»

@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®"""
    model_name: str
    provider: str            # openai, google, anthropic
    tier: ModelTier
    cost_per_1k_input: float # æ¯1Kè¼¸å…¥tokenæˆæœ¬ (USD)
    cost_per_1k_output: float # æ¯1Kè¼¸å‡ºtokenæˆæœ¬ (USD)
    max_context: int         # æœ€å¤§ä¸Šä¸‹æ–‡é•·åº¦
    speed_score: float       # é€Ÿåº¦è©•åˆ† (1-10)
    quality_score: float     # è³ªé‡è©•åˆ† (1-10)
    rate_limit: int         # æ¯åˆ†é˜è«‹æ±‚é™åˆ¶
    supports_streaming: bool = True
    supports_json_mode: bool = False
    description: str = ""

@dataclass
class CostBudget:
    """æˆæœ¬é ç®—"""
    user_id: str
    membership_tier: str
    daily_budget_usd: float
    monthly_budget_usd: float
    daily_used_usd: float = 0.0
    monthly_used_usd: float = 0.0
    last_reset_daily: str = ""
    last_reset_monthly: str = ""
    
    def __post_init__(self):
        today = datetime.now().strftime('%Y-%m-%d')
        current_month = datetime.now().strftime('%Y-%m')
        if not self.last_reset_daily:
            self.last_reset_daily = today
        if not self.last_reset_monthly:
            self.last_reset_monthly = current_month

@dataclass
class UsageRecord:
    """ä½¿ç”¨è¨˜éŒ„"""
    user_id: str
    request_id: str
    model_name: str
    task_type: str
    input_tokens: int
    output_tokens: int
    cost_usd: float
    response_time_ms: int
    success: bool
    timestamp: str
    quality_rating: Optional[float] = None

class LLMCostOptimizer:
    """LLMæˆæœ¬å„ªåŒ–å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # æ¨¡å‹é…ç½®
        self.model_configs = self._initialize_model_configs()
        
        # æˆæœ¬è¿½è¹¤
        self.usage_records: List[UsageRecord] = []
        self.user_budgets: Dict[str, CostBudget] = {}
        
        # å¿«å–è¨­ç½®
        self.response_cache: Dict[str, Dict[str, Any]] = {}
        self.cache_duration = 1800  # 30åˆ†é˜å¿«å–
        
        # å„ªåŒ–è¨­ç½®
        self.cost_optimization_enabled = True
        self.quality_threshold = 7.0  # æœ€ä½è³ªé‡è¦æ±‚
        
        # è¨­ç½®æ—¥èªŒ
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
    
    def _initialize_model_configs(self) -> Dict[str, ModelConfig]:
        """åˆå§‹åŒ–æ¨¡å‹é…ç½®"""
        configs = {}
        
        # OpenAI æ¨¡å‹
        configs["gpt-3.5-turbo"] = ModelConfig(
            model_name="gpt-3.5-turbo",
            provider="openai",
            tier=ModelTier.BASIC,
            cost_per_1k_input=0.0015,
            cost_per_1k_output=0.002,
            max_context=16385,
            speed_score=9.0,
            quality_score=7.0,
            rate_limit=3500,
            supports_json_mode=True,
            description="é«˜é€Ÿåº¦ã€ä½æˆæœ¬çš„åŸºç¤æ¨¡å‹"
        )
        
        configs["gpt-4"] = ModelConfig(
            model_name="gpt-4",
            provider="openai",
            tier=ModelTier.STANDARD,
            cost_per_1k_input=0.03,
            cost_per_1k_output=0.06,
            max_context=8192,
            speed_score=6.0,
            quality_score=9.0,
            rate_limit=500,
            supports_json_mode=True,
            description="é«˜è³ªé‡åˆ†æå’Œæ¨ç†æ¨¡å‹"
        )
        
        configs["gpt-4-turbo"] = ModelConfig(
            model_name="gpt-4-turbo",
            provider="openai",
            tier=ModelTier.PREMIUM,
            cost_per_1k_input=0.01,
            cost_per_1k_output=0.03,
            max_context=128000,
            speed_score=7.0,
            quality_score=9.5,
            rate_limit=800,
            supports_json_mode=True,
            description="é«˜æ€§åƒ¹æ¯”çš„é€²éšæ¨¡å‹"
        )
        
        configs["gpt-4o"] = ModelConfig(
            model_name="gpt-4o",
            provider="openai",
            tier=ModelTier.ULTRA,
            cost_per_1k_input=0.005,
            cost_per_1k_output=0.015,
            max_context=128000,
            speed_score=8.0,
            quality_score=10.0,
            rate_limit=1000,
            supports_json_mode=True,
            description="æœ€æ–°æœ€å¼·çš„å¤šæ¨¡æ…‹æ¨¡å‹"
        )
        
        # Google æ¨¡å‹
        configs["gemini-flash"] = ModelConfig(
            model_name="gemini-1.5-flash",
            provider="google",
            tier=ModelTier.BASIC,
            cost_per_1k_input=0.00075,
            cost_per_1k_output=0.003,
            max_context=1000000,
            speed_score=10.0,
            quality_score=7.5,
            rate_limit=2000,
            supports_json_mode=True,
            description="è¶…é«˜é€Ÿåº¦ã€è¶…å¤§ä¸Šä¸‹æ–‡çš„ç¶“æ¿Ÿæ¨¡å‹"
        )
        
        configs["gemini-pro"] = ModelConfig(
            model_name="gemini-1.5-pro",
            provider="google",
            tier=ModelTier.PREMIUM,
            cost_per_1k_input=0.0035,
            cost_per_1k_output=0.0105,
            max_context=2000000,
            speed_score=7.0,
            quality_score=9.0,
            rate_limit=300,
            supports_json_mode=True,
            description="å¤§ä¸Šä¸‹æ–‡é«˜è³ªé‡æ¨¡å‹"
        )
        
        # Anthropic æ¨¡å‹
        configs["claude-haiku"] = ModelConfig(
            model_name="claude-3-haiku",
            provider="anthropic",
            tier=ModelTier.BASIC,
            cost_per_1k_input=0.00025,
            cost_per_1k_output=0.00125,
            max_context=200000,
            speed_score=9.5,
            quality_score=8.0,
            rate_limit=1000,
            description="æœ€ç¶“æ¿Ÿçš„Claudeæ¨¡å‹"
        )
        
        configs["claude-sonnet"] = ModelConfig(
            model_name="claude-3.5-sonnet",
            provider="anthropic",
            tier=ModelTier.PREMIUM,
            cost_per_1k_input=0.003,
            cost_per_1k_output=0.015,
            max_context=200000,
            speed_score=7.0,
            quality_score=9.5,
            rate_limit=500,
            description="å¹³è¡¡æ€§èƒ½çš„Claudeæ¨¡å‹"
        )
        
        configs["claude-opus"] = ModelConfig(
            model_name="claude-3-opus",
            provider="anthropic",
            tier=ModelTier.ULTRA,
            cost_per_1k_input=0.015,
            cost_per_1k_output=0.075,
            max_context=200000,
            speed_score=5.0,
            quality_score=10.0,
            rate_limit=200,
            description="æœ€é«˜è³ªé‡çš„Claudeæ¨¡å‹"
        )
        
        return configs
    
    async def get_user_budget(self, user_id: str, membership_tier: str) -> CostBudget:
        """ç²å–ç”¨æˆ¶é ç®—"""
        if user_id not in self.user_budgets:
            # æ ¹æ“šæœƒå“¡ç­‰ç´šè¨­å®šé ç®—
            budget_mapping = {
                "FREE": {"daily": 0.10, "monthly": 2.00},    # $0.10/å¤©, $2/æœˆ
                "GOLD": {"daily": 1.00, "monthly": 25.00},   # $1/å¤©, $25/æœˆ
                "DIAMOND": {"daily": 10.00, "monthly": 250.00}  # $10/å¤©, $250/æœˆ
            }
            
            budget_config = budget_mapping.get(membership_tier, budget_mapping["FREE"])
            
            self.user_budgets[user_id] = CostBudget(
                user_id=user_id,
                membership_tier=membership_tier,
                daily_budget_usd=budget_config["daily"],
                monthly_budget_usd=budget_config["monthly"]
            )
        
        budget = self.user_budgets[user_id]
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡ç½®æ¯æ—¥/æ¯æœˆä½¿ç”¨é‡
        today = datetime.now().strftime('%Y-%m-%d')
        current_month = datetime.now().strftime('%Y-%m')
        
        if budget.last_reset_daily != today:
            budget.daily_used_usd = 0.0
            budget.last_reset_daily = today
            
        if budget.last_reset_monthly != current_month:
            budget.monthly_used_usd = 0.0
            budget.last_reset_monthly = current_month
        
        return budget
    
    def check_budget_availability(self, budget: CostBudget, estimated_cost: float) -> Dict[str, Any]:
        """æª¢æŸ¥é ç®—å¯ç”¨æ€§"""
        daily_remaining = budget.daily_budget_usd - budget.daily_used_usd
        monthly_remaining = budget.monthly_budget_usd - budget.monthly_used_usd
        
        can_afford_daily = daily_remaining >= estimated_cost
        can_afford_monthly = monthly_remaining >= estimated_cost
        
        return {
            "can_afford": can_afford_daily and can_afford_monthly,
            "daily_remaining": daily_remaining,
            "monthly_remaining": monthly_remaining,
            "estimated_cost": estimated_cost,
            "budget_tier": budget.membership_tier,
            "constraints": {
                "daily_limit_reached": not can_afford_daily,
                "monthly_limit_reached": not can_afford_monthly
            }
        }
    
    async def select_optimal_model(
        self,
        task_complexity: TaskComplexity,
        user_context: Dict[str, Any],
        estimated_tokens: int = 1000,
        quality_requirements: float = None
    ) -> Tuple[ModelConfig, Dict[str, Any]]:
        """é¸æ“‡æœ€å„ªæ¨¡å‹"""
        
        user_id = user_context.get('user_id', 'anonymous')
        membership_tier = user_context.get('membership_tier', 'FREE')
        
        # ç²å–ç”¨æˆ¶é ç®—
        budget = await self.get_user_budget(user_id, membership_tier)
        
        # è¨­å®šè³ªé‡è¦æ±‚
        min_quality = quality_requirements or self._get_min_quality_for_task(task_complexity)
        
        # ç¯©é¸ç¬¦åˆæ¢ä»¶çš„æ¨¡å‹
        candidate_models = []
        
        for model_name, config in self.model_configs.items():
            # æª¢æŸ¥è³ªé‡è¦æ±‚
            if config.quality_score < min_quality:
                continue
            
            # æª¢æŸ¥æœƒå“¡ç­‰ç´šé™åˆ¶
            if not self._is_model_allowed_for_tier(config, membership_tier):
                continue
            
            # ä¼°ç®—æˆæœ¬
            estimated_cost = self._calculate_estimated_cost(config, estimated_tokens)
            
            # æª¢æŸ¥é ç®—
            budget_check = self.check_budget_availability(budget, estimated_cost)
            if not budget_check["can_afford"]:
                continue
            
            # è¨ˆç®—æ€§åƒ¹æ¯”è©•åˆ†
            cost_efficiency = self._calculate_cost_efficiency(config, estimated_cost, task_complexity)
            
            candidate_models.append({
                "config": config,
                "estimated_cost": estimated_cost,
                "cost_efficiency": cost_efficiency,
                "budget_impact": estimated_cost / budget.daily_budget_usd
            })
        
        if not candidate_models:
            # æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ¨¡å‹ï¼Œè¿”å›æœ€ä¾¿å®œçš„åŸºç¤æ¨¡å‹
            fallback_model = self._get_fallback_model(membership_tier)
            return fallback_model, {
                "selection_reason": "budget_constraints",
                "message": "å·²é¸æ“‡æœ€ç¶“æ¿Ÿçš„å¯ç”¨æ¨¡å‹",
                "budget_warning": True
            }
        
        # æ ¹æ“šç­–ç•¥é¸æ“‡æœ€ä½³æ¨¡å‹
        selected = self._apply_selection_strategy(candidate_models, task_complexity, user_context)
        
        return selected["config"], {
            "selection_reason": "optimized",
            "estimated_cost": selected["estimated_cost"],
            "cost_efficiency": selected["cost_efficiency"],
            "quality_score": selected["config"].quality_score,
            "alternatives_count": len(candidate_models) - 1
        }
    
    def _get_min_quality_for_task(self, complexity: TaskComplexity) -> float:
        """ç²å–ä»»å‹™æ‰€éœ€æœ€ä½è³ªé‡"""
        quality_mapping = {
            TaskComplexity.SIMPLE: 6.0,      # åŸºç¤åˆ†æå¯æ¥å—è¼ƒä½è³ªé‡
            TaskComplexity.MODERATE: 7.0,    # æ¨™æº–åˆ†æéœ€è¦ä¸­ç­‰è³ªé‡
            TaskComplexity.COMPLEX: 8.0,     # è¤‡é›œåˆ†æéœ€è¦é«˜è³ªé‡
            TaskComplexity.CRITICAL: 9.0     # é—œéµæ±ºç­–éœ€è¦æœ€é«˜è³ªé‡
        }
        return quality_mapping.get(complexity, 7.0)
    
    def _is_model_allowed_for_tier(self, model_config: ModelConfig, membership_tier: str) -> bool:
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å…è¨±è©²æœƒå“¡ç­‰ç´šä½¿ç”¨"""
        tier_limits = {
            "FREE": [ModelTier.BASIC],
            "GOLD": [ModelTier.BASIC, ModelTier.STANDARD, ModelTier.PREMIUM],
            "DIAMOND": [ModelTier.BASIC, ModelTier.STANDARD, ModelTier.PREMIUM, ModelTier.ULTRA]
        }
        
        allowed_tiers = tier_limits.get(membership_tier, [ModelTier.BASIC])
        return model_config.tier in allowed_tiers
    
    def _calculate_estimated_cost(self, model_config: ModelConfig, estimated_tokens: int) -> float:
        """è¨ˆç®—é ä¼°æˆæœ¬"""
        input_tokens = int(estimated_tokens * 0.7)  # å‡è¨­70%ç‚ºè¼¸å…¥
        output_tokens = int(estimated_tokens * 0.3)  # å‡è¨­30%ç‚ºè¼¸å‡º
        
        input_cost = (input_tokens / 1000) * model_config.cost_per_1k_input
        output_cost = (output_tokens / 1000) * model_config.cost_per_1k_output
        
        return input_cost + output_cost
    
    def _calculate_cost_efficiency(
        self, 
        model_config: ModelConfig, 
        estimated_cost: float, 
        task_complexity: TaskComplexity
    ) -> float:
        """è¨ˆç®—æˆæœ¬æ•ˆç›Šè©•åˆ†"""
        # åŸºç¤è©•åˆ†ï¼šè³ªé‡ / æˆæœ¬
        base_score = model_config.quality_score / max(estimated_cost * 1000, 0.001)
        
        # æ ¹æ“šä»»å‹™è¤‡é›œåº¦èª¿æ•´
        complexity_multiplier = {
            TaskComplexity.SIMPLE: 1.2,      # ç°¡å–®ä»»å‹™æ›´é‡è¦–æˆæœ¬
            TaskComplexity.MODERATE: 1.0,    # æ¨™æº–æ¬Šé‡
            TaskComplexity.COMPLEX: 0.8,     # è¤‡é›œä»»å‹™æ›´é‡è¦–è³ªé‡
            TaskComplexity.CRITICAL: 0.6     # é—œéµä»»å‹™æœ€é‡è¦–è³ªé‡
        }
        
        multiplier = complexity_multiplier.get(task_complexity, 1.0)
        
        # è€ƒæ…®é€Ÿåº¦å› ç´ 
        speed_bonus = model_config.speed_score * 0.1
        
        return base_score * multiplier + speed_bonus
    
    def _get_fallback_model(self, membership_tier: str) -> ModelConfig:
        """ç²å–å¾Œå‚™æ¨¡å‹"""
        fallback_mapping = {
            "FREE": "gpt-3.5-turbo",
            "GOLD": "gpt-3.5-turbo", 
            "DIAMOND": "gpt-4"
        }
        
        model_name = fallback_mapping.get(membership_tier, "gpt-3.5-turbo")
        return self.model_configs[model_name]
    
    def _apply_selection_strategy(
        self, 
        candidates: List[Dict[str, Any]], 
        task_complexity: TaskComplexity,
        user_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‡‰ç”¨é¸æ“‡ç­–ç•¥"""
        
        # æ ¹æ“šä»»å‹™è¤‡é›œåº¦å’Œç”¨æˆ¶åå¥½é¸æ“‡ç­–ç•¥
        if task_complexity in [TaskComplexity.CRITICAL]:
            # é—œéµä»»å‹™ï¼šå„ªå…ˆè³ªé‡
            return max(candidates, key=lambda x: x["config"].quality_score)
        elif task_complexity == TaskComplexity.SIMPLE:
            # ç°¡å–®ä»»å‹™ï¼šå„ªå…ˆæˆæœ¬æ•ˆç›Š
            return max(candidates, key=lambda x: x["cost_efficiency"])
        else:
            # å¹³è¡¡é¸æ“‡ï¼šç¶œåˆè©•åˆ†
            for candidate in candidates:
                candidate["composite_score"] = (
                    candidate["cost_efficiency"] * 0.4 +
                    candidate["config"].quality_score * 0.4 +
                    candidate["config"].speed_score * 0.2
                )
            
            return max(candidates, key=lambda x: x["composite_score"])
    
    async def check_cache(self, request_hash: str) -> Optional[Dict[str, Any]]:
        """æª¢æŸ¥å¿«å–"""
        if request_hash in self.response_cache:
            cached_data = self.response_cache[request_hash]
            
            # æª¢æŸ¥å¿«å–æœ‰æ•ˆæœŸ
            cache_time = datetime.fromisoformat(cached_data["cached_at"])
            if datetime.now() - cache_time < timedelta(seconds=self.cache_duration):
                self.logger.debug(f"å¿«å–å‘½ä¸­: {request_hash[:8]}...")
                return cached_data["response"]
        
        return None
    
    def save_to_cache(self, request_hash: str, response: Dict[str, Any]):
        """ä¿å­˜åˆ°å¿«å–"""
        self.response_cache[request_hash] = {
            "response": response,
            "cached_at": datetime.now().isoformat()
        }
        
        # æ¸…ç†éæœŸå¿«å–
        self._cleanup_expired_cache()
    
    def _cleanup_expired_cache(self):
        """æ¸…ç†éæœŸå¿«å–"""
        current_time = datetime.now()
        expired_keys = []
        
        for key, cached_data in self.response_cache.items():
            cache_time = datetime.fromisoformat(cached_data["cached_at"])
            if current_time - cache_time >= timedelta(seconds=self.cache_duration):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.response_cache[key]
    
    def generate_request_hash(self, prompt: str, model_name: str, parameters: Dict[str, Any]) -> str:
        """ç”Ÿæˆè«‹æ±‚hashç”¨æ–¼å¿«å–"""
        hash_input = f"{prompt}:{model_name}:{json.dumps(parameters, sort_keys=True)}"
        return hashlib.sha256(hash_input.encode()).hexdigest()  # å®‰å…¨ä¿®å¾©ï¼šä½¿ç”¨SHA256æ›¿æ›MD5
    
    async def record_usage(
        self,
        user_id: str,
        request_id: str,
        model_name: str,
        task_type: str,
        input_tokens: int,
        output_tokens: int,
        response_time_ms: int,
        success: bool
    ) -> UsageRecord:
        """è¨˜éŒ„ä½¿ç”¨æƒ…æ³"""
        
        model_config = self.model_configs.get(model_name)
        if not model_config:
            self.logger.warning(f"æœªçŸ¥æ¨¡å‹: {model_name}")
            cost_usd = 0.0
        else:
            input_cost = (input_tokens / 1000) * model_config.cost_per_1k_input
            output_cost = (output_tokens / 1000) * model_config.cost_per_1k_output
            cost_usd = input_cost + output_cost
        
        # å‰µå»ºä½¿ç”¨è¨˜éŒ„
        record = UsageRecord(
            user_id=user_id,
            request_id=request_id,
            model_name=model_name,
            task_type=task_type,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            cost_usd=cost_usd,
            response_time_ms=response_time_ms,
            success=success,
            timestamp=datetime.now().isoformat()
        )
        
        self.usage_records.append(record)
        
        # æ›´æ–°ç”¨æˆ¶é ç®—ä½¿ç”¨é‡
        if user_id in self.user_budgets and success:
            budget = self.user_budgets[user_id]
            budget.daily_used_usd += cost_usd
            budget.monthly_used_usd += cost_usd
        
        self.logger.info(f"è¨˜éŒ„ä½¿ç”¨: {user_id} - {model_name} - ${cost_usd:.4f}")
        
        return record
    
    async def get_cost_analytics(self, user_id: str = None, days: int = 30) -> Dict[str, Any]:
        """ç²å–æˆæœ¬åˆ†æ"""
        
        # ç¯©é¸è¨˜éŒ„
        start_date = datetime.now() - timedelta(days=days)
        filtered_records = [
            record for record in self.usage_records
            if datetime.fromisoformat(record.timestamp) >= start_date and
               (user_id is None or record.user_id == user_id)
        ]
        
        if not filtered_records:
            return {
                "total_cost": 0.0,
                "total_requests": 0,
                "average_cost_per_request": 0.0,
                "model_breakdown": {},
                "daily_costs": []
            }
        
        # ç¸½æˆæœ¬çµ±è¨ˆ
        total_cost = sum(record.cost_usd for record in filtered_records)
        total_requests = len(filtered_records)
        avg_cost = total_cost / total_requests if total_requests > 0 else 0.0
        
        # æŒ‰æ¨¡å‹åˆ†çµ„
        model_breakdown = {}
        for record in filtered_records:
            if record.model_name not in model_breakdown:
                model_breakdown[record.model_name] = {
                    "requests": 0,
                    "cost": 0.0,
                    "avg_response_time": 0.0,
                    "success_rate": 0.0
                }
            
            breakdown = model_breakdown[record.model_name]
            breakdown["requests"] += 1
            breakdown["cost"] += record.cost_usd
            breakdown["avg_response_time"] += record.response_time_ms
            breakdown["success_rate"] += 1 if record.success else 0
        
        # è¨ˆç®—å¹³å‡å€¼
        for model_name, breakdown in model_breakdown.items():
            requests = breakdown["requests"]
            breakdown["avg_response_time"] /= requests
            breakdown["success_rate"] = breakdown["success_rate"] / requests * 100
            breakdown["avg_cost_per_request"] = breakdown["cost"] / requests
        
        # æ¯æ—¥æˆæœ¬è¶¨å‹¢
        daily_costs = {}
        for record in filtered_records:
            date = record.timestamp[:10]  # YYYY-MM-DD
            if date not in daily_costs:
                daily_costs[date] = 0.0
            daily_costs[date] += record.cost_usd
        
        daily_costs_list = [
            {"date": date, "cost": cost}
            for date, cost in sorted(daily_costs.items())
        ]
        
        return {
            "analysis_period_days": days,
            "total_cost": total_cost,
            "total_requests": total_requests,
            "average_cost_per_request": avg_cost,
            "model_breakdown": model_breakdown,
            "daily_costs": daily_costs_list,
            "cost_efficiency_score": self._calculate_efficiency_score(filtered_records),
            "timestamp": datetime.now().isoformat()
        }
    
    def _calculate_efficiency_score(self, records: List[UsageRecord]) -> float:
        """è¨ˆç®—æˆæœ¬æ•ˆç›Šè©•åˆ†"""
        if not records:
            return 0.0
        
        # åŸºæ–¼æˆåŠŸç‡ã€æˆæœ¬å’ŒéŸ¿æ‡‰æ™‚é–“çš„ç¶œåˆè©•åˆ†
        total_requests = len(records)
        successful_requests = sum(1 for r in records if r.success)
        success_rate = successful_requests / total_requests
        
        avg_cost = sum(r.cost_usd for r in records) / total_requests
        avg_response_time = sum(r.response_time_ms for r in records) / total_requests
        
        # æ­£è¦åŒ–è©•åˆ† (0-100)
        efficiency_score = (
            success_rate * 40 +  # æˆåŠŸç‡æ¬Šé‡40%
            max(0, (0.1 - avg_cost) / 0.1) * 30 +  # æˆæœ¬æ•ˆç›Šæ¬Šé‡30%
            max(0, (5000 - avg_response_time) / 5000) * 30  # éŸ¿æ‡‰é€Ÿåº¦æ¬Šé‡30%
        ) * 100
        
        return min(100, max(0, efficiency_score))
    
    def get_optimization_recommendations(self, user_id: str) -> List[Dict[str, Any]]:
        """ç²å–å„ªåŒ–å»ºè­°"""
        recommendations = []
        
        # åˆ†æç”¨æˆ¶ä½¿ç”¨æ¨¡å¼
        user_records = [r for r in self.usage_records if r.user_id == user_id]
        
        if not user_records:
            return [{
                "type": "no_data",
                "title": "æš«ç„¡ä½¿ç”¨æ•¸æ“š",
                "description": "é–‹å§‹ä½¿ç”¨AIåˆ†æåŠŸèƒ½å¾Œï¼Œç³»çµ±å°‡æä¾›å€‹æ€§åŒ–å„ªåŒ–å»ºè­°",
                "priority": "info"
            }]
        
        # æˆæœ¬å„ªåŒ–å»ºè­°
        total_cost = sum(r.cost_usd for r in user_records[-30:])  # æœ€è¿‘30ç­†
        if total_cost > 1.0:  # å¦‚æœæˆæœ¬è¼ƒé«˜
            recommendations.append({
                "type": "cost_optimization",
                "title": "è€ƒæ…®ä½¿ç”¨æ›´ç¶“æ¿Ÿçš„æ¨¡å‹",
                "description": f"æœ€è¿‘30æ¬¡åˆ†ææˆæœ¬ç‚º${total_cost:.2f}ï¼Œå¯å˜—è©¦ä½¿ç”¨Gemini Flashæˆ–Claude Haikuç­‰ç¶“æ¿Ÿå‹æ¨¡å‹",
                "priority": "medium",
                "potential_savings": f"${total_cost * 0.3:.2f}"
            })
        
        # æ¨¡å‹é¸æ“‡å»ºè­°
        model_usage = {}
        for record in user_records[-50:]:  # æœ€è¿‘50ç­†
            model_usage[record.model_name] = model_usage.get(record.model_name, 0) + 1
        
        if len(model_usage) == 1:  # åªä½¿ç”¨ä¸€å€‹æ¨¡å‹
            recommendations.append({
                "type": "model_diversity",
                "title": "å˜—è©¦å¤šæ¨£åŒ–çš„æ¨¡å‹é¸æ“‡",
                "description": "ä¸åŒä»»å‹™å¯ä½¿ç”¨ä¸åŒæ¨¡å‹ç²å¾—æ›´å¥½çš„æˆæœ¬æ•ˆç›Šï¼Œç³»çµ±å¯è‡ªå‹•ç‚ºæ‚¨é¸æ“‡æœ€é©åˆçš„æ¨¡å‹",
                "priority": "low"
            })
        
        # å¿«å–ä½¿ç”¨å»ºè­°
        cache_hits = len([r for r in user_records if hasattr(r, 'from_cache') and r.from_cache])
        cache_rate = cache_hits / len(user_records) if user_records else 0
        
        if cache_rate < 0.1:  # å¿«å–å‘½ä¸­ç‡ä½
            recommendations.append({
                "type": "cache_optimization",
                "title": "å¢åŠ é‡è¤‡æŸ¥è©¢ä»¥æé«˜æ•ˆç‡",
                "description": "ç›¸ä¼¼çš„åˆ†æè«‹æ±‚æœƒä½¿ç”¨å¿«å–çµæœï¼Œå¯ç¯€çœæˆæœ¬å’Œæ™‚é–“",
                "priority": "low"
            })
        
        return recommendations
    
    def clear_cache(self):
        """æ¸…ç†å…¨éƒ¨å¿«å–"""
        self.response_cache.clear()
        self.logger.info("LLMæˆæœ¬å„ªåŒ–å™¨å¿«å–å·²æ¸…ç†")

# ä¾¿åˆ©å‡½æ•¸
async def optimize_llm_request(
    user_context: Dict[str, Any],
    task_type: str,
    estimated_tokens: int = 1000,
    quality_requirements: float = None
) -> Dict[str, Any]:
    """å„ªåŒ–LLMè«‹æ±‚"""
    optimizer = LLMCostOptimizer()
    
    # åˆ†æä»»å‹™è¤‡é›œåº¦
    complexity_mapping = {
        "basic_analysis": TaskComplexity.SIMPLE,
        "technical_analysis": TaskComplexity.MODERATE,
        "fundamental_analysis": TaskComplexity.MODERATE,
        "comprehensive_analysis": TaskComplexity.COMPLEX,
        "investment_advice": TaskComplexity.CRITICAL,
        "risk_assessment": TaskComplexity.CRITICAL
    }
    
    task_complexity = complexity_mapping.get(task_type, TaskComplexity.MODERATE)
    
    # é¸æ“‡æœ€å„ªæ¨¡å‹
    optimal_model, selection_info = await optimizer.select_optimal_model(
        task_complexity, user_context, estimated_tokens, quality_requirements
    )
    
    return {
        "recommended_model": optimal_model.model_name,
        "provider": optimal_model.provider,
        "estimated_cost": selection_info.get("estimated_cost", 0.0),
        "quality_score": optimal_model.quality_score,
        "selection_reason": selection_info.get("selection_reason"),
        "optimization_tips": selection_info
    }

async def get_user_cost_summary(user_id: str) -> Dict[str, Any]:
    """ç²å–ç”¨æˆ¶æˆæœ¬ç¸½è¦½"""
    optimizer = LLMCostOptimizer()
    
    # ç²å–ç”¨æˆ¶é ç®—
    budget = await optimizer.get_user_budget(user_id, "GOLD")  # é è¨­GOLDï¼Œå¯¦éš›æ‡‰å¾ç”¨æˆ¶ä¸Šä¸‹æ–‡ç²å–
    
    # ç²å–æˆæœ¬åˆ†æ
    analytics = await optimizer.get_cost_analytics(user_id, days=30)
    
    # ç²å–å„ªåŒ–å»ºè­°
    recommendations = optimizer.get_optimization_recommendations(user_id)
    
    return {
        "budget_info": asdict(budget),
        "usage_analytics": analytics,
        "optimization_recommendations": recommendations,
        "cost_efficiency_score": analytics.get("cost_efficiency_score", 0),
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    # æ¸¬è©¦è…³æœ¬
    import asyncio
    
    async def test_cost_optimizer():
        print("ğŸ’° æ¸¬è©¦LLMæˆæœ¬å„ªåŒ–å™¨")
        
        optimizer = LLMCostOptimizer()
        
        # æ¸¬è©¦æ¨¡å‹é¸æ“‡
        user_context = {
            "user_id": "test_user",
            "membership_tier": "GOLD"
        }
        
        optimal_model, selection_info = await optimizer.select_optimal_model(
            TaskComplexity.MODERATE,
            user_context,
            estimated_tokens=1500
        )
        
        print(f"æ¨è–¦æ¨¡å‹: {optimal_model.model_name}")
        print(f"é ä¼°æˆæœ¬: ${selection_info.get('estimated_cost', 0):.4f}")
        print(f"è³ªé‡è©•åˆ†: {optimal_model.quality_score}/10")
        
        # æ¸¬è©¦ä½¿ç”¨è¨˜éŒ„
        record = await optimizer.record_usage(
            user_id="test_user",
            request_id="test_001",
            model_name=optimal_model.model_name,
            task_type="test_analysis",
            input_tokens=1000,
            output_tokens=500,
            response_time_ms=2500,
            success=True
        )
        
        print(f"è¨˜éŒ„ä½¿ç”¨: ${record.cost_usd:.4f}")
        
        # æ¸¬è©¦æˆæœ¬åˆ†æ
        analytics = await optimizer.get_cost_analytics("test_user")
        print(f"ç¸½æˆæœ¬: ${analytics['total_cost']:.4f}")
        print(f"æ•ˆç›Šè©•åˆ†: {analytics['cost_efficiency_score']:.1f}/100")
        
        print("âœ… æ¸¬è©¦å®Œæˆ")
    
    asyncio.run(test_cost_optimizer())