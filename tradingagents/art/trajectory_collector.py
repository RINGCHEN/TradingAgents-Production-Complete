#!/usr/bin/env python3
"""
TrajectoryCollector - ARTè»Œè·¡æ”¶é›†å™¨
å¤©å·¥ (TianGong) - æ•´åˆBaseAnalystç³»çµ±çš„æ±ºç­–è»Œè·¡æ”¶é›†å™¨

æ­¤æ¨¡çµ„æä¾›ï¼š
1. å®Œæ•´çš„åˆ†æå¸«æ±ºç­–è»Œè·¡æ”¶é›†åŠŸèƒ½
2. èˆ‡BaseAnalystç³»çµ±çš„ç„¡ç¸«æ•´åˆ
3. æ¨ç†éç¨‹å’Œä¸­é–“ç‹€æ…‹çš„çµæ§‹åŒ–è¨˜éŒ„
4. æ”¯æ´å¤šç¨®åˆ†æå¸«é¡å‹çš„è»Œè·¡æ”¶é›†
5. GRPOè¨“ç·´æº–å‚™çš„æ•¸æ“šçµæ§‹
6. é«˜æ•ˆèƒ½çš„å¤§é‡è»Œè·¡è™•ç†
"""

from typing import Dict, Any, List, Optional, Tuple, Union, Callable
from dataclasses import dataclass, asdict, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
import os
import json
import logging
import asyncio
import hashlib
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import threading
from collections import defaultdict
import uuid

# Import existing base classes
try:
    from ..agents.analysts.base_analyst import BaseAnalyst, AnalysisResult, AnalysisState, AnalysisType
    BASE_ANALYST_AVAILABLE = True
except ImportError:
    BASE_ANALYST_AVAILABLE = False
    # Define minimal compatibility classes
    class AnalysisType(Enum):
        TECHNICAL = "technical"
        FUNDAMENTAL = "fundamental"
        NEWS_SENTIMENT = "news_sentiment"
        MARKET_SENTIMENT = "market_sentiment"
        RISK_ASSESSMENT = "risk_assessment"
        INVESTMENT_PLANNING = "investment_planning"
        TAIWAN_SPECIFIC = "taiwan_specific"

class TrajectoryType(Enum):
    """è»Œè·¡æ­¥é©Ÿé¡å‹"""
    INITIALIZATION = "initialization"              # åˆå§‹åŒ–éšæ®µ
    DATA_COLLECTION = "data_collection"            # æ•¸æ“šæ”¶é›†
    DATA_VALIDATION = "data_validation"            # æ•¸æ“šé©—è­‰
    DATA_INTERPRETATION = "data_interpretation"    # æ•¸æ“šè§£è®€
    FINANCIAL_ANALYSIS = "financial_analysis"      # è²¡å‹™åˆ†æ
    TECHNICAL_ANALYSIS = "technical_analysis"      # æŠ€è¡“åˆ†æ
    MARKET_SENTIMENT_ANALYSIS = "market_sentiment_analysis"  # å¸‚å ´æƒ…ç·’åˆ†æ
    RISK_ASSESSMENT = "risk_assessment"            # é¢¨éšªè©•ä¼°
    VALUATION_CALCULATION = "valuation_calculation" # ä¼°å€¼è¨ˆç®—
    PEER_COMPARISON = "peer_comparison"            # åŒæ¥­æ¯”è¼ƒ
    REASONING_SYNTHESIS = "reasoning_synthesis"    # æ¨ç†ç¶œåˆ
    CONFIDENCE_CALIBRATION = "confidence_calibration" # ä¿¡å¿ƒåº¦æ ¡æº–
    RECOMMENDATION_LOGIC = "recommendation_logic"  # å»ºè­°é‚è¼¯
    FINAL_VALIDATION = "final_validation"          # æœ€çµ‚é©—è­‰
    ERROR_HANDLING = "error_handling"              # éŒ¯èª¤è™•ç†

class TrajectoryStatus(Enum):
    """è»Œè·¡ç‹€æ…‹"""
    ACTIVE = "active"        # æ´»èºæ”¶é›†ä¸­
    COMPLETED = "completed"  # å·²å®Œæˆ
    FAILED = "failed"        # æ”¶é›†å¤±æ•—
    CANCELLED = "cancelled"  # å·²å–æ¶ˆ

@dataclass
class DecisionStep:
    """æ±ºç­–æ­¥é©Ÿè©³ç´°è¨˜éŒ„"""
    step_id: str
    trajectory_id: str
    step_number: int
    timestamp: str
    trajectory_type: TrajectoryType
    
    # è¼¸å…¥æ•¸æ“š
    input_data: Dict[str, Any]
    input_data_hash: str = ""
    
    # æ¨ç†éç¨‹
    reasoning_process: List[str] = field(default_factory=list)
    reasoning_depth_score: float = 0.0
    
    # ä¸­é–“çµæœ
    intermediate_result: Any = None
    intermediate_confidence: float = 0.0
    
    # è¨ˆç®—éç¨‹
    computation_method: str = "default"
    computation_time_ms: float = 0.0
    model_used: Optional[str] = None
    
    # æ•¸æ“šä¾è³´
    data_dependencies: List[str] = field(default_factory=list)
    external_api_calls: List[str] = field(default_factory=list)
    
    # è³ªé‡æŒ‡æ¨™
    confidence_score: float = 0.0
    uncertainty_factors: List[str] = field(default_factory=list)
    validation_checks: Dict[str, bool] = field(default_factory=dict)
    
    # æ€§èƒ½æŒ‡æ¨™
    memory_usage_mb: float = 0.0
    cpu_usage_percent: float = 0.0
    
    def __post_init__(self):
        # è¨ˆç®—è¼¸å…¥æ•¸æ“šçš„å“ˆå¸Œå€¼
        if not self.input_data_hash:
            self.input_data_hash = self._calculate_data_hash(self.input_data)
        
        # è¨ˆç®—æ¨ç†æ·±åº¦åˆ†æ•¸
        if not self.reasoning_depth_score:
            self.reasoning_depth_score = self._calculate_reasoning_depth()
    
    def _calculate_data_hash(self, data: Dict[str, Any]) -> str:
        """è¨ˆç®—æ•¸æ“šçš„å”¯ä¸€å“ˆå¸Œå€¼"""
        try:
            data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
            return hashlib.sha256(data_str.encode('utf-8')).hexdigest()[:16]
        except:
            return str(hash(str(data)))[:16]
    
    def _calculate_reasoning_depth(self) -> float:
        """è¨ˆç®—æ¨ç†æ·±åº¦åˆ†æ•¸"""
        if not self.reasoning_process:
            return 0.0
        
        # åŸºæ–¼æ¨ç†æ­¥é©Ÿæ•¸é‡å’Œå…§å®¹è³ªé‡è¨ˆç®—åˆ†æ•¸
        step_count = len(self.reasoning_process)
        avg_length = sum(len(step) for step in self.reasoning_process) / step_count
        
        # æ¨™æº–åŒ–åˆ†æ•¸
        depth_score = min(1.0, (step_count * avg_length) / 500.0)
        return round(depth_score, 3)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        result = asdict(self)
        result['trajectory_type'] = self.trajectory_type.value
        return result

@dataclass
class TrajectoryMetrics:
    """è»Œè·¡è³ªé‡æŒ‡æ¨™"""
    trajectory_id: str
    
    # åŸºæœ¬æŒ‡æ¨™
    total_steps: int = 0
    total_duration_ms: float = 0.0
    
    # è³ªé‡æŒ‡æ¨™
    avg_confidence: float = 0.0
    confidence_consistency: float = 0.0
    reasoning_depth: float = 0.0
    data_utilization_score: float = 0.0
    
    # æ•ˆç‡æŒ‡æ¨™
    avg_step_duration: float = 0.0
    memory_efficiency: float = 0.0
    api_efficiency: float = 0.0
    
    # å®Œæ•´æ€§æŒ‡æ¨™
    completion_rate: float = 0.0
    error_rate: float = 0.0
    validation_pass_rate: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

@dataclass
class AnalysisTrajectory:
    """å®Œæ•´çš„åˆ†æè»Œè·¡è¨˜éŒ„"""
    trajectory_id: str
    stock_id: str
    analyst_type: str
    analyst_version: str
    user_id: str
    
    # æ™‚é–“ä¿¡æ¯
    start_time: str
    end_time: Optional[str] = None
    total_duration_ms: float = 0.0
    
    # æ±ºç­–æ­¥é©Ÿ
    decision_steps: List[DecisionStep] = field(default_factory=list)
    
    # æœ€çµ‚çµæœ
    final_recommendation: Optional[str] = None
    final_confidence: Optional[float] = None
    final_target_price: Optional[float] = None
    final_reasoning: List[str] = field(default_factory=list)
    
    # ä¸Šä¸‹æ–‡æ•¸æ“š
    context_data: Dict[str, Any] = field(default_factory=dict)
    user_context: Dict[str, Any] = field(default_factory=dict)
    market_context: Dict[str, Any] = field(default_factory=dict)
    
    # ç³»çµ±ä¿¡æ¯
    system_version: str = "1.0.0"
    model_versions: Dict[str, str] = field(default_factory=dict)
    
    # è»Œè·¡ç‹€æ…‹
    status: TrajectoryStatus = TrajectoryStatus.ACTIVE
    error_message: Optional[str] = None
    
    # è³ªé‡æŒ‡æ¨™
    metrics: Optional[TrajectoryMetrics] = None
    
    # ç‰ˆæœ¬æ§åˆ¶
    version: int = 1
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())
    
    def add_decision_step(self, step: DecisionStep):
        """æ·»åŠ æ±ºç­–æ­¥é©Ÿ"""
        step.step_number = len(self.decision_steps) + 1
        step.trajectory_id = self.trajectory_id
        self.decision_steps.append(step)
        self.updated_at = datetime.now().isoformat()
    
    def complete_trajectory(self, recommendation: str, confidence: float, 
                          target_price: Optional[float] = None, 
                          reasoning: List[str] = None):
        """å®Œæˆè»Œè·¡æ”¶é›†"""
        self.end_time = datetime.now().isoformat()
        self.final_recommendation = recommendation
        self.final_confidence = confidence
        self.final_target_price = target_price
        self.final_reasoning = reasoning or []
        self.status = TrajectoryStatus.COMPLETED
        self.updated_at = datetime.now().isoformat()
        
        # è¨ˆç®—ç¸½æŒçºŒæ™‚é–“
        if self.start_time and self.end_time:
            start = datetime.fromisoformat(self.start_time)
            end = datetime.fromisoformat(self.end_time)
            self.total_duration_ms = (end - start).total_seconds() * 1000
        
        # è¨ˆç®—è³ªé‡æŒ‡æ¨™
        self.metrics = self._calculate_metrics()
    
    def fail_trajectory(self, error_message: str):
        """æ¨™è¨˜è»Œè·¡å¤±æ•—"""
        self.status = TrajectoryStatus.FAILED
        self.error_message = error_message
        self.end_time = datetime.now().isoformat()
        self.updated_at = datetime.now().isoformat()
    
    def _calculate_metrics(self) -> TrajectoryMetrics:
        """è¨ˆç®—è»Œè·¡è³ªé‡æŒ‡æ¨™"""
        if not self.decision_steps:
            return TrajectoryMetrics(trajectory_id=self.trajectory_id)
        
        # åŸºæœ¬æŒ‡æ¨™
        total_steps = len(self.decision_steps)
        
        # è³ªé‡æŒ‡æ¨™
        confidences = [step.confidence_score for step in self.decision_steps if step.confidence_score > 0]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
        confidence_consistency = 1.0 - np.std(confidences) if len(confidences) > 1 else 1.0
        
        reasoning_depths = [step.reasoning_depth_score for step in self.decision_steps]
        avg_reasoning_depth = sum(reasoning_depths) / len(reasoning_depths) if reasoning_depths else 0.0
        
        # æ•¸æ“šåˆ©ç”¨ç‡
        all_dependencies = set()
        for step in self.decision_steps:
            all_dependencies.update(step.data_dependencies)
        data_utilization_score = min(1.0, len(all_dependencies) / 10.0)  # å‡è¨­æœ€å¤š10ç¨®æ•¸æ“šæº
        
        # æ•ˆç‡æŒ‡æ¨™
        durations = [step.computation_time_ms for step in self.decision_steps if step.computation_time_ms > 0]
        avg_step_duration = sum(durations) / len(durations) if durations else 0.0
        
        # å®Œæ•´æ€§æŒ‡æ¨™
        validation_results = []
        for step in self.decision_steps:
            if step.validation_checks:
                validation_results.extend(step.validation_checks.values())
        validation_pass_rate = sum(validation_results) / len(validation_results) if validation_results else 1.0
        
        return TrajectoryMetrics(
            trajectory_id=self.trajectory_id,
            total_steps=total_steps,
            total_duration_ms=self.total_duration_ms,
            avg_confidence=avg_confidence,
            confidence_consistency=max(0.0, confidence_consistency),
            reasoning_depth=avg_reasoning_depth,
            data_utilization_score=data_utilization_score,
            avg_step_duration=avg_step_duration,
            completion_rate=1.0 if self.status == TrajectoryStatus.COMPLETED else 0.0,
            validation_pass_rate=validation_pass_rate
        )
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        result = asdict(self)
        result['status'] = self.status.value
        result['decision_steps'] = [step.to_dict() for step in self.decision_steps]
        if self.metrics:
            result['metrics'] = self.metrics.to_dict()
        return result
    
    def get_grpo_training_data(self) -> Dict[str, Any]:
        """ç²å–GRPOè¨“ç·´ç”¨çš„æ•¸æ“šæ ¼å¼"""
        return {
            'trajectory_id': self.trajectory_id,
            'stock_id': self.stock_id,
            'analyst_type': self.analyst_type,
            'user_id': self.user_id,
            'steps': [
                {
                    'step_number': step.step_number,
                    'input': step.input_data,
                    'reasoning': step.reasoning_process,
                    'output': step.intermediate_result,
                    'confidence': step.confidence_score,
                    'method': step.computation_method
                }
                for step in self.decision_steps
            ],
            'final_output': {
                'recommendation': self.final_recommendation,
                'confidence': self.final_confidence,
                'target_price': self.final_target_price,
                'reasoning': self.final_reasoning
            },
            'context': {
                'user_context': self.user_context,
                'market_context': self.market_context
            },
            'quality_metrics': self.metrics.to_dict() if self.metrics else {}
        }

class TrajectoryCollector:
    """ARTè»Œè·¡æ”¶é›†å™¨ - ç”Ÿç”¢ç´šå¯¦ç¾"""
    
    def __init__(self, 
                 storage_path: str = None,
                 max_active_trajectories: int = 1000,
                 auto_save_interval: int = 300,
                 enable_performance_monitoring: bool = True):
        
        # å­˜å„²é…ç½®
        self.storage_path = Path(storage_path) if storage_path else Path("./art_data/trajectories")
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # è»Œè·¡ç®¡ç†
        self.active_trajectories: Dict[str, AnalysisTrajectory] = {}
        self.completed_trajectories: Dict[str, AnalysisTrajectory] = {}
        self.max_active_trajectories = max_active_trajectories
        
        # æ€§èƒ½ç›£æ§
        self.enable_performance_monitoring = enable_performance_monitoring
        self.performance_stats = {
            'total_trajectories_created': 0,
            'total_trajectories_completed': 0,
            'total_steps_recorded': 0,
            'avg_trajectory_duration': 0.0,
            'memory_usage_mb': 0.0
        }
        
        # é…ç½®
        self.config = {
            'min_trajectory_length': 3,
            'max_step_reasoning_length': 1000,
            'auto_save_interval': auto_save_interval,
            'compression_enabled': True,
            'versioning_enabled': True
        }
        
        # æ—¥èªŒè¨˜éŒ„
        self.logger = logging.getLogger(__name__)
        self._setup_logging()
        
        # ç·šç¨‹æ± 
        self.thread_pool = ThreadPoolExecutor(max_workers=4, thread_name_prefix="ART-Collector")
        
        # è‡ªå‹•ä¿å­˜
        self._last_save_time = datetime.now()
        self._auto_save_task = None
        
        # çµ±è¨ˆä¿¡æ¯
        self.collection_stats = defaultdict(int)
        self._stats_lock = threading.Lock()
        
        self.logger.info(f"TrajectoryCollector initialized with storage: {self.storage_path}")
    
    def _setup_logging(self):
        """è¨­ç½®å°ˆç”¨æ—¥èªŒè¨˜éŒ„"""
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - ART-TrajectoryCollector - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
    
    async def start_trajectory(self, 
                              stock_id: str,
                              analyst: 'BaseAnalyst',
                              user_context: Dict[str, Any] = None,
                              market_context: Dict[str, Any] = None,
                              additional_context: Dict[str, Any] = None) -> str:
        """é–‹å§‹è»Œè·¡æ”¶é›† - èˆ‡BaseAnalystæ•´åˆ"""
        
        # æª¢æŸ¥æ´»èºè»Œè·¡é™åˆ¶
        if len(self.active_trajectories) >= self.max_active_trajectories:
            await self._cleanup_old_trajectories()
        
        # ç”Ÿæˆè»Œè·¡ID
        trajectory_id = self._generate_trajectory_id(stock_id, analyst, user_context)
        
        # ç²å–åˆ†æå¸«ä¿¡æ¯
        analyst_info = analyst.get_analyst_info() if hasattr(analyst, 'get_analyst_info') else {}
        analyst_type = getattr(analyst, 'analyst_id', analyst.__class__.__name__)
        analyst_version = analyst_info.get('version', '1.0.0')
        
        # å‰µå»ºè»Œè·¡è¨˜éŒ„
        trajectory = AnalysisTrajectory(
            trajectory_id=trajectory_id,
            stock_id=stock_id,
            analyst_type=analyst_type,
            analyst_version=analyst_version,
            user_id=user_context.get('user_id', 'anonymous') if user_context else 'anonymous',
            start_time=datetime.now().isoformat(),
            user_context=user_context or {},
            market_context=market_context or {},
            context_data=additional_context or {},
            model_versions=analyst_info.get('model_versions', {})
        )
        
        # æ·»åŠ åˆ°æ´»èºè»Œè·¡
        self.active_trajectories[trajectory_id] = trajectory
        
        # æ›´æ–°çµ±è¨ˆ
        with self._stats_lock:
            self.collection_stats['trajectories_started'] += 1
            self.performance_stats['total_trajectories_created'] += 1
        
        self.logger.info(f"Started trajectory collection: {trajectory_id} for {analyst_type} on {stock_id}")
        return trajectory_id
    
    def _generate_trajectory_id(self, stock_id: str, analyst: Any, user_context: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„è»Œè·¡ID"""
        user_id = user_context.get('user_id', 'anonymous') if user_context else 'anonymous'
        analyst_type = getattr(analyst, 'analyst_id', analyst.__class__.__name__)
        timestamp = str(int(datetime.now().timestamp() * 1000))  # æ¯«ç§’ç´šæ™‚é–“æˆ³
        unique_suffix = str(uuid.uuid4())[:8]
        
        return f"{analyst_type}_{stock_id}_{user_id}_{timestamp}_{unique_suffix}"
    
    async def record_step(self,
                         trajectory_id: str,
                         trajectory_type: TrajectoryType,
                         input_data: Dict[str, Any],
                         reasoning_process: List[str],
                         intermediate_result: Any = None,
                         confidence_score: float = 0.0,
                         computation_method: str = "default",
                         model_used: Optional[str] = None,
                         computation_time_ms: float = 0.0,
                         uncertainty_factors: List[str] = None,
                         validation_checks: Dict[str, bool] = None) -> str:
        """è¨˜éŒ„æ±ºç­–æ­¥é©Ÿ - å¢å¼·ç‰ˆæœ¬"""
        
        if trajectory_id not in self.active_trajectories:
            raise ValueError(f"Trajectory not found or not active: {trajectory_id}")
        
        trajectory = self.active_trajectories[trajectory_id]
        
        # ç”Ÿæˆæ­¥é©ŸID
        step_id = f"{trajectory_id}_step_{len(trajectory.decision_steps) + 1}"
        
        # æ€§èƒ½ç›£æ§
        memory_usage = 0.0
        cpu_usage = 0.0
        if self.enable_performance_monitoring:
            try:
                import psutil
                process = psutil.Process()
                memory_usage = process.memory_info().rss / 1024 / 1024  # MB
                cpu_usage = process.cpu_percent()
            except ImportError:
                pass
        
        # åˆ†ææ•¸æ“šä¾è³´
        data_dependencies = self._analyze_data_dependencies(input_data)
        external_api_calls = self._extract_api_calls(input_data)
        
        # å‰µå»ºæ±ºç­–æ­¥é©Ÿ
        step = DecisionStep(
            step_id=step_id,
            trajectory_id=trajectory_id,
            step_number=len(trajectory.decision_steps) + 1,
            timestamp=datetime.now().isoformat(),
            trajectory_type=trajectory_type,
            input_data=input_data,
            reasoning_process=reasoning_process[:self.config['max_step_reasoning_length']],  # é™åˆ¶é•·åº¦
            intermediate_result=intermediate_result,
            intermediate_confidence=confidence_score,
            computation_method=computation_method,
            model_used=model_used,
            computation_time_ms=computation_time_ms,
            data_dependencies=data_dependencies,
            external_api_calls=external_api_calls,
            confidence_score=confidence_score,
            uncertainty_factors=uncertainty_factors or [],
            validation_checks=validation_checks or {},
            memory_usage_mb=memory_usage,
            cpu_usage_percent=cpu_usage
        )
        
        # æ·»åŠ åˆ°è»Œè·¡
        trajectory.add_decision_step(step)
        
        # æ›´æ–°çµ±è¨ˆ
        with self._stats_lock:
            self.collection_stats['steps_recorded'] += 1
            self.performance_stats['total_steps_recorded'] += 1
        
        self.logger.debug(f"Recorded step: {step_id} ({trajectory_type.value})")
        return step_id
    
    def _analyze_data_dependencies(self, input_data: Dict[str, Any]) -> List[str]:
        """åˆ†ææ•¸æ“šä¾è³´é—œä¿‚"""
        dependencies = []
        
        # æª¢æŸ¥å¸¸è¦‹æ•¸æ“šé¡å‹
        dependency_mapping = {
            'stock_price': 'market_data',
            'financial_data': 'financial_statements',
            'income_statement': 'financial_statements',
            'balance_sheet': 'financial_statements',
            'cash_flow': 'financial_statements',
            'news_data': 'news_sources',
            'sentiment_data': 'sentiment_analysis',
            'technical_indicators': 'technical_analysis',
            'sector_comparison': 'industry_data',
            'peer_analysis': 'industry_data',
            'market_data': 'market_data',
            'macro_data': 'macroeconomic_data',
            'taiwan_institutional_data': 'institutional_data',
            'taiwan_market_conditions': 'taiwan_market_data'
        }
        
        for key in input_data.keys():
            for pattern, dependency in dependency_mapping.items():
                if pattern in key.lower():
                    if dependency not in dependencies:
                        dependencies.append(dependency)
                    break
        
        return dependencies
    
    def _extract_api_calls(self, input_data: Dict[str, Any]) -> List[str]:
        """æå–APIèª¿ç”¨è¨˜éŒ„"""
        api_calls = []
        
        # æª¢æŸ¥æ•¸æ“šä¾†æºæ¨™è¨˜
        if isinstance(input_data, dict):
            if input_data.get('source') == 'finmind_api':
                api_calls.append('FinMind API')
            elif input_data.get('source') == 'finnhub_api':
                api_calls.append('Finnhub API')
            elif 'api_source' in input_data:
                api_calls.append(input_data['api_source'])
        
        return api_calls
    
    async def complete_trajectory(self,
                                trajectory_id: str,
                                final_recommendation: str,
                                final_confidence: float,
                                final_target_price: Optional[float] = None,
                                final_reasoning: List[str] = None) -> AnalysisTrajectory:
        """å®Œæˆè»Œè·¡æ”¶é›†"""
        
        if trajectory_id not in self.active_trajectories:
            raise ValueError(f"Active trajectory not found: {trajectory_id}")
        
        trajectory = self.active_trajectories[trajectory_id]
        
        # å®Œæˆè»Œè·¡
        trajectory.complete_trajectory(
            recommendation=final_recommendation,
            confidence=final_confidence,
            target_price=final_target_price,
            reasoning=final_reasoning
        )
        
        # ç§»å‹•åˆ°å®Œæˆè»Œè·¡
        self.completed_trajectories[trajectory_id] = trajectory
        del self.active_trajectories[trajectory_id]
        
        # ä¿å­˜è»Œè·¡
        await self._save_trajectory(trajectory)
        
        # æ›´æ–°çµ±è¨ˆ
        with self._stats_lock:
            self.collection_stats['trajectories_completed'] += 1
            self.performance_stats['total_trajectories_completed'] += 1
        
        self.logger.info(f"Completed trajectory: {trajectory_id}")
        return trajectory
    
    async def fail_trajectory(self, trajectory_id: str, error_message: str) -> AnalysisTrajectory:
        """æ¨™è¨˜è»Œè·¡å¤±æ•—"""
        
        if trajectory_id not in self.active_trajectories:
            raise ValueError(f"Active trajectory not found: {trajectory_id}")
        
        trajectory = self.active_trajectories[trajectory_id]
        trajectory.fail_trajectory(error_message)
        
        # ç§»å‹•åˆ°å®Œæˆè»Œè·¡ï¼ˆå¤±æ•—ä¹Ÿç®—å®Œæˆï¼‰
        self.completed_trajectories[trajectory_id] = trajectory
        del self.active_trajectories[trajectory_id]
        
        # ä¿å­˜è»Œè·¡
        await self._save_trajectory(trajectory)
        
        # æ›´æ–°çµ±è¨ˆ
        with self._stats_lock:
            self.collection_stats['trajectories_failed'] += 1
        
        self.logger.warning(f"Failed trajectory: {trajectory_id} - {error_message}")
        return trajectory
    
    async def get_trajectory(self, trajectory_id: str) -> Optional[AnalysisTrajectory]:
        """ç²å–è»Œè·¡è¨˜éŒ„"""
        
        # é¦–å…ˆæª¢æŸ¥æ´»èºè»Œè·¡
        if trajectory_id in self.active_trajectories:
            return self.active_trajectories[trajectory_id]
        
        # ç„¶å¾Œæª¢æŸ¥å®Œæˆè»Œè·¡
        if trajectory_id in self.completed_trajectories:
            return self.completed_trajectories[trajectory_id]
        
        # æœ€å¾Œå˜—è©¦å¾å­˜å„²åŠ è¼‰
        try:
            trajectory = await self._load_trajectory(trajectory_id)
            if trajectory:
                self.completed_trajectories[trajectory_id] = trajectory
            return trajectory
        except Exception as e:
            self.logger.error(f"Failed to load trajectory {trajectory_id}: {e}")
            return None
    
    async def get_user_trajectories(self, 
                                  user_id: str,
                                  limit: int = 100,
                                  analyst_type: Optional[str] = None,
                                  status: Optional[TrajectoryStatus] = None) -> List[AnalysisTrajectory]:
        """ç²å–ç”¨æˆ¶çš„è»Œè·¡è¨˜éŒ„"""
        
        trajectories = []
        
        # æœå°‹å®Œæˆè»Œè·¡
        for trajectory in self.completed_trajectories.values():
            if trajectory.user_id == user_id:
                if analyst_type and trajectory.analyst_type != analyst_type:
                    continue
                if status and trajectory.status != status:
                    continue
                trajectories.append(trajectory)
        
        # æœå°‹æ´»èºè»Œè·¡
        for trajectory in self.active_trajectories.values():
            if trajectory.user_id == user_id:
                if analyst_type and trajectory.analyst_type != analyst_type:
                    continue
                if status and trajectory.status != status:
                    continue
                trajectories.append(trajectory)
        
        # æŒ‰æ™‚é–“æ’åºä¸¦é™åˆ¶æ•¸é‡
        trajectories.sort(key=lambda x: x.start_time, reverse=True)
        return trajectories[:limit]
    
    async def get_grpo_training_data(self, 
                                   user_id: str,
                                   min_quality_score: float = 0.5,
                                   limit: int = 500) -> List[Dict[str, Any]]:
        """ç²å–GRPOè¨“ç·´æ•¸æ“š"""
        
        user_trajectories = await self.get_user_trajectories(
            user_id=user_id,
            status=TrajectoryStatus.COMPLETED,
            limit=limit * 2  # ç²å–æ›´å¤šä»¥ä¾¿éæ¿¾
        )
        
        training_data = []
        for trajectory in user_trajectories:
            # æª¢æŸ¥è»Œè·¡è³ªé‡
            if trajectory.metrics and self._calculate_trajectory_quality_score(trajectory.metrics) >= min_quality_score:
                # æª¢æŸ¥æœ€å°æ­¥é©Ÿæ•¸
                if len(trajectory.decision_steps) >= self.config['min_trajectory_length']:
                    training_data.append(trajectory.get_grpo_training_data())
        
        return training_data[:limit]
    
    def _calculate_trajectory_quality_score(self, metrics: TrajectoryMetrics) -> float:
        """è¨ˆç®—è»Œè·¡ç¶œåˆè³ªé‡åˆ†æ•¸"""
        weights = {
            'avg_confidence': 0.3,
            'confidence_consistency': 0.2,
            'reasoning_depth': 0.2,
            'data_utilization_score': 0.15,
            'completion_rate': 0.1,
            'validation_pass_rate': 0.05
        }
        
        score = 0.0
        for metric, weight in weights.items():
            score += getattr(metrics, metric, 0.0) * weight
        
        return min(1.0, score)
    
    async def _save_trajectory(self, trajectory: AnalysisTrajectory):
        """ä¿å­˜è»Œè·¡åˆ°å­˜å„²"""
        try:
            trajectory_file = self.storage_path / f"trajectory_{trajectory.trajectory_id}.json"
            
            # ä½¿ç”¨ç·šç¨‹æ± é€²è¡Œç•°æ­¥ä¿å­˜
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                self.thread_pool,
                self._sync_save_trajectory,
                trajectory_file,
                trajectory.to_dict()
            )
            
        except Exception as e:
            self.logger.error(f"Failed to save trajectory {trajectory.trajectory_id}: {e}")
    
    def _sync_save_trajectory(self, file_path: Path, trajectory_data: Dict[str, Any]):
        """åŒæ­¥ä¿å­˜è»Œè·¡æ•¸æ“š"""
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(trajectory_data, f, ensure_ascii=False, indent=2)
    
    async def _load_trajectory(self, trajectory_id: str) -> Optional[AnalysisTrajectory]:
        """å¾å­˜å„²åŠ è¼‰è»Œè·¡"""
        try:
            trajectory_file = self.storage_path / f"trajectory_{trajectory_id}.json"
            if not trajectory_file.exists():
                return None
            
            # ä½¿ç”¨ç·šç¨‹æ± é€²è¡Œç•°æ­¥åŠ è¼‰
            loop = asyncio.get_event_loop()
            trajectory_data = await loop.run_in_executor(
                self.thread_pool,
                self._sync_load_trajectory,
                trajectory_file
            )
            
            if trajectory_data:
                return self._deserialize_trajectory(trajectory_data)
            
        except Exception as e:
            self.logger.error(f"Failed to load trajectory {trajectory_id}: {e}")
        
        return None
    
    def _sync_load_trajectory(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """åŒæ­¥åŠ è¼‰è»Œè·¡æ•¸æ“š"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return None
    
    def _deserialize_trajectory(self, data: Dict[str, Any]) -> AnalysisTrajectory:
        """ååºåˆ—åŒ–è»Œè·¡æ•¸æ“š"""
        # é‡å»ºæ±ºç­–æ­¥é©Ÿ
        decision_steps = []
        for step_data in data.get('decision_steps', []):
            step = DecisionStep(
                step_id=step_data['step_id'],
                trajectory_id=step_data['trajectory_id'],
                step_number=step_data['step_number'],
                timestamp=step_data['timestamp'],
                trajectory_type=TrajectoryType(step_data['trajectory_type']),
                input_data=step_data['input_data'],
                reasoning_process=step_data['reasoning_process'],
                intermediate_result=step_data.get('intermediate_result'),
                confidence_score=step_data['confidence_score'],
                computation_method=step_data['computation_method'],
                data_dependencies=step_data.get('data_dependencies', []),
                model_used=step_data.get('model_used')
            )
            decision_steps.append(step)
        
        # é‡å»ºè»Œè·¡
        trajectory = AnalysisTrajectory(
            trajectory_id=data['trajectory_id'],
            stock_id=data['stock_id'],
            analyst_type=data['analyst_type'],
            analyst_version=data.get('analyst_version', '1.0.0'),
            user_id=data['user_id'],
            start_time=data['start_time'],
            end_time=data.get('end_time'),
            decision_steps=decision_steps,
            final_recommendation=data.get('final_recommendation'),
            final_confidence=data.get('final_confidence'),
            final_target_price=data.get('final_target_price'),
            final_reasoning=data.get('final_reasoning', []),
            context_data=data.get('context_data', {}),
            user_context=data.get('user_context', {}),
            market_context=data.get('market_context', {}),
            status=TrajectoryStatus(data.get('status', 'completed'))
        )
        
        # é‡å»ºè³ªé‡æŒ‡æ¨™
        if data.get('metrics'):
            metrics_data = data['metrics']
            trajectory.metrics = TrajectoryMetrics(
                trajectory_id=metrics_data['trajectory_id'],
                total_steps=metrics_data.get('total_steps', 0),
                total_duration_ms=metrics_data.get('total_duration_ms', 0.0),
                avg_confidence=metrics_data.get('avg_confidence', 0.0),
                confidence_consistency=metrics_data.get('confidence_consistency', 0.0),
                reasoning_depth=metrics_data.get('reasoning_depth', 0.0),
                data_utilization_score=metrics_data.get('data_utilization_score', 0.0),
                completion_rate=metrics_data.get('completion_rate', 0.0),
                validation_pass_rate=metrics_data.get('validation_pass_rate', 0.0)
            )
        
        return trajectory
    
    async def _cleanup_old_trajectories(self):
        """æ¸…ç†èˆŠçš„æ´»èºè»Œè·¡"""
        current_time = datetime.now()
        trajectories_to_remove = []
        
        for trajectory_id, trajectory in self.active_trajectories.items():
            start_time = datetime.fromisoformat(trajectory.start_time)
            if (current_time - start_time) > timedelta(hours=24):  # è¶…é24å°æ™‚çš„æ´»èºè»Œè·¡
                trajectories_to_remove.append(trajectory_id)
        
        for trajectory_id in trajectories_to_remove:
            await self.fail_trajectory(trajectory_id, "Trajectory timeout - auto cleanup")
    
    def get_collection_statistics(self) -> Dict[str, Any]:
        """ç²å–æ”¶é›†çµ±è¨ˆä¿¡æ¯"""
        with self._stats_lock:
            stats = self.collection_stats.copy()
            stats.update(self.performance_stats)
        
        stats.update({
            'active_trajectories': len(self.active_trajectories),
            'completed_trajectories': len(self.completed_trajectories),
            'storage_path': str(self.storage_path),
            'system_status': 'active'
        })
        
        return stats
    
    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        # ä¿å­˜æ‰€æœ‰æ´»èºè»Œè·¡
        for trajectory_id in list(self.active_trajectories.keys()):
            await self.fail_trajectory(trajectory_id, "System shutdown")
        
        # é—œé–‰ç·šç¨‹æ± 
        self.thread_pool.shutdown(wait=True)
        
        self.logger.info("TrajectoryCollector cleanup completed")

# å·¥å» å‡½æ•¸å’Œä¾¿åˆ©å‡½æ•¸
async def create_trajectory_collector(
    storage_path: str = None,
    max_active_trajectories: int = 1000,
    auto_save_interval: int = 300,
    enable_performance_monitoring: bool = True
) -> TrajectoryCollector:
    """å‰µå»ºè»Œè·¡æ”¶é›†å™¨å¯¦ä¾‹"""
    
    collector = TrajectoryCollector(
        storage_path=storage_path,
        max_active_trajectories=max_active_trajectories,
        auto_save_interval=auto_save_interval,
        enable_performance_monitoring=enable_performance_monitoring
    )
    
    return collector

async def create_trajectory_collector_with_base_analyst_integration() -> TrajectoryCollector:
    """å‰µå»ºèˆ‡BaseAnalystå®Œå…¨æ•´åˆçš„è»Œè·¡æ”¶é›†å™¨"""
    
    if not BASE_ANALYST_AVAILABLE:
        raise RuntimeError("BaseAnalyst not available. Cannot create integrated trajectory collector.")
    
    # ä½¿ç”¨å„ªåŒ–è¨­ç½®
    collector = TrajectoryCollector(
        storage_path="./art_data/trajectories",
        max_active_trajectories=2000,  # æ›´å¤§çš„å®¹é‡
        auto_save_interval=180,        # æ›´é »ç¹çš„è‡ªå‹•ä¿å­˜
        enable_performance_monitoring=True
    )
    
    return collector


# è‡ªå‹•æª¢æ¸¬å’Œåˆ‡æ›åˆ° TradingAgents ç›®éŒ„
def ensure_tradingagents_directory():
    """ç¢ºä¿ç•¶å‰å·¥ä½œç›®éŒ„åœ¨ TradingAgents/ ä¸‹ï¼Œä»¥æ­£ç¢ºè¨ªå•é…ç½®æ–‡ä»¶"""
    current_dir = Path.cwd()
    
    # å¦‚æœç•¶å‰ç›®éŒ„æ˜¯ TradingAgents çš„çˆ¶ç›®éŒ„ï¼Œåˆ‡æ›åˆ° TradingAgents
    if (current_dir / 'TradingAgents').exists():
        os.chdir(current_dir / 'TradingAgents')
        print(f"[DIR] è‡ªå‹•åˆ‡æ›å·¥ä½œç›®éŒ„åˆ°: {Path.cwd()}")
    
    # é©—è­‰å¿…è¦çš„ç›®éŒ„å­˜åœ¨
    required_dirs = ['configs', 'training', 'tradingagents']
    missing_dirs = [d for d in required_dirs if not Path(d).exists()]
    
    if missing_dirs:
        raise FileNotFoundError(f"ç¼ºå°‘å¿…è¦ç›®éŒ„: {missing_dirs}. è«‹ç¢ºä¿å¾ TradingAgents/ ç›®éŒ„åŸ·è¡Œæ­¤è…³æœ¬")

# ç›®éŒ„æª¢æŸ¥å‡½æ•¸å·²æº–å‚™å¥½ï¼Œä½†ä¸åœ¨æ¨¡çµ„å°å…¥æ™‚è‡ªå‹•åŸ·è¡Œ
# åªåœ¨éœ€è¦æ™‚æ‰‹å‹•èª¿ç”¨ ensure_tradingagents_directory()

if __name__ == "__main__":
    # æ¸¬è©¦è…³æœ¬
    import asyncio
    
    async def test_trajectory_collector():
        print("ğŸš€ æ¸¬è©¦TrajectoryCollector")
        
        # å‰µå»ºæ”¶é›†å™¨
        collector = await create_trajectory_collector("./test_trajectories")
        
        # æ¨¡æ“¬åˆ†æå¸«
        class MockAnalyst:
            analyst_id = "test_analyst"
            
            def get_analyst_info(self):
                return {'version': '1.0.0', 'type': 'fundamental'}
        
        analyst = MockAnalyst()
        
        # é–‹å§‹è»Œè·¡
        trajectory_id = await collector.start_trajectory(
            stock_id="2330",
            analyst=analyst,
            user_context={'user_id': 'test_user', 'membership_tier': 'GOLD'}
        )
        
        print(f"ğŸ“Š é–‹å§‹è»Œè·¡: {trajectory_id}")
        
        # è¨˜éŒ„æ­¥é©Ÿ
        await collector.record_step(
            trajectory_id=trajectory_id,
            trajectory_type=TrajectoryType.DATA_COLLECTION,
            input_data={'stock_price': 580, 'pe_ratio': 22.5},
            reasoning_process=['æ”¶é›†è‚¡åƒ¹æ•¸æ“š', 'åˆ†ææœ¬ç›Šæ¯”'],
            intermediate_result={'data_quality': 'good'},
            confidence_score=0.9,
            computation_time_ms=150.0
        )
        
        await collector.record_step(
            trajectory_id=trajectory_id,
            trajectory_type=TrajectoryType.RECOMMENDATION_LOGIC,
            input_data={'financial_score': 8.5, 'technical_score': 7.2},
            reasoning_process=['ç¶œåˆè²¡å‹™æŒ‡æ¨™', 'è€ƒæ…®æŠ€è¡“é¢', 'çµ¦å‡ºå»ºè­°'],
            intermediate_result={'recommendation': 'BUY'},
            confidence_score=0.85,
            computation_time_ms=300.0
        )
        
        # å®Œæˆè»Œè·¡
        completed_trajectory = await collector.complete_trajectory(
            trajectory_id=trajectory_id,
            final_recommendation='BUY',
            final_confidence=0.87,
            final_target_price=650.0,
            final_reasoning=['è²¡å‹™æŒ‡æ¨™å„ªç•°', 'æŠ€è¡“é¢æ”¯æ’', 'å»ºè­°è²·å…¥']
        )
        
        print(f"âœ… å®Œæˆè»Œè·¡ï¼Œè³ªé‡åˆ†æ•¸: {collector._calculate_trajectory_quality_score(completed_trajectory.metrics):.3f}")
        
        # ç²å–çµ±è¨ˆ
        stats = collector.get_collection_statistics()
        print(f"ğŸ“ˆ çµ±è¨ˆä¿¡æ¯: {stats}")
        
        # ç²å–GRPOæ•¸æ“š
        grpo_data = await collector.get_grpo_training_data('test_user')
        print(f"ğŸ¯ GRPOè¨“ç·´æ•¸æ“š: {len(grpo_data)} æ¢è¨˜éŒ„")
        
        # æ¸…ç†
        await collector.cleanup()
        
        print("âœ… TrajectoryCollectoræ¸¬è©¦å®Œæˆ")
    
    asyncio.run(test_trajectory_collector())