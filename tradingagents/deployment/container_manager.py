#!/usr/bin/env python3
"""
å®¹å™¨ç®¡ç†å™¨ (Container Manager)
å¤©å·¥é–‹ç‰©ç³»çµ±çš„å®¹å™¨åŒ–éƒ¨ç½²å’Œç®¡ç†

æ­¤æ¨¡çµ„æä¾›ï¼š
1. Docker å®¹å™¨ç®¡ç†
2. Kubernetes éƒ¨ç½²ç®¡ç†
3. å®¹å™¨ç·¨æ’å’Œå”èª¿
4. å®¹å™¨ç›£æ§å’Œæ—¥èªŒ
5. å®¹å™¨å®‰å…¨é…ç½®
6. å®¹å™¨ç¶²è·¯ç®¡ç†

ç”±å¢¨å­(DevOpså·¥ç¨‹å¸«)è¨­è¨ˆå¯¦ç¾
"""

import asyncio
import docker
import yaml
import json
import subprocess
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field, asdict
from enum import Enum
import uuid
from datetime import datetime
from pathlib import Path
import logging

from ..utils.logging_config import get_system_logger
from ..utils.error_handler import handle_error
from ..utils.resilience_manager import get_global_resilience_manager

logger = get_system_logger("container_manager")

class ContainerPlatform(Enum):
    """å®¹å™¨å¹³å°"""
    DOCKER = "docker"
    KUBERNETES = "kubernetes"
    DOCKER_SWARM = "docker_swarm"
    PODMAN = "podman"

class ContainerStatus(Enum):
    """å®¹å™¨ç‹€æ…‹"""
    CREATED = "created"
    RUNNING = "running"
    PAUSED = "paused"
    STOPPED = "stopped"
    RESTARTING = "restarting"
    REMOVING = "removing"
    EXITED = "exited"
    DEAD = "dead"

class NetworkMode(Enum):
    """ç¶²è·¯æ¨¡å¼"""
    BRIDGE = "bridge"
    HOST = "host"
    NONE = "none"
    CONTAINER = "container"
    CUSTOM = "custom"

@dataclass
class DockerConfiguration:
    """Docker é…ç½®"""
    config_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    image_name: str = ""
    image_tag: str = "latest"
    container_name: str = ""
    ports: Dict[str, str] = field(default_factory=dict)  # host_port: container_port
    environment: Dict[str, str] = field(default_factory=dict)
    volumes: Dict[str, str] = field(default_factory=dict)  # host_path: container_path
    network_mode: NetworkMode = NetworkMode.BRIDGE
    restart_policy: str = "unless-stopped"
    memory_limit: Optional[str] = None
    cpu_limit: Optional[str] = None
    health_check: Optional[Dict[str, Any]] = None
    labels: Dict[str, str] = field(default_factory=dict)
    command: Optional[List[str]] = None
    working_dir: Optional[str] = None
    user: Optional[str] = None
    privileged: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['network_mode'] = self.network_mode.value
        return data

@dataclass
class KubernetesConfiguration:
    """Kubernetes é…ç½®"""
    config_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    namespace: str = "default"
    deployment_name: str = ""
    replicas: int = 1
    image: str = ""
    ports: List[Dict[str, Any]] = field(default_factory=list)
    environment: Dict[str, str] = field(default_factory=dict)
    volumes: List[Dict[str, Any]] = field(default_factory=list)
    resource_requests: Dict[str, str] = field(default_factory=dict)
    resource_limits: Dict[str, str] = field(default_factory=dict)
    health_checks: Dict[str, Any] = field(default_factory=dict)
    service_config: Dict[str, Any] = field(default_factory=dict)
    ingress_config: Optional[Dict[str, Any]] = None
    config_maps: List[Dict[str, Any]] = field(default_factory=list)
    secrets: List[Dict[str, Any]] = field(default_factory=list)
    labels: Dict[str, str] = field(default_factory=dict)
    annotations: Dict[str, str] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

@dataclass
class ContainerInfo:
    """å®¹å™¨è³‡è¨Š"""
    container_id: str = ""
    name: str = ""
    image: str = ""
    status: ContainerStatus = ContainerStatus.CREATED
    created_at: Optional[datetime] = None
    started_at: Optional[datetime] = None
    ports: Dict[str, str] = field(default_factory=dict)
    environment: Dict[str, str] = field(default_factory=dict)
    network_settings: Dict[str, Any] = field(default_factory=dict)
    resource_usage: Dict[str, Any] = field(default_factory=dict)
    health_status: Optional[str] = None
    logs: List[str] = field(default_factory=list)

@dataclass
class DeploymentInfo:
    """éƒ¨ç½²è³‡è¨Š"""
    deployment_id: str = ""
    name: str = ""
    namespace: str = ""
    replicas: int = 0
    available_replicas: int = 0
    ready_replicas: int = 0
    updated_replicas: int = 0
    status: str = ""
    created_at: Optional[datetime] = None
    conditions: List[Dict[str, Any]] = field(default_factory=list)

class ContainerManager:
    """å®¹å™¨ç®¡ç†å™¨ - å¤©å·¥é–‹ç‰©ç³»çµ±å®¹å™¨åŒ–éƒ¨ç½²æ ¸å¿ƒçµ„ä»¶"""
    
    def __init__(self, platform: ContainerPlatform = ContainerPlatform.DOCKER):
        self.platform = platform
        self.resilience_manager = get_global_resilience_manager()
        
        # Docker å®¢æˆ¶ç«¯
        self.docker_client = None
        if platform == ContainerPlatform.DOCKER:
            try:
                self.docker_client = docker.from_env()
                logger.info("Docker å®¢æˆ¶ç«¯é€£æ¥æˆåŠŸ")
            except Exception as e:
                logger.warning(f"Docker å®¢æˆ¶ç«¯é€£æ¥å¤±æ•—: {e}")
        
        # å®¹å™¨è¿½è¹¤
        self.managed_containers: Dict[str, ContainerInfo] = {}
        self.managed_deployments: Dict[str, DeploymentInfo] = {}
        
        logger.info(f"å®¹å™¨ç®¡ç†å™¨å·²åˆå§‹åŒ–", extra={
            'platform': platform.value,
            'docker_available': self.docker_client is not None
        })
    
    async def build_image(self, 
                         dockerfile_path: str,
                         image_name: str,
                         image_tag: str = "latest",
                         build_args: Optional[Dict[str, str]] = None,
                         no_cache: bool = False) -> str:
        """å»ºç½® Docker æ˜ åƒ"""
        
        if not self.docker_client:
            raise RuntimeError("Docker å®¢æˆ¶ç«¯æœªé€£æ¥")
        
        full_image_name = f"{image_name}:{image_tag}"
        
        logger.info(f"é–‹å§‹å»ºç½®æ˜ åƒ: {full_image_name}", extra={
            'dockerfile_path': dockerfile_path,
            'build_args': build_args,
            'no_cache': no_cache
        })
        
        try:
            # å»ºç½®æ˜ åƒ
            image, build_logs = self.docker_client.images.build(
                path=dockerfile_path,
                tag=full_image_name,
                buildargs=build_args or {},
                nocache=no_cache,
                rm=True
            )
            
            # è™•ç†å»ºç½®æ—¥èªŒ
            build_output = []
            for log in build_logs:
                if 'stream' in log:
                    build_output.append(log['stream'].strip())
            
            logger.info(f"æ˜ åƒå»ºç½®æˆåŠŸ: {full_image_name}", extra={
                'image_id': image.id,
                'image_size': image.attrs.get('Size', 0),
                'build_logs_count': len(build_output)
            })
            
            return image.id
            
        except Exception as e:
            logger.error(f"æ˜ åƒå»ºç½®å¤±æ•—: {full_image_name} - {e}")
            raise
    
    async def run_container(self, config: DockerConfiguration) -> ContainerInfo:
        """é‹è¡Œ Docker å®¹å™¨"""
        
        if not self.docker_client:
            raise RuntimeError("Docker å®¢æˆ¶ç«¯æœªé€£æ¥")
        
        full_image_name = f"{config.image_name}:{config.image_tag}"
        
        logger.info(f"é–‹å§‹é‹è¡Œå®¹å™¨: {config.container_name}", extra={
            'image': full_image_name,
            'ports': config.ports,
            'environment_vars': len(config.environment)
        })
        
        try:
            # æº–å‚™å®¹å™¨é…ç½®
            container_kwargs = {
                'image': full_image_name,
                'name': config.container_name,
                'ports': config.ports,
                'environment': config.environment,
                'volumes': config.volumes,
                'network_mode': config.network_mode.value,
                'restart_policy': {"Name": config.restart_policy},
                'labels': config.labels,
                'detach': True
            }
            
            # æ·»åŠ è³‡æºé™åˆ¶
            if config.memory_limit or config.cpu_limit:
                container_kwargs['mem_limit'] = config.memory_limit
                if config.cpu_limit:
                    container_kwargs['cpu_period'] = 100000
                    container_kwargs['cpu_quota'] = int(float(config.cpu_limit) * 100000)
            
            # æ·»åŠ å‘½ä»¤å’Œå·¥ä½œç›®éŒ„
            if config.command:
                container_kwargs['command'] = config.command
            if config.working_dir:
                container_kwargs['working_dir'] = config.working_dir
            if config.user:
                container_kwargs['user'] = config.user
            
            # æ·»åŠ æ¬Šé™è¨­ç½®
            container_kwargs['privileged'] = config.privileged
            
            # æ·»åŠ å¥åº·æª¢æŸ¥
            if config.health_check:
                container_kwargs['healthcheck'] = config.health_check
            
            # å‰µå»ºä¸¦å•Ÿå‹•å®¹å™¨
            container = self.docker_client.containers.run(**container_kwargs)
            
            # ç­‰å¾…å®¹å™¨å•Ÿå‹•
            await asyncio.sleep(1)
            container.reload()
            
            # å‰µå»ºå®¹å™¨è³‡è¨Š
            container_info = self._create_container_info(container)
            self.managed_containers[container.id] = container_info
            
            logger.info(f"å®¹å™¨é‹è¡ŒæˆåŠŸ: {config.container_name}", extra={
                'container_id': container.id,
                'status': container_info.status.value
            })
            
            return container_info
            
        except Exception as e:
            logger.error(f"å®¹å™¨é‹è¡Œå¤±æ•—: {config.container_name} - {e}")
            raise
    
    def _create_container_info(self, container) -> ContainerInfo:
        """å‰µå»ºå®¹å™¨è³‡è¨Šå°è±¡"""
        
        attrs = container.attrs
        
        # è§£ææ™‚é–“
        created_at = None
        started_at = None
        if 'Created' in attrs:
            created_at = datetime.fromisoformat(attrs['Created'].replace('Z', '+00:00'))
        if 'State' in attrs and 'StartedAt' in attrs['State']:
            started_at_str = attrs['State']['StartedAt']
            if started_at_str != '0001-01-01T00:00:00Z':
                started_at = datetime.fromisoformat(started_at_str.replace('Z', '+00:00'))
        
        # è§£æç‹€æ…‹
        status = ContainerStatus.CREATED
        if 'State' in attrs:
            state = attrs['State']['Status']
            try:
                status = ContainerStatus(state)
            except ValueError:
                status = ContainerStatus.CREATED
        
        # è§£æç«¯å£
        ports = {}
        if 'NetworkSettings' in attrs and 'Ports' in attrs['NetworkSettings']:
            for container_port, host_configs in attrs['NetworkSettings']['Ports'].items():
                if host_configs:
                    for host_config in host_configs:
                        host_port = host_config.get('HostPort')
                        if host_port:
                            ports[host_port] = container_port
        
        # è§£æç’°å¢ƒè®Šæ•¸
        environment = {}
        if 'Config' in attrs and 'Env' in attrs['Config']:
            for env_var in attrs['Config']['Env']:
                if '=' in env_var:
                    key, value = env_var.split('=', 1)
                    environment[key] = value
        
        # è§£æå¥åº·ç‹€æ…‹
        health_status = None
        if 'State' in attrs and 'Health' in attrs['State']:
            health_status = attrs['State']['Health'].get('Status')
        
        return ContainerInfo(
            container_id=container.id,
            name=container.name,
            image=attrs.get('Config', {}).get('Image', ''),
            status=status,
            created_at=created_at,
            started_at=started_at,
            ports=ports,
            environment=environment,
            network_settings=attrs.get('NetworkSettings', {}),
            health_status=health_status
        )
    
    async def stop_container(self, container_name_or_id: str, timeout: int = 10) -> bool:
        """åœæ­¢å®¹å™¨"""
        
        if not self.docker_client:
            raise RuntimeError("Docker å®¢æˆ¶ç«¯æœªé€£æ¥")
        
        try:
            container = self.docker_client.containers.get(container_name_or_id)
            container.stop(timeout=timeout)
            
            # æ›´æ–°å®¹å™¨ç‹€æ…‹
            await asyncio.sleep(1)
            container.reload()
            if container.id in self.managed_containers:
                self.managed_containers[container.id] = self._create_container_info(container)
            
            logger.info(f"å®¹å™¨å·²åœæ­¢: {container_name_or_id}")
            return True
            
        except Exception as e:
            logger.error(f"åœæ­¢å®¹å™¨å¤±æ•—: {container_name_or_id} - {e}")
            return False
    
    async def restart_container(self, container_name_or_id: str, timeout: int = 10) -> bool:
        """é‡å•Ÿå®¹å™¨"""
        
        if not self.docker_client:
            raise RuntimeError("Docker å®¢æˆ¶ç«¯æœªé€£æ¥")
        
        try:
            container = self.docker_client.containers.get(container_name_or_id)
            container.restart(timeout=timeout)
            
            # æ›´æ–°å®¹å™¨ç‹€æ…‹
            await asyncio.sleep(2)
            container.reload()
            if container.id in self.managed_containers:
                self.managed_containers[container.id] = self._create_container_info(container)
            
            logger.info(f"å®¹å™¨å·²é‡å•Ÿ: {container_name_or_id}")
            return True
            
        except Exception as e:
            logger.error(f"é‡å•Ÿå®¹å™¨å¤±æ•—: {container_name_or_id} - {e}")
            return False
    
    async def remove_container(self, container_name_or_id: str, force: bool = False) -> bool:
        """åˆªé™¤å®¹å™¨"""
        
        if not self.docker_client:
            raise RuntimeError("Docker å®¢æˆ¶ç«¯æœªé€£æ¥")
        
        try:
            container = self.docker_client.containers.get(container_name_or_id)
            container.remove(force=force)
            
            # å¾ç®¡ç†åˆ—è¡¨ä¸­ç§»é™¤
            if container.id in self.managed_containers:
                del self.managed_containers[container.id]
            
            logger.info(f"å®¹å™¨å·²åˆªé™¤: {container_name_or_id}")
            return True
            
        except Exception as e:
            logger.error(f"åˆªé™¤å®¹å™¨å¤±æ•—: {container_name_or_id} - {e}")
            return False
    
    async def get_container_logs(self, 
                               container_name_or_id: str,
                               tail: int = 100,
                               follow: bool = False) -> List[str]:
        """ç²å–å®¹å™¨æ—¥èªŒ"""
        
        if not self.docker_client:
            raise RuntimeError("Docker å®¢æˆ¶ç«¯æœªé€£æ¥")
        
        try:
            container = self.docker_client.containers.get(container_name_or_id)
            logs = container.logs(tail=tail, follow=follow, stream=follow)
            
            if follow:
                # æµå¼æ—¥èªŒ
                log_lines = []
                for log_line in logs:
                    log_lines.append(log_line.decode('utf-8').strip())
                    if len(log_lines) >= tail:
                        break
                return log_lines
            else:
                # ä¸€æ¬¡æ€§æ—¥èªŒ
                return logs.decode('utf-8').strip().split('\n')
                
        except Exception as e:
            logger.error(f"ç²å–å®¹å™¨æ—¥èªŒå¤±æ•—: {container_name_or_id} - {e}")
            return []
    
    async def get_container_stats(self, container_name_or_id: str) -> Dict[str, Any]:
        """ç²å–å®¹å™¨çµ±è¨ˆè³‡è¨Š"""
        
        if not self.docker_client:
            raise RuntimeError("Docker å®¢æˆ¶ç«¯æœªé€£æ¥")
        
        try:
            container = self.docker_client.containers.get(container_name_or_id)
            stats = container.stats(stream=False)
            
            # è¨ˆç®— CPU ä½¿ç”¨ç‡
            cpu_usage = 0
            if 'cpu_stats' in stats and 'precpu_stats' in stats:
                cpu_delta = stats['cpu_stats']['cpu_usage']['total_usage'] - \
                           stats['precpu_stats']['cpu_usage']['total_usage']
                system_delta = stats['cpu_stats']['system_cpu_usage'] - \
                              stats['precpu_stats']['system_cpu_usage']
                
                if system_delta > 0:
                    cpu_usage = (cpu_delta / system_delta) * len(stats['cpu_stats']['cpu_usage']['percpu_usage']) * 100
            
            # è¨ˆç®—è¨˜æ†¶é«”ä½¿ç”¨ç‡
            memory_usage = 0
            memory_limit = 0
            if 'memory_stats' in stats:
                memory_usage = stats['memory_stats'].get('usage', 0)
                memory_limit = stats['memory_stats'].get('limit', 0)
            
            memory_percentage = 0
            if memory_limit > 0:
                memory_percentage = (memory_usage / memory_limit) * 100
            
            # ç¶²è·¯çµ±è¨ˆ
            network_rx = 0
            network_tx = 0
            if 'networks' in stats:
                for interface, net_stats in stats['networks'].items():
                    network_rx += net_stats.get('rx_bytes', 0)
                    network_tx += net_stats.get('tx_bytes', 0)
            
            return {
                'cpu_percentage': round(cpu_usage, 2),
                'memory_usage_bytes': memory_usage,
                'memory_limit_bytes': memory_limit,
                'memory_percentage': round(memory_percentage, 2),
                'network_rx_bytes': network_rx,
                'network_tx_bytes': network_tx,
                'timestamp': datetime.now()
            }
            
        except Exception as e:
            logger.error(f"ç²å–å®¹å™¨çµ±è¨ˆå¤±æ•—: {container_name_or_id} - {e}")
            return {}
    
    async def deploy_to_kubernetes(self, config: KubernetesConfiguration) -> DeploymentInfo:
        """éƒ¨ç½²åˆ° Kubernetes"""
        
        logger.info(f"é–‹å§‹ Kubernetes éƒ¨ç½²: {config.deployment_name}", extra={
            'namespace': config.namespace,
            'replicas': config.replicas,
            'image': config.image
        })
        
        try:
            # ç”Ÿæˆ Kubernetes æ¸…å–®
            manifests = self._generate_k8s_manifests(config)
            
            # æ‡‰ç”¨æ¸…å–®
            for manifest_type, manifest_content in manifests.items():
                await self._apply_k8s_manifest(manifest_content, manifest_type)
            
            # ç­‰å¾…éƒ¨ç½²å®Œæˆ
            deployment_info = await self._wait_for_deployment(config)
            
            self.managed_deployments[config.deployment_name] = deployment_info
            
            logger.info(f"Kubernetes éƒ¨ç½²æˆåŠŸ: {config.deployment_name}", extra={
                'deployment_id': deployment_info.deployment_id,
                'available_replicas': deployment_info.available_replicas
            })
            
            return deployment_info
            
        except Exception as e:
            logger.error(f"Kubernetes éƒ¨ç½²å¤±æ•—: {config.deployment_name} - {e}")
            raise
    
    def _generate_k8s_manifests(self, config: KubernetesConfiguration) -> Dict[str, Dict]:
        """ç”Ÿæˆ Kubernetes æ¸…å–®"""
        
        manifests = {}
        
        # Deployment æ¸…å–®
        deployment = {
            'apiVersion': 'apps/v1',
            'kind': 'Deployment',
            'metadata': {
                'name': config.deployment_name,
                'namespace': config.namespace,
                'labels': config.labels,
                'annotations': config.annotations
            },
            'spec': {
                'replicas': config.replicas,
                'selector': {
                    'matchLabels': {
                        'app': config.deployment_name
                    }
                },
                'template': {
                    'metadata': {
                        'labels': {
                            'app': config.deployment_name,
                            **config.labels
                        }
                    },
                    'spec': {
                        'containers': [{
                            'name': config.deployment_name,
                            'image': config.image,
                            'ports': [{'containerPort': port['container_port']} for port in config.ports],
                            'env': [{'name': k, 'value': v} for k, v in config.environment.items()],
                            'resources': {
                                'requests': config.resource_requests,
                                'limits': config.resource_limits
                            }
                        }]
                    }
                }
            }
        }
        
        # æ·»åŠ å¥åº·æª¢æŸ¥
        if config.health_checks:
            container = deployment['spec']['template']['spec']['containers'][0]
            if 'liveness_probe' in config.health_checks:
                container['livenessProbe'] = config.health_checks['liveness_probe']
            if 'readiness_probe' in config.health_checks:
                container['readinessProbe'] = config.health_checks['readiness_probe']
        
        # æ·»åŠ å·
        if config.volumes:
            deployment['spec']['template']['spec']['volumes'] = config.volumes
            deployment['spec']['template']['spec']['containers'][0]['volumeMounts'] = [
                {
                    'name': vol['name'],
                    'mountPath': vol['mount_path']
                }
                for vol in config.volumes
            ]
        
        manifests['deployment'] = deployment
        
        # Service æ¸…å–®
        if config.service_config:
            service = {
                'apiVersion': 'v1',
                'kind': 'Service',
                'metadata': {
                    'name': f"{config.deployment_name}-service",
                    'namespace': config.namespace,
                    'labels': config.labels
                },
                'spec': {
                    'selector': {
                        'app': config.deployment_name
                    },
                    'ports': [
                        {
                            'name': port.get('name', 'http'),
                            'port': port['service_port'],
                            'targetPort': port['container_port'],
                            'protocol': port.get('protocol', 'TCP')
                        }
                        for port in config.ports
                    ],
                    'type': config.service_config.get('type', 'ClusterIP')
                }
            }
            manifests['service'] = service
        
        # Ingress æ¸…å–®
        if config.ingress_config:
            ingress = {
                'apiVersion': 'networking.k8s.io/v1',
                'kind': 'Ingress',
                'metadata': {
                    'name': f"{config.deployment_name}-ingress",
                    'namespace': config.namespace,
                    'annotations': config.ingress_config.get('annotations', {})
                },
                'spec': {
                    'rules': [
                        {
                            'host': config.ingress_config['host'],
                            'http': {
                                'paths': [
                                    {
                                        'path': config.ingress_config.get('path', '/'),
                                        'pathType': 'Prefix',
                                        'backend': {
                                            'service': {
                                                'name': f"{config.deployment_name}-service",
                                                'port': {
                                                    'number': config.ports[0]['service_port']
                                                }
                                            }
                                        }
                                    }
                                ]
                            }
                        }
                    ]
                }
            }
            
            if config.ingress_config.get('tls'):
                ingress['spec']['tls'] = config.ingress_config['tls']
            
            manifests['ingress'] = ingress
        
        # ConfigMap æ¸…å–®
        for config_map in config.config_maps:
            manifests[f"configmap-{config_map['name']}"] = {
                'apiVersion': 'v1',
                'kind': 'ConfigMap',
                'metadata': {
                    'name': config_map['name'],
                    'namespace': config.namespace
                },
                'data': config_map['data']
            }
        
        # Secret æ¸…å–®
        for secret in config.secrets:
            manifests[f"secret-{secret['name']}"] = {
                'apiVersion': 'v1',
                'kind': 'Secret',
                'metadata': {
                    'name': secret['name'],
                    'namespace': config.namespace
                },
                'type': secret.get('type', 'Opaque'),
                'data': secret['data']
            }
        
        return manifests
    
    async def _apply_k8s_manifest(self, manifest: Dict, manifest_type: str):
        """æ‡‰ç”¨ Kubernetes æ¸…å–®"""
        
        # å°‡æ¸…å–®å¯«å…¥è‡¨æ™‚æ–‡ä»¶
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(manifest, f, default_flow_style=False)
            temp_file = f.name
        
        try:
            # ä½¿ç”¨ kubectl apply
            cmd = ["kubectl", "apply", "-f", temp_file]
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode != 0:
                error_msg = stderr.decode() if stderr else "æœªçŸ¥éŒ¯èª¤"
                raise Exception(f"æ‡‰ç”¨ {manifest_type} æ¸…å–®å¤±æ•—: {error_msg}")
            
            logger.info(f"å·²æ‡‰ç”¨ {manifest_type} æ¸…å–®")
            
        finally:
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            Path(temp_file).unlink(missing_ok=True)
    
    async def _wait_for_deployment(self, config: KubernetesConfiguration) -> DeploymentInfo:
        """ç­‰å¾…éƒ¨ç½²å®Œæˆ"""
        
        max_wait_time = 300  # 5åˆ†é˜
        check_interval = 10   # 10ç§’
        
        for _ in range(max_wait_time // check_interval):
            try:
                # ç²å–éƒ¨ç½²ç‹€æ…‹
                cmd = [
                    "kubectl", "get", "deployment", config.deployment_name,
                    "-n", config.namespace,
                    "-o", "json"
                ]
                
                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                
                stdout, stderr = await process.communicate()
                
                if process.returncode == 0:
                    deployment_data = json.loads(stdout.decode())
                    deployment_info = self._parse_deployment_info(deployment_data)
                    
                    # æª¢æŸ¥æ˜¯å¦éƒ¨ç½²å®Œæˆ
                    if (deployment_info.available_replicas >= config.replicas and
                        deployment_info.ready_replicas >= config.replicas):
                        return deployment_info
                
                await asyncio.sleep(check_interval)
                
            except Exception as e:
                logger.warning(f"æª¢æŸ¥éƒ¨ç½²ç‹€æ…‹å¤±æ•—: {e}")
                await asyncio.sleep(check_interval)
        
        raise Exception(f"éƒ¨ç½² {config.deployment_name} è¶…æ™‚")
    
    def _parse_deployment_info(self, deployment_data: Dict) -> DeploymentInfo:
        """è§£æéƒ¨ç½²è³‡è¨Š"""
        
        metadata = deployment_data.get('metadata', {})
        status = deployment_data.get('status', {})
        
        # è§£æå‰µå»ºæ™‚é–“
        created_at = None
        if 'creationTimestamp' in metadata:
            created_at = datetime.fromisoformat(
                metadata['creationTimestamp'].replace('Z', '+00:00')
            )
        
        return DeploymentInfo(
            deployment_id=metadata.get('uid', ''),
            name=metadata.get('name', ''),
            namespace=metadata.get('namespace', ''),
            replicas=status.get('replicas', 0),
            available_replicas=status.get('availableReplicas', 0),
            ready_replicas=status.get('readyReplicas', 0),
            updated_replicas=status.get('updatedReplicas', 0),
            status='Ready' if status.get('readyReplicas', 0) == status.get('replicas', 0) else 'Updating',
            created_at=created_at,
            conditions=status.get('conditions', [])
        )
    
    async def scale_deployment(self, 
                             deployment_name: str, 
                             namespace: str,
                             replicas: int) -> bool:
        """æ“´å±•éƒ¨ç½²"""
        
        try:
            cmd = [
                "kubectl", "scale", "deployment", deployment_name,
                "-n", namespace,
                "--replicas", str(replicas)
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                logger.info(f"éƒ¨ç½²æ“´å±•æˆåŠŸ: {deployment_name} -> {replicas} å‰¯æœ¬")
                return True
            else:
                error_msg = stderr.decode() if stderr else "æœªçŸ¥éŒ¯èª¤"
                logger.error(f"éƒ¨ç½²æ“´å±•å¤±æ•—: {deployment_name} - {error_msg}")
                return False
                
        except Exception as e:
            logger.error(f"éƒ¨ç½²æ“´å±•éŒ¯èª¤: {deployment_name} - {e}")
            return False
    
    async def delete_deployment(self, deployment_name: str, namespace: str) -> bool:
        """åˆªé™¤éƒ¨ç½²"""
        
        try:
            cmd = [
                "kubectl", "delete", "deployment", deployment_name,
                "-n", namespace
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                # å¾ç®¡ç†åˆ—è¡¨ä¸­ç§»é™¤
                if deployment_name in self.managed_deployments:
                    del self.managed_deployments[deployment_name]
                
                logger.info(f"éƒ¨ç½²å·²åˆªé™¤: {deployment_name}")
                return True
            else:
                error_msg = stderr.decode() if stderr else "æœªçŸ¥éŒ¯èª¤"
                logger.error(f"åˆªé™¤éƒ¨ç½²å¤±æ•—: {deployment_name} - {error_msg}")
                return False
                
        except Exception as e:
            logger.error(f"åˆªé™¤éƒ¨ç½²éŒ¯èª¤: {deployment_name} - {e}")
            return False
    
    def list_containers(self) -> List[ContainerInfo]:
        """åˆ—å‡ºæ‰€æœ‰ç®¡ç†çš„å®¹å™¨"""
        return list(self.managed_containers.values())
    
    def list_deployments(self) -> List[DeploymentInfo]:
        """åˆ—å‡ºæ‰€æœ‰ç®¡ç†çš„éƒ¨ç½²"""
        return list(self.managed_deployments.values())
    
    async def get_cluster_info(self) -> Dict[str, Any]:
        """ç²å–å¢é›†è³‡è¨Š"""
        
        if self.platform != ContainerPlatform.KUBERNETES:
            return {}
        
        try:
            # ç²å–ç¯€é»è³‡è¨Š
            cmd = ["kubectl", "get", "nodes", "-o", "json"]
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                nodes_data = json.loads(stdout.decode())
                
                cluster_info = {
                    'nodes_count': len(nodes_data.get('items', [])),
                    'nodes': [],
                    'cluster_version': '',
                    'total_cpu': 0,
                    'total_memory': 0
                }
                
                for node in nodes_data.get('items', []):
                    node_info = {
                        'name': node['metadata']['name'],
                        'status': 'Ready' if any(
                            condition['type'] == 'Ready' and condition['status'] == 'True'
                            for condition in node['status']['conditions']
                        ) else 'NotReady',
                        'version': node['status']['nodeInfo']['kubeletVersion'],
                        'os': node['status']['nodeInfo']['operatingSystem'],
                        'architecture': node['status']['nodeInfo']['architecture']
                    }
                    
                    # è³‡æºå®¹é‡
                    capacity = node['status']['capacity']
                    node_info['cpu'] = capacity.get('cpu', '0')
                    node_info['memory'] = capacity.get('memory', '0Ki')
                    
                    cluster_info['nodes'].append(node_info)
                
                return cluster_info
            
        except Exception as e:
            logger.error(f"ç²å–å¢é›†è³‡è¨Šå¤±æ•—: {e}")
        
        return {}
    
    async def cleanup_resources(self, namespace: Optional[str] = None):
        """æ¸…ç†è³‡æº"""
        
        logger.info("é–‹å§‹æ¸…ç†å®¹å™¨è³‡æº", extra={
            'managed_containers': len(self.managed_containers),
            'managed_deployments': len(self.managed_deployments),
            'namespace': namespace
        })
        
        # æ¸…ç† Docker å®¹å™¨
        if self.docker_client:
            for container_id in list(self.managed_containers.keys()):
                try:
                    await self.stop_container(container_id)
                    await self.remove_container(container_id)
                except Exception as e:
                    logger.warning(f"æ¸…ç†å®¹å™¨å¤±æ•— {container_id}: {e}")
        
        # æ¸…ç† Kubernetes éƒ¨ç½²
        if self.platform == ContainerPlatform.KUBERNETES:
            for deployment_name in list(self.managed_deployments.keys()):
                deployment_namespace = namespace or "default"
                try:
                    await self.delete_deployment(deployment_name, deployment_namespace)
                except Exception as e:
                    logger.warning(f"æ¸…ç†éƒ¨ç½²å¤±æ•— {deployment_name}: {e}")
        
        logger.info("å®¹å™¨è³‡æºæ¸…ç†å®Œæˆ")

def create_container_manager(platform: ContainerPlatform = ContainerPlatform.DOCKER) -> ContainerManager:
    """å‰µå»ºå®¹å™¨ç®¡ç†å™¨å¯¦ä¾‹"""
    return ContainerManager(platform)

if __name__ == "__main__":
    # æ¸¬è©¦è…³æœ¬
    async def test_container_manager():
        print("æ¸¬è©¦å®¹å™¨ç®¡ç†å™¨...")
        
        # å‰µå»ºç®¡ç†å™¨
        manager = create_container_manager(ContainerPlatform.DOCKER)
        
        # æ¸¬è©¦ Docker é…ç½®
        docker_config = DockerConfiguration(
            image_name="nginx",
            image_tag="alpine",
            container_name="test-nginx",
            ports={"8080": "80"},
            environment={"NGINX_HOST": "localhost"},
            restart_policy="unless-stopped"
        )
        
        try:
            # é‹è¡Œæ¸¬è©¦å®¹å™¨
            print("é‹è¡Œæ¸¬è©¦å®¹å™¨...")
            container_info = await manager.run_container(docker_config)
            print(f"âœ… å®¹å™¨é‹è¡ŒæˆåŠŸ: {container_info.name}")
            
            # ç²å–å®¹å™¨ç‹€æ…‹
            await asyncio.sleep(2)
            stats = await manager.get_container_stats(container_info.container_id)
            print(f"ğŸ“Š å®¹å™¨çµ±è¨ˆ: CPU {stats.get('cpu_percentage', 0):.1f}%, "
                  f"è¨˜æ†¶é«” {stats.get('memory_percentage', 0):.1f}%")
            
            # ç²å–æ—¥èªŒ
            logs = await manager.get_container_logs(container_info.container_id, tail=5)
            print(f"ğŸ“ å®¹å™¨æ—¥èªŒ: {len(logs)} è¡Œ")
            
            # åœæ­¢å®¹å™¨
            await manager.stop_container(container_info.container_id)
            print("â¹ï¸ å®¹å™¨å·²åœæ­¢")
            
            # æ¸…ç†
            await manager.remove_container(container_info.container_id)
            print("ğŸ—‘ï¸ å®¹å™¨å·²æ¸…ç†")
            
        except Exception as e:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        
        print("å®¹å™¨ç®¡ç†å™¨æ¸¬è©¦å®Œæˆ")
    
    asyncio.run(test_container_manager())