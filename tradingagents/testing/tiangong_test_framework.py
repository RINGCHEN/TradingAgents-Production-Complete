#!/usr/bin/env python3
"""
å¤©å·¥é–‹ç‰©æ¸¬è©¦æ¡†æ¶ (TianGong Test Framework)
å°ˆç‚ºå¤©å·¥é–‹ç‰©å”èª¿ç³»çµ±è¨­è¨ˆçš„ç¶œåˆæ¸¬è©¦å’Œé©—è­‰æ©Ÿåˆ¶

æ­¤æ¨¡çµ„æä¾›ï¼š
1. ä»£ç†äººåŠŸèƒ½æ¸¬è©¦
2. å”èª¿ç³»çµ±æ•´åˆæ¸¬è©¦
3. å·¥ä½œæµåŸ·è¡Œæ¸¬è©¦
4. æ€§èƒ½å£“åŠ›æ¸¬è©¦
5. å®‰å…¨æ€§æ¸¬è©¦
6. å®¹éŒ¯æ©Ÿåˆ¶æ¸¬è©¦
7. è‡ªå‹•åŒ–æ¸¬è©¦å ±å‘Š

ç”±ç‹„ä»å‚‘(å“è³ªå®ˆè­·è€…)è¨­è¨ˆå¯¦ç¾
"""

import asyncio
import pytest
import unittest
import time
import threading
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Union, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
import json
import logging
import traceback
import statistics
from contextlib import asynccontextmanager

from ..coordination import (
    TianGongCoordinationService,
    create_tiangong_service,
    create_project_context,
    ProjectType,
    TaskPriority,
    setup_coordination_system
)
from ..utils.logging_config import get_system_logger
from ..utils.performance_monitor import PerformanceCollector, PerformanceAnalyzer
from ..utils.resilience_manager import ResilienceManager

logger = get_system_logger("tiangong_test_framework")

class TestType(Enum):
    """æ¸¬è©¦é¡å‹"""
    UNIT = "unit"
    INTEGRATION = "integration"
    SYSTEM = "system"
    PERFORMANCE = "performance"
    SECURITY = "security"
    STRESS = "stress"
    SMOKE = "smoke"
    REGRESSION = "regression"

class TestStatus(Enum):
    """æ¸¬è©¦ç‹€æ…‹"""
    PENDING = "pending"
    RUNNING = "running"
    PASSED = "passed"
    FAILED = "failed"
    SKIPPED = "skipped"
    ERROR = "error"

class TestSeverity(Enum):
    """æ¸¬è©¦åš´é‡æ€§"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

@dataclass
class TestCase:
    """æ¸¬è©¦ç”¨ä¾‹"""
    test_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    name: str = ""
    description: str = ""
    test_type: TestType = TestType.UNIT
    severity: TestSeverity = TestSeverity.MEDIUM
    test_function: Optional[Callable] = None
    setup_function: Optional[Callable] = None
    teardown_function: Optional[Callable] = None
    timeout_seconds: int = 30
    expected_result: Optional[Any] = None
    test_data: Dict[str, Any] = field(default_factory=dict)
    prerequisites: List[str] = field(default_factory=list)
    tags: List[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class TestResult:
    """æ¸¬è©¦çµæœ"""
    test_id: str = ""
    test_name: str = ""
    status: TestStatus = TestStatus.PENDING
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    execution_time: float = 0.0
    actual_result: Optional[Any] = None
    expected_result: Optional[Any] = None
    error_message: Optional[str] = None
    error_traceback: Optional[str] = None
    assertions_passed: int = 0
    assertions_failed: int = 0
    performance_metrics: Dict[str, float] = field(default_factory=dict)
    logs: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'test_id': self.test_id,
            'test_name': self.test_name,
            'status': self.status.value,
            'start_time': self.start_time.isoformat() if self.start_time else None,
            'end_time': self.end_time.isoformat() if self.end_time else None,
            'execution_time': self.execution_time,
            'actual_result': str(self.actual_result) if self.actual_result is not None else None,
            'expected_result': str(self.expected_result) if self.expected_result is not None else None,
            'error_message': self.error_message,
            'assertions_passed': self.assertions_passed,
            'assertions_failed': self.assertions_failed,
            'performance_metrics': self.performance_metrics,
            'logs_count': len(self.logs)
        }

@dataclass
class TestSuite:
    """æ¸¬è©¦å¥—ä»¶"""
    suite_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    name: str = ""
    description: str = ""
    test_cases: List[TestCase] = field(default_factory=list)
    setup_suite: Optional[Callable] = None
    teardown_suite: Optional[Callable] = None
    parallel_execution: bool = False
    max_parallel_tests: int = 3
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class TestReport:
    """æ¸¬è©¦å ±å‘Š"""
    report_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    test_session_id: str = ""
    suite_name: str = ""
    total_tests: int = 0
    passed_tests: int = 0
    failed_tests: int = 0
    skipped_tests: int = 0
    error_tests: int = 0
    success_rate: float = 0.0
    total_execution_time: float = 0.0
    test_results: List[TestResult] = field(default_factory=list)
    performance_summary: Dict[str, Any] = field(default_factory=dict)
    coverage_data: Dict[str, Any] = field(default_factory=dict)
    recommendations: List[str] = field(default_factory=list)
    generated_at: datetime = field(default_factory=datetime.now)

class TestAssertion:
    """æ¸¬è©¦æ–·è¨€"""
    
    def __init__(self, test_result: TestResult):
        self.test_result = test_result
    
    def assert_equal(self, actual, expected, message: str = ""):
        """æ–·è¨€ç›¸ç­‰"""
        try:
            assert actual == expected, message or f"Expected {expected}, but got {actual}"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise
    
    def assert_not_equal(self, actual, expected, message: str = ""):
        """æ–·è¨€ä¸ç›¸ç­‰"""
        try:
            assert actual != expected, message or f"Expected {actual} != {expected}"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise
    
    def assert_true(self, condition, message: str = ""):
        """æ–·è¨€ç‚ºçœŸ"""
        try:
            assert condition is True, message or f"Expected True, but got {condition}"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise
    
    def assert_false(self, condition, message: str = ""):
        """æ–·è¨€ç‚ºå‡"""
        try:
            assert condition is False, message or f"Expected False, but got {condition}"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise
    
    def assert_is_none(self, value, message: str = ""):
        """æ–·è¨€ç‚ºNone"""
        try:
            assert value is None, message or f"Expected None, but got {value}"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise
    
    def assert_is_not_none(self, value, message: str = ""):
        """æ–·è¨€ä¸ç‚ºNone"""
        try:
            assert value is not None, message or f"Expected not None, but got None"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise
    
    def assert_in(self, item, container, message: str = ""):
        """æ–·è¨€åŒ…å«"""
        try:
            assert item in container, message or f"Expected {item} in {container}"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise
    
    def assert_greater(self, actual, expected, message: str = ""):
        """æ–·è¨€å¤§æ–¼"""
        try:
            assert actual > expected, message or f"Expected {actual} > {expected}"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise
    
    def assert_less(self, actual, expected, message: str = ""):
        """æ–·è¨€å°æ–¼"""
        try:
            assert actual < expected, message or f"Expected {actual} < {expected}"
            self.test_result.assertions_passed += 1
            return True
        except AssertionError as e:
            self.test_result.assertions_failed += 1
            self.test_result.logs.append(f"æ–·è¨€å¤±æ•—: {str(e)}")
            raise

class TianGongTestRunner:
    """å¤©å·¥é–‹ç‰©æ¸¬è©¦é‹è¡Œå™¨"""
    
    def __init__(self):
        self.test_suites: Dict[str, TestSuite] = {}
        self.test_results: Dict[str, List[TestResult]] = {}
        self.performance_collector = PerformanceCollector(collection_interval=1.0)
        self.current_session_id = None
    
    def register_test_suite(self, test_suite: TestSuite):
        """è¨»å†Šæ¸¬è©¦å¥—ä»¶"""
        self.test_suites[test_suite.suite_id] = test_suite
        logger.info(f"è¨»å†Šæ¸¬è©¦å¥—ä»¶: {test_suite.name} ({len(test_suite.test_cases)} å€‹æ¸¬è©¦ç”¨ä¾‹)")
    
    async def run_test_suite(self, suite_id: str) -> TestReport:
        """é‹è¡Œæ¸¬è©¦å¥—ä»¶"""
        
        if suite_id not in self.test_suites:
            raise ValueError(f"æ¸¬è©¦å¥—ä»¶ä¸å­˜åœ¨: {suite_id}")
        
        test_suite = self.test_suites[suite_id]
        self.current_session_id = str(uuid.uuid4())
        
        logger.info(f"é–‹å§‹é‹è¡Œæ¸¬è©¦å¥—ä»¶: {test_suite.name}")
        
        # å•Ÿå‹•æ€§èƒ½ç›£æ§
        await self.performance_collector.start_collection()
        
        suite_start_time = time.time()
        test_results = []
        
        try:
            # åŸ·è¡Œå¥—ä»¶è¨­ç½®
            if test_suite.setup_suite:
                try:
                    if asyncio.iscoroutinefunction(test_suite.setup_suite):
                        await test_suite.setup_suite()
                    else:
                        test_suite.setup_suite()
                    logger.info("å¥—ä»¶è¨­ç½®å®Œæˆ")
                except Exception as e:
                    logger.error(f"å¥—ä»¶è¨­ç½®å¤±æ•—: {e}")
                    raise
            
            # åŸ·è¡Œæ¸¬è©¦ç”¨ä¾‹
            if test_suite.parallel_execution:
                test_results = await self._run_tests_parallel(test_suite.test_cases, test_suite.max_parallel_tests)
            else:
                test_results = await self._run_tests_sequential(test_suite.test_cases)
            
            # åŸ·è¡Œå¥—ä»¶æ¸…ç†
            if test_suite.teardown_suite:
                try:
                    if asyncio.iscoroutinefunction(test_suite.teardown_suite):
                        await test_suite.teardown_suite()
                    else:
                        test_suite.teardown_suite()
                    logger.info("å¥—ä»¶æ¸…ç†å®Œæˆ")
                except Exception as e:
                    logger.error(f"å¥—ä»¶æ¸…ç†å¤±æ•—: {e}")
        
        finally:
            # åœæ­¢æ€§èƒ½ç›£æ§
            await self.performance_collector.stop_collection()
        
        suite_execution_time = time.time() - suite_start_time
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        report = self._generate_test_report(
            session_id=self.current_session_id,
            suite_name=test_suite.name,
            test_results=test_results,
            total_execution_time=suite_execution_time
        )
        
        # ä¿å­˜æ¸¬è©¦çµæœ
        self.test_results[self.current_session_id] = test_results
        
        logger.info(f"æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå®Œæˆ: {test_suite.name}", extra={
            'session_id': self.current_session_id,
            'total_tests': report.total_tests,
            'passed_tests': report.passed_tests,
            'failed_tests': report.failed_tests,
            'success_rate': report.success_rate,
            'execution_time': suite_execution_time
        })
        
        return report
    
    async def _run_tests_sequential(self, test_cases: List[TestCase]) -> List[TestResult]:
        """é †åºåŸ·è¡Œæ¸¬è©¦ç”¨ä¾‹"""
        results = []
        
        for test_case in test_cases:
            result = await self._run_single_test(test_case)
            results.append(result)
        
        return results
    
    async def _run_tests_parallel(self, test_cases: List[TestCase], max_parallel: int) -> List[TestResult]:
        """ä¸¦è¡ŒåŸ·è¡Œæ¸¬è©¦ç”¨ä¾‹"""
        results = []
        semaphore = asyncio.Semaphore(max_parallel)
        
        async def run_with_semaphore(test_case):
            async with semaphore:
                return await self._run_single_test(test_case)
        
        tasks = [run_with_semaphore(test_case) for test_case in test_cases]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è™•ç†ç•°å¸¸çµæœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_result = TestResult(
                    test_id=test_cases[i].test_id,
                    test_name=test_cases[i].name,
                    status=TestStatus.ERROR,
                    error_message=str(result),
                    error_traceback=traceback.format_exc()
                )
                processed_results.append(error_result)
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _run_single_test(self, test_case: TestCase) -> TestResult:
        """åŸ·è¡Œå–®å€‹æ¸¬è©¦ç”¨ä¾‹"""
        
        result = TestResult(
            test_id=test_case.test_id,
            test_name=test_case.name,
            expected_result=test_case.expected_result
        )
        
        assertion = TestAssertion(result)
        
        try:
            result.start_time = datetime.now()
            result.status = TestStatus.RUNNING
            
            # åŸ·è¡Œæ¸¬è©¦è¨­ç½®
            if test_case.setup_function:
                if asyncio.iscoroutinefunction(test_case.setup_function):
                    await test_case.setup_function()
                else:
                    test_case.setup_function()
            
            # åŸ·è¡Œæ¸¬è©¦å‡½æ•¸
            if test_case.test_function:
                start_time = time.time()
                
                if asyncio.iscoroutinefunction(test_case.test_function):
                    result.actual_result = await asyncio.wait_for(
                        test_case.test_function(assertion, test_case.test_data),
                        timeout=test_case.timeout_seconds
                    )
                else:
                    result.actual_result = test_case.test_function(assertion, test_case.test_data)
                
                execution_time = time.time() - start_time
                result.performance_metrics['execution_time'] = execution_time
            
            # æª¢æŸ¥æ¸¬è©¦çµæœ
            if result.assertions_failed > 0:
                result.status = TestStatus.FAILED
            else:
                result.status = TestStatus.PASSED
            
            # åŸ·è¡Œæ¸¬è©¦æ¸…ç†
            if test_case.teardown_function:
                if asyncio.iscoroutinefunction(test_case.teardown_function):
                    await test_case.teardown_function()
                else:
                    test_case.teardown_function()
        
        except asyncio.TimeoutError:
            result.status = TestStatus.FAILED
            result.error_message = f"æ¸¬è©¦è¶…æ™‚ ({test_case.timeout_seconds}s)"
        
        except Exception as e:
            result.status = TestStatus.ERROR
            result.error_message = str(e)
            result.error_traceback = traceback.format_exc()
        
        finally:
            result.end_time = datetime.now()
            if result.start_time:
                result.execution_time = (result.end_time - result.start_time).total_seconds()
        
        return result
    
    def _generate_test_report(self, 
                            session_id: str,
                            suite_name: str, 
                            test_results: List[TestResult], 
                            total_execution_time: float) -> TestReport:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        
        # çµ±è¨ˆæ¸¬è©¦çµæœ
        total_tests = len(test_results)
        passed_tests = len([r for r in test_results if r.status == TestStatus.PASSED])
        failed_tests = len([r for r in test_results if r.status == TestStatus.FAILED])
        skipped_tests = len([r for r in test_results if r.status == TestStatus.SKIPPED])
        error_tests = len([r for r in test_results if r.status == TestStatus.ERROR])
        
        success_rate = passed_tests / total_tests if total_tests > 0 else 0.0
        
        # æ€§èƒ½æ‘˜è¦
        execution_times = [r.execution_time for r in test_results if r.execution_time > 0]
        performance_summary = {}
        
        if execution_times:
            performance_summary = {
                'avg_execution_time': statistics.mean(execution_times),
                'min_execution_time': min(execution_times),
                'max_execution_time': max(execution_times),
                'total_execution_time': total_execution_time
            }
        
        # ç”Ÿæˆå»ºè­°
        recommendations = self._generate_recommendations(test_results, performance_summary)
        
        return TestReport(
            test_session_id=session_id,
            suite_name=suite_name,
            total_tests=total_tests,
            passed_tests=passed_tests,
            failed_tests=failed_tests,
            skipped_tests=skipped_tests,
            error_tests=error_tests,
            success_rate=success_rate,
            total_execution_time=total_execution_time,
            test_results=test_results,
            performance_summary=performance_summary,
            recommendations=recommendations
        )
    
    def _generate_recommendations(self, 
                                test_results: List[TestResult], 
                                performance_summary: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ¸¬è©¦å»ºè­°"""
        recommendations = []
        
        # å¤±æ•—ç‡åˆ†æ
        failed_tests = [r for r in test_results if r.status in [TestStatus.FAILED, TestStatus.ERROR]]
        if len(failed_tests) > len(test_results) * 0.1:  # å¤±æ•—ç‡è¶…é10%
            recommendations.append("æ¸¬è©¦å¤±æ•—ç‡è¼ƒé«˜ï¼Œå»ºè­°æª¢æŸ¥ä»£ç¢¼å“è³ªå’Œæ¸¬è©¦ç”¨ä¾‹è¨­è¨ˆ")
        
        # æ€§èƒ½åˆ†æ
        if performance_summary and performance_summary.get('avg_execution_time', 0) > 10:
            recommendations.append("å¹³å‡æ¸¬è©¦åŸ·è¡Œæ™‚é–“è¼ƒé•·ï¼Œå»ºè­°å„ªåŒ–æ¸¬è©¦ç”¨ä¾‹æˆ–ç³»çµ±æ€§èƒ½")
        
        # æ–·è¨€åˆ†æ
        total_assertions = sum(r.assertions_passed + r.assertions_failed for r in test_results)
        if total_assertions < len(test_results) * 2:  # å¹³å‡æ¯å€‹æ¸¬è©¦å°‘æ–¼2å€‹æ–·è¨€
            recommendations.append("æ¸¬è©¦è¦†è“‹åº¦å¯èƒ½ä¸è¶³ï¼Œå»ºè­°å¢åŠ æ›´å¤šæ–·è¨€å’Œæ¸¬è©¦å ´æ™¯")
        
        # éŒ¯èª¤æ¨¡å¼åˆ†æ
        error_messages = [r.error_message for r in failed_tests if r.error_message]
        common_errors = {}
        for error in error_messages:
            error_type = error.split(':')[0] if ':' in error else error
            common_errors[error_type] = common_errors.get(error_type, 0) + 1
        
        if common_errors:
            most_common_error = max(common_errors, key=common_errors.get)
            if common_errors[most_common_error] > 1:
                recommendations.append(f"å¸¸è¦‹éŒ¯èª¤æ¨¡å¼: {most_common_error}ï¼Œå»ºè­°é‡é»é—œæ³¨æ­¤é¡å•é¡Œ")
        
        return recommendations

class TianGongAgentTestSuite:
    """å¤©å·¥é–‹ç‰©ä»£ç†äººæ¸¬è©¦å¥—ä»¶"""
    
    @staticmethod
    def create_agent_functionality_tests() -> TestSuite:
        """å‰µå»ºä»£ç†äººåŠŸèƒ½æ¸¬è©¦å¥—ä»¶"""
        
        test_cases = []
        
        # å”èª¿å™¨æ¸¬è©¦
        test_cases.append(TestCase(
            name="å¤©å·¥å”èª¿å™¨åˆå§‹åŒ–æ¸¬è©¦",
            description="æ¸¬è©¦ä¸»å”èª¿å™¨æ˜¯å¦èƒ½æ­£ç¢ºåˆå§‹åŒ–",
            test_type=TestType.UNIT,
            severity=TestSeverity.CRITICAL,
            test_function=TianGongAgentTestSuite._test_coordinator_initialization,
            timeout_seconds=10
        ))
        
        # ä»£ç†äººè¨»å†Šæ¸¬è©¦
        test_cases.append(TestCase(
            name="ä»£ç†äººè¨»å†Šæ¸¬è©¦",
            description="æ¸¬è©¦ä»£ç†äººæ˜¯å¦èƒ½æ­£ç¢ºè¨»å†Šåˆ°å”èª¿å™¨",
            test_type=TestType.INTEGRATION,
            severity=TestSeverity.HIGH,
            test_function=TianGongAgentTestSuite._test_agent_registration,
            timeout_seconds=15
        ))
        
        # ä»»å‹™å”èª¿æ¸¬è©¦
        test_cases.append(TestCase(
            name="ä»»å‹™å”èª¿åŸ·è¡Œæ¸¬è©¦",
            description="æ¸¬è©¦ä»»å‹™æ˜¯å¦èƒ½æ­£ç¢ºåˆ†é…å’ŒåŸ·è¡Œ",
            test_type=TestType.INTEGRATION,
            severity=TestSeverity.HIGH,
            test_function=TianGongAgentTestSuite._test_task_coordination,
            timeout_seconds=30
        ))
        
        # å·¥ä½œç¸½çµæ¸¬è©¦
        test_cases.append(TestCase(
            name="å·¥ä½œç¸½çµç”Ÿæˆæ¸¬è©¦",
            description="æ¸¬è©¦æ˜¯å¦èƒ½æ­£ç¢ºç”Ÿæˆå·¥ä½œç¸½çµå ±å‘Š",
            test_type=TestType.INTEGRATION,
            severity=TestSeverity.MEDIUM,
            test_function=TianGongAgentTestSuite._test_work_summary_generation,
            timeout_seconds=20
        ))
        
        return TestSuite(
            name="å¤©å·¥é–‹ç‰©ä»£ç†äººåŠŸèƒ½æ¸¬è©¦å¥—ä»¶",
            description="æ¸¬è©¦æ‰€æœ‰ä»£ç†äººçš„åŸºæœ¬åŠŸèƒ½å’Œå”èª¿æ©Ÿåˆ¶",
            test_cases=test_cases,
            parallel_execution=False
        )
    
    @staticmethod
    async def _test_coordinator_initialization(assertion: TestAssertion, test_data: Dict[str, Any]):
        """æ¸¬è©¦å”èª¿å™¨åˆå§‹åŒ–"""
        from ..coordination.master_weaver import MasterWeaverCoordinator
        
        coordinator = MasterWeaverCoordinator()
        
        assertion.assert_is_not_none(coordinator, "å”èª¿å™¨æ‡‰è©²æˆåŠŸåˆå§‹åŒ–")
        assertion.assert_is_not_none(coordinator.coordinator_id, "å”èª¿å™¨æ‡‰è©²æœ‰å”¯ä¸€ID")
        assertion.assert_equal(coordinator.name, "å¤©å·¥ (TianGong) - ä¸»å”èª¿è€…", "å”èª¿å™¨åç¨±æ‡‰è©²æ­£ç¢º")
        
        return {"coordinator_id": coordinator.coordinator_id}
    
    @staticmethod
    async def _test_agent_registration(assertion: TestAssertion, test_data: Dict[str, Any]):
        """æ¸¬è©¦ä»£ç†äººè¨»å†Š"""
        coordinator, agents = await setup_coordination_system()
        
        assertion.assert_is_not_none(coordinator, "å”èª¿å™¨æ‡‰è©²æˆåŠŸåˆå§‹åŒ–")
        assertion.assert_greater(len(agents), 0, "æ‡‰è©²è¨»å†Šè‡³å°‘ä¸€å€‹ä»£ç†äºº")
        assertion.assert_equal(len(agents), 6, "æ‡‰è©²è¨»å†Š6å€‹å°ˆæ¥­ä»£ç†äºº")
        
        # æª¢æŸ¥ç‰¹å®šä»£ç†äºº
        expected_agents = [
            'code_architect_liang',
            'code_artisan_luban',
            'qa_guardian_direnjie',
            'doc_scribe_sima',
            'devops_engineer_mozi',
            'security_advisor_baozhen'
        ]
        
        for agent_name in expected_agents:
            assertion.assert_in(agent_name, agents, f"æ‡‰è©²åŒ…å«ä»£ç†äºº: {agent_name}")
        
        return {"registered_agents": len(agents)}
    
    @staticmethod
    async def _test_task_coordination(assertion: TestAssertion, test_data: Dict[str, Any]):
        """æ¸¬è©¦ä»»å‹™å”èª¿"""
        from ..coordination.master_weaver import TaskCoordination, TaskPriority
        
        coordinator, agents = await setup_coordination_system()
        
        # å‰µå»ºæ¸¬è©¦ä»»å‹™
        task = TaskCoordination(
            name="æ¸¬è©¦ä»»å‹™",
            description="ç”¨æ–¼æ¸¬è©¦çš„ç°¡å–®ä»»å‹™",
            task_type="test_task",
            priority=TaskPriority.MEDIUM,
            estimated_hours=1
        )
        
        # å”èª¿åŸ·è¡Œä»»å‹™
        result = await coordinator.coordinate_task(task)
        
        assertion.assert_is_not_none(result, "ä»»å‹™å”èª¿æ‡‰è©²è¿”å›çµæœ")
        assertion.assert_true(hasattr(result, 'task_id'), "çµæœæ‡‰è©²åŒ…å«ä»»å‹™ID")
        
        return {"task_executed": True, "result": str(result)}
    
    @staticmethod
    async def _test_work_summary_generation(assertion: TestAssertion, test_data: Dict[str, Any]):
        """æ¸¬è©¦å·¥ä½œç¸½çµç”Ÿæˆ"""
        coordinator, agents = await setup_coordination_system()
        
        # åŸ·è¡Œä¸€å€‹ç°¡å–®ä»»å‹™ä»¥ç”Ÿæˆå·¥ä½œæ•¸æ“š
        from ..coordination.master_weaver import TaskCoordination, TaskPriority
        
        task = TaskCoordination(
            name="ç¸½çµæ¸¬è©¦ä»»å‹™",
            description="ç”¨æ–¼æ¸¬è©¦ç¸½çµç”Ÿæˆçš„ä»»å‹™",
            task_type="summary_test",
            priority=TaskPriority.LOW,
            estimated_hours=0.5
        )
        
        await coordinator.coordinate_task(task)
        
        # ç”Ÿæˆå·¥ä½œç¸½çµ
        summary = await coordinator.generate_work_summary()
        
        assertion.assert_is_not_none(summary, "æ‡‰è©²ç”Ÿæˆå·¥ä½œç¸½çµ")
        assertion.assert_is_not_none(summary.report_id, "ç¸½çµæ‡‰è©²æœ‰å ±å‘ŠID")
        assertion.assert_greater(len(summary.achievements), 0, "ç¸½çµæ‡‰è©²åŒ…å«æˆå°±")
        
        return {"summary_generated": True, "report_id": summary.report_id}

class TianGongSystemTestSuite:
    """å¤©å·¥é–‹ç‰©ç³»çµ±æ¸¬è©¦å¥—ä»¶"""
    
    @staticmethod
    def create_system_integration_tests() -> TestSuite:
        """å‰µå»ºç³»çµ±æ•´åˆæ¸¬è©¦å¥—ä»¶"""
        
        test_cases = []
        
        # å”èª¿æœå‹™æ¸¬è©¦
        test_cases.append(TestCase(
            name="å”èª¿æœå‹™å®Œæ•´æµç¨‹æ¸¬è©¦",
            description="æ¸¬è©¦å¤©å·¥é–‹ç‰©å”èª¿æœå‹™çš„å®Œæ•´å°ˆæ¡ˆåŸ·è¡Œæµç¨‹",
            test_type=TestType.SYSTEM,
            severity=TestSeverity.CRITICAL,
            test_function=TianGongSystemTestSuite._test_coordination_service_full_flow,
            timeout_seconds=60
        ))
        
        # æ€§èƒ½æ¸¬è©¦
        test_cases.append(TestCase(
            name="ä¸¦è¡Œä»»å‹™è™•ç†æ€§èƒ½æ¸¬è©¦",
            description="æ¸¬è©¦ç³»çµ±è™•ç†å¤šå€‹ä¸¦è¡Œä»»å‹™çš„æ€§èƒ½",
            test_type=TestType.PERFORMANCE,
            severity=TestSeverity.HIGH,
            test_function=TianGongSystemTestSuite._test_parallel_task_performance,
            timeout_seconds=45
        ))
        
        # å®¹éŒ¯æ¸¬è©¦
        test_cases.append(TestCase(
            name="ç³»çµ±å®¹éŒ¯æ©Ÿåˆ¶æ¸¬è©¦",
            description="æ¸¬è©¦ç³»çµ±åœ¨ç•°å¸¸æƒ…æ³ä¸‹çš„å®¹éŒ¯èƒ½åŠ›",
            test_type=TestType.STRESS,
            severity=TestSeverity.HIGH,
            test_function=TianGongSystemTestSuite._test_fault_tolerance,
            timeout_seconds=30
        ))
        
        return TestSuite(
            name="å¤©å·¥é–‹ç‰©ç³»çµ±æ•´åˆæ¸¬è©¦å¥—ä»¶",
            description="æ¸¬è©¦æ•´å€‹å¤©å·¥é–‹ç‰©ç³»çµ±çš„æ•´åˆåŠŸèƒ½å’Œæ€§èƒ½",
            test_cases=test_cases,
            parallel_execution=False
        )
    
    @staticmethod
    async def _test_coordination_service_full_flow(assertion: TestAssertion, test_data: Dict[str, Any]):
        """æ¸¬è©¦å”èª¿æœå‹™å®Œæ•´æµç¨‹"""
        
        # åˆå§‹åŒ–æœå‹™
        service = await create_tiangong_service()
        
        assertion.assert_is_not_none(service, "å”èª¿æœå‹™æ‡‰è©²æˆåŠŸåˆå§‹åŒ–")
        
        # å‰µå»ºæ¸¬è©¦å°ˆæ¡ˆ
        project = create_project_context(
            name="ç³»çµ±æ¸¬è©¦å°ˆæ¡ˆ",
            project_type=ProjectType.WEB_APPLICATION,
            requirements=["åŸºæœ¬åŠŸèƒ½", "æ¸¬è©¦è¦†è“‹", "æ–‡æª”å®Œæ•´"]
        )
        
        assertion.assert_is_not_none(project, "å°ˆæ¡ˆä¸Šä¸‹æ–‡æ‡‰è©²æˆåŠŸå‰µå»º")
        
        # åŸ·è¡Œå°ˆæ¡ˆå”èª¿
        result = await service.execute_project(project)
        
        assertion.assert_is_not_none(result, "å°ˆæ¡ˆåŸ·è¡Œæ‡‰è©²è¿”å›çµæœ")
        assertion.assert_true(result.overall_success, "å°ˆæ¡ˆæ‡‰è©²åŸ·è¡ŒæˆåŠŸ")
        assertion.assert_greater(result.tasks_completed, 0, "æ‡‰è©²å®Œæˆè‡³å°‘ä¸€å€‹ä»»å‹™")
        
        # é—œé–‰æœå‹™
        await service.shutdown()
        
        return {
            "project_executed": True,
            "tasks_completed": result.tasks_completed,
            "execution_time": result.execution_time
        }
    
    @staticmethod
    async def _test_parallel_task_performance(assertion: TestAssertion, test_data: Dict[str, Any]):
        """æ¸¬è©¦ä¸¦è¡Œä»»å‹™æ€§èƒ½"""
        
        service = await create_tiangong_service()
        
        # å‰µå»ºå¤šå€‹ä¸¦è¡Œå°ˆæ¡ˆ
        projects = []
        for i in range(3):
            project = create_project_context(
                name=f"ä¸¦è¡Œæ¸¬è©¦å°ˆæ¡ˆ{i+1}",
                project_type=ProjectType.API_SERVICE,
                requirements=[f"éœ€æ±‚{i+1}"]
            )
            projects.append(project)
        
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        start_time = time.time()
        
        # ä¸¦è¡ŒåŸ·è¡Œå°ˆæ¡ˆ
        tasks = [service.execute_project(project) for project in projects]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        execution_time = time.time() - start_time
        
        # æª¢æŸ¥çµæœ
        successful_results = [r for r in results if not isinstance(r, Exception)]
        assertion.assert_equal(len(successful_results), 3, "æ‰€æœ‰ä¸¦è¡Œå°ˆæ¡ˆæ‡‰è©²æˆåŠŸåŸ·è¡Œ")
        assertion.assert_less(execution_time, 30, "ä¸¦è¡ŒåŸ·è¡Œæ™‚é–“æ‡‰è©²åœ¨åˆç†ç¯„åœå…§")
        
        await service.shutdown()
        
        return {
            "parallel_projects": len(projects),
            "successful_executions": len(successful_results),
            "total_execution_time": execution_time
        }
    
    @staticmethod
    async def _test_fault_tolerance(assertion: TestAssertion, test_data: Dict[str, Any]):
        """æ¸¬è©¦å®¹éŒ¯æ©Ÿåˆ¶"""
        
        service = await create_tiangong_service()
        
        # å‰µå»ºä¸€å€‹å¯èƒ½å¤±æ•—çš„å°ˆæ¡ˆ
        project = create_project_context(
            name="å®¹éŒ¯æ¸¬è©¦å°ˆæ¡ˆ",
            project_type=ProjectType.TRADING_SYSTEM,
            requirements=["è¤‡é›œéœ€æ±‚", "é«˜é¢¨éšªæ“ä½œ"]
        )
        
        try:
            # åŸ·è¡Œå°ˆæ¡ˆï¼ˆå¯èƒ½æœƒæœ‰éƒ¨åˆ†å¤±æ•—ï¼‰
            result = await service.execute_project(project)
            
            # æª¢æŸ¥ç³»çµ±æ˜¯å¦å„ªé›…è™•ç†äº†å•é¡Œ
            assertion.assert_is_not_none(result, "å³ä½¿æœ‰å¤±æ•—ï¼Œç³»çµ±ä¹Ÿæ‡‰è©²è¿”å›çµæœ")
            assertion.assert_greater_equal(result.tasks_completed + result.tasks_failed, 1, "æ‡‰è©²å˜—è©¦åŸ·è¡Œä»»å‹™")
            
            # æª¢æŸ¥ç³»çµ±ç‹€æ…‹
            status = await service.get_service_status()
            assertion.assert_equal(status['status'], 'ready', "æœå‹™æ‡‰è©²ä¿æŒå¯ç”¨ç‹€æ…‹")
            
        except Exception as e:
            # å¦‚æœæœ‰ç•°å¸¸ï¼Œæª¢æŸ¥æ˜¯å¦è¢«æ­£ç¢ºè™•ç†
            assertion.assert_true(isinstance(e, (ValueError, RuntimeError)), f"æ‡‰è©²æ˜¯é æœŸçš„ç•°å¸¸é¡å‹: {type(e)}")
        
        await service.shutdown()
        
        return {"fault_tolerance_tested": True}

# ä¾¿åˆ©å‡½æ•¸
async def run_agent_tests() -> TestReport:
    """é‹è¡Œä»£ç†äººæ¸¬è©¦"""
    runner = TianGongTestRunner()
    test_suite = TianGongAgentTestSuite.create_agent_functionality_tests()
    runner.register_test_suite(test_suite)
    return await runner.run_test_suite(test_suite.suite_id)

async def run_system_tests() -> TestReport:
    """é‹è¡Œç³»çµ±æ¸¬è©¦"""
    runner = TianGongTestRunner()
    test_suite = TianGongSystemTestSuite.create_system_integration_tests()
    runner.register_test_suite(test_suite)
    return await runner.run_test_suite(test_suite.suite_id)

async def run_all_tests() -> Dict[str, TestReport]:
    """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
    results = {}
    
    # é‹è¡Œä»£ç†äººæ¸¬è©¦
    agent_report = await run_agent_tests()
    results['agent_tests'] = agent_report
    
    # é‹è¡Œç³»çµ±æ¸¬è©¦  
    system_report = await run_system_tests()
    results['system_tests'] = system_report
    
    return results

if __name__ == "__main__":
    # æ¸¬è©¦è…³æœ¬
    async def main():
        print("ğŸ§ª å¤©å·¥é–‹ç‰©æ¸¬è©¦æ¡†æ¶æ¼”ç¤º")
        print("=" * 50)
        
        try:
            # é‹è¡Œæ‰€æœ‰æ¸¬è©¦
            test_results = await run_all_tests()
            
            print("\nğŸ“Š æ¸¬è©¦çµæœæ‘˜è¦:")
            print("-" * 30)
            
            for test_type, report in test_results.items():
                print(f"\n{test_type.upper()}:")
                print(f"  ç¸½æ¸¬è©¦æ•¸: {report.total_tests}")
                print(f"  é€šé: {report.passed_tests}")
                print(f"  å¤±æ•—: {report.failed_tests}")
                print(f"  éŒ¯èª¤: {report.error_tests}")
                print(f"  æˆåŠŸç‡: {report.success_rate:.1%}")
                print(f"  åŸ·è¡Œæ™‚é–“: {report.total_execution_time:.2f}s")
                
                if report.recommendations:
                    print(f"  å»ºè­°:")
                    for rec in report.recommendations:
                        print(f"    - {rec}")
            
            print("\nâœ… æ¸¬è©¦æ¡†æ¶æ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
            return 1
        
        return 0
    
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)